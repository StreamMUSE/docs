{"config":{"lang":["en","zh"],"separator":"[\\s\\u200b\\u3000\\-\u3001\u3002\uff0c\uff0e\uff1f\uff01\uff1b]+","pipeline":["stemmer"]},"docs":[{"location":"","title":"StreamMUSE Documentation","text":"<p>\u6b22\u8fce\u6765\u5230 StreamMUSE \u9879\u76ee\u6587\u6863\uff01</p>"},{"location":"#_1","title":"\u9879\u76ee\u7b80\u4ecb","text":"<p>StreamMUSE \u662f\u4e00\u4e2a...\uff08\u9879\u76ee\u63cf\u8ff0\uff09</p>"},{"location":"#_2","title":"\u5feb\u901f\u5bfc\u822a","text":""},{"location":"#real-time-inference-system","title":"\ud83d\ude80 Real-Time Inference System","text":"<p>\u5b9e\u65f6\u63a8\u7406\u7cfb\u7edf\u662f StreamMUSE \u7684\u6838\u5fc3\u7ec4\u4ef6\uff0c\u63d0\u4f9b\u9ad8\u6027\u80fd\u7684\u5b9e\u65f6\u6570\u636e\u5904\u7406\u548c\u63a8\u7406\u80fd\u529b\u3002</p> <ul> <li>\u7cfb\u7edf\u6982\u8ff0</li> <li>\u5feb\u901f\u5f00\u59cb</li> <li>API \u53c2\u8003</li> </ul>"},{"location":"#training-framework","title":"\ud83c\udfd7\ufe0f Training Framework","text":"<p>\u8bad\u7ec3\u6846\u67b6\u4e3a\u6a21\u578b\u8bad\u7ec3\u63d0\u4f9b\u5b8c\u6574\u7684\u5de5\u5177\u94fe\u548c\u7ba1\u7406\u5e73\u53f0\u3002</p> <ul> <li>\u6846\u67b6\u6982\u8ff0</li> <li>\u73af\u5883\u8bbe\u7f6e</li> <li>\u6a21\u578b\u8bad\u7ec3</li> </ul>"},{"location":"#_3","title":"\u83b7\u53d6\u5e2e\u52a9","text":"<p>\u5982\u679c\u60a8\u5728\u4f7f\u7528\u8fc7\u7a0b\u4e2d\u9047\u5230\u95ee\u9898\uff0c\u53ef\u4ee5\uff1a</p> <ul> <li>\u67e5\u770b \u5e38\u89c1\u95ee\u9898</li> <li>\u63d0\u4ea4 GitHub Issue</li> <li>\u8054\u7cfb\u5f00\u53d1\u56e2\u961f</li> </ul>"},{"location":"#_4","title":"\u8d21\u732e\u6307\u5357","text":"<p>\u6211\u4eec\u6b22\u8fce\u793e\u533a\u8d21\u732e\uff01\u8bf7\u67e5\u770b\u6211\u4eec\u7684\u8d21\u732e\u6307\u5357\u4e86\u89e3\u5982\u4f55\u53c2\u4e0e\u9879\u76ee\u5f00\u53d1\u3002</p> <p>\u6700\u540e\u66f4\u65b0: {{ page.meta.git_revision_date_localized }}</p>"},{"location":"changelog/","title":"\u66f4\u65b0\u65e5\u5fd7","text":""},{"location":"changelog/#unreleased","title":"[Unreleased]","text":""},{"location":"changelog/#_2","title":"\u65b0\u589e","text":"<ul> <li>\u65b0\u529f\u80fd\u5f00\u53d1\u4e2d...</li> </ul>"},{"location":"changelog/#_3","title":"\u4fee\u6539","text":"<ul> <li>\u6027\u80fd\u4f18\u5316</li> </ul>"},{"location":"changelog/#_4","title":"\u4fee\u590d","text":"<ul> <li>Bug \u4fee\u590d</li> </ul>"},{"location":"changelog/#v100-2024-09-11","title":"[v1.0.0] - 2024-09-11","text":""},{"location":"changelog/#_5","title":"\u65b0\u589e","text":"<ul> <li>Real-Time Inference System \u521d\u59cb\u7248\u672c</li> <li>Training Framework \u521d\u59cb\u7248\u672c</li> <li>\u5b8c\u6574\u7684\u6587\u6863\u7cfb\u7edf</li> <li>\u76d1\u63a7\u548c\u65e5\u5fd7\u7cfb\u7edf</li> </ul>"},{"location":"changelog/#_6","title":"\u7279\u6027","text":"<ul> <li>\u652f\u6301\u591a\u79cd\u6a21\u578b\u683c\u5f0f</li> <li>\u5206\u5e03\u5f0f\u8bad\u7ec3</li> <li>\u5b9e\u65f6\u63a8\u7406</li> <li>\u81ea\u52a8\u5316\u90e8\u7f72</li> </ul>"},{"location":"changelog/#_7","title":"\u7248\u672c\u53f7\u8bf4\u660e","text":"<p>\u6211\u4eec\u4f7f\u7528 \u8bed\u4e49\u5316\u7248\u672c \u8fdb\u884c\u7248\u672c\u7ba1\u7406\uff1a</p> <ul> <li>\u4e3b\u7248\u672c\u53f7: \u4e0d\u517c\u5bb9\u7684 API \u4fee\u6539</li> <li>\u6b21\u7248\u672c\u53f7: \u5411\u4e0b\u517c\u5bb9\u7684\u529f\u80fd\u6027\u65b0\u589e</li> <li>\u4fee\u8ba2\u53f7: \u5411\u4e0b\u517c\u5bb9\u7684\u95ee\u9898\u4fee\u6b63</li> </ul>"},{"location":"changelog/#_8","title":"\u53d1\u5e03\u8ba1\u5212","text":"<ul> <li>v1.1.0: \u9884\u8ba1 2024\u5e7410\u6708\uff0c\u65b0\u589e\u6a21\u578b\u4f18\u5316\u529f\u80fd</li> <li>v1.2.0: \u9884\u8ba1 2024\u5e7411\u6708\uff0c\u589e\u5f3a\u76d1\u63a7\u7cfb\u7edf</li> <li>v2.0.0: \u9884\u8ba1 2025\u5e741\u6708\uff0c\u67b6\u6784\u91cd\u6784</li> </ul>"},{"location":"faq/","title":"\u5e38\u89c1\u95ee\u9898","text":""},{"location":"faq/#_2","title":"\u4e00\u822c\u95ee\u9898","text":""},{"location":"faq/#q-streammuse","title":"Q: StreamMUSE \u652f\u6301\u54ea\u4e9b\u6a21\u578b\u683c\u5f0f\uff1f","text":"<p>A: \u76ee\u524d\u652f\u6301 PyTorch (.pth, .pt)\u3001TensorFlow (.pb, SavedModel)\u3001ONNX (.onnx) \u7b49\u683c\u5f0f\u3002</p>"},{"location":"faq/#q","title":"Q: \u5982\u4f55\u76d1\u63a7\u7cfb\u7edf\u6027\u80fd\uff1f","text":"<p>A: \u7cfb\u7edf\u5185\u7f6e Prometheus + Grafana \u76d1\u63a7\u6808\uff0c\u53ef\u4ee5\u5b9e\u65f6\u67e5\u770b\u6027\u80fd\u6307\u6807\u3002\u8bbf\u95ee <code>http://localhost:3000</code> \u67e5\u770b\u76d1\u63a7\u9762\u677f\u3002</p>"},{"location":"faq/#q-gpu","title":"Q: \u652f\u6301\u591aGPU\u8bad\u7ec3\u5417\uff1f","text":"<p>A: \u662f\u7684\uff0cTraining Framework \u652f\u6301\u591aGPU\u548c\u5206\u5e03\u5f0f\u8bad\u7ec3\u3002</p>"},{"location":"faq/#real-time-inference-system","title":"Real-Time Inference System","text":""},{"location":"faq/#q_1","title":"Q: \u63a8\u7406\u5ef6\u8fdf\u662f\u591a\u5c11\uff1f","text":"<p>A: \u5178\u578b\u5ef6\u8fdf\u5728 10-50ms \u4e4b\u95f4\uff0c\u5177\u4f53\u53d6\u51b3\u4e8e\u6a21\u578b\u5927\u5c0f\u548c\u786c\u4ef6\u914d\u7f6e\u3002</p>"},{"location":"faq/#q_2","title":"Q: \u5982\u4f55\u4f18\u5316\u63a8\u7406\u6027\u80fd\uff1f","text":"<p>A: \u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u4f18\u5316\uff1a - \u542f\u7528\u6a21\u578b\u91cf\u5316 - \u4f7f\u7528 GPU \u52a0\u901f - \u8c03\u6574\u6279\u5904\u7406\u5927\u5c0f - \u542f\u7528\u7f13\u5b58</p>"},{"location":"faq/#q_3","title":"Q: \u5982\u4f55\u5904\u7406\u5e76\u53d1\u8bf7\u6c42\uff1f","text":"<p>A: \u7cfb\u7edf\u652f\u6301\u81ea\u52a8\u8d1f\u8f7d\u5747\u8861\u548c\u52a8\u6001\u6269\u7f29\u5bb9\uff0c\u53ef\u4ee5\u6839\u636e\u8d1f\u8f7d\u81ea\u52a8\u8c03\u6574\u670d\u52a1\u5b9e\u4f8b\u6570\u91cf\u3002</p>"},{"location":"faq/#training-framework","title":"Training Framework","text":""},{"location":"faq/#q_4","title":"Q: \u5982\u4f55\u5f00\u59cb\u4e00\u4e2a\u65b0\u7684\u8bad\u7ec3\u4efb\u52a1\uff1f","text":"<p>A: \u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\uff1a <pre><code>streammuse-training run --config config.yaml\n</code></pre></p>"},{"location":"faq/#q_5","title":"Q: \u8bad\u7ec3\u53ef\u4ee5\u65ad\u70b9\u7eed\u4f20\u5417\uff1f","text":"<p>A: \u662f\u7684\uff0c\u7cfb\u7edf\u81ea\u52a8\u4fdd\u5b58\u68c0\u67e5\u70b9\uff0c\u53ef\u4ee5\u4ece\u4efb\u610f\u68c0\u67e5\u70b9\u6062\u590d\u8bad\u7ec3\u3002</p>"},{"location":"faq/#q_6","title":"Q: \u5982\u4f55\u67e5\u770b\u8bad\u7ec3\u65e5\u5fd7\uff1f","text":"<p>A: \u8bbf\u95ee MLflow UI (<code>http://localhost:5000</code>) \u67e5\u770b\u8be6\u7ec6\u7684\u8bad\u7ec3\u65e5\u5fd7\u548c\u6307\u6807\u3002</p>"},{"location":"faq/#_3","title":"\u6545\u969c\u6392\u9664","text":""},{"location":"faq/#_4","title":"\u670d\u52a1\u65e0\u6cd5\u542f\u52a8","text":"<ol> <li>\u68c0\u67e5\u7aef\u53e3\u662f\u5426\u88ab\u5360\u7528</li> <li>\u786e\u8ba4\u4f9d\u8d56\u670d\u52a1\u662f\u5426\u6b63\u5e38\u8fd0\u884c</li> <li>\u67e5\u770b\u65e5\u5fd7\u6587\u4ef6\u83b7\u53d6\u8be6\u7ec6\u9519\u8bef\u4fe1\u606f</li> </ol>"},{"location":"faq/#_5","title":"\u5185\u5b58\u4e0d\u8db3","text":"<ol> <li>\u51cf\u5c11\u6279\u5904\u7406\u5927\u5c0f</li> <li>\u542f\u7528\u68af\u5ea6\u7d2f\u79ef</li> <li>\u4f7f\u7528\u6a21\u578b\u5e76\u884c</li> </ol>"},{"location":"faq/#gpu","title":"GPU \u76f8\u5173\u95ee\u9898","text":"<ol> <li>\u786e\u8ba4 CUDA \u7248\u672c\u517c\u5bb9\u6027</li> <li>\u68c0\u67e5 GPU \u5185\u5b58\u4f7f\u7528\u60c5\u51b5</li> <li>\u9a8c\u8bc1 NVIDIA \u9a71\u52a8\u7a0b\u5e8f</li> </ol>"},{"location":"real-time-inference/","title":"Real-Time Inference System \u6982\u8ff0","text":""},{"location":"real-time-inference/#_1","title":"\u7cfb\u7edf\u7b80\u4ecb","text":"<p>Real-Time Inference System \u662f StreamMUSE \u7684\u6838\u5fc3\u63a8\u7406\u5f15\u64ce\uff0c\u4e13\u4e3a\u9ad8\u5e76\u53d1\u3001\u4f4e\u5ef6\u8fdf\u7684\u5b9e\u65f6\u6570\u636e\u5904\u7406\u573a\u666f\u8bbe\u8ba1\u3002</p>"},{"location":"real-time-inference/#_2","title":"\u4e3b\u8981\u7279\u6027","text":"<ul> <li>\u9ad8\u6027\u80fd: \u652f\u6301\u6beb\u79d2\u7ea7\u54cd\u5e94\u65f6\u95f4</li> <li>\u9ad8\u53ef\u7528: 99.9% \u670d\u52a1\u53ef\u7528\u6027\u4fdd\u8bc1</li> <li>\u5f39\u6027\u6269\u5c55: \u652f\u6301\u52a8\u6001\u6269\u7f29\u5bb9</li> <li>\u591a\u6a21\u578b\u652f\u6301: \u652f\u6301\u591a\u79cd\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6</li> </ul>"},{"location":"real-time-inference/#_3","title":"\u7cfb\u7edf\u67b6\u6784","text":"<pre><code>graph TD\n    A[\u5ba2\u6237\u7aef\u8bf7\u6c42] --&gt; B[\u8d1f\u8f7d\u5747\u8861\u5668]\n    B --&gt; C[API Gateway]\n    C --&gt; D[\u63a8\u7406\u670d\u52a1]\n    D --&gt; E[\u6a21\u578b\u7f13\u5b58]\n    D --&gt; F[\u7ed3\u679c\u5904\u7406]\n    F --&gt; G[\u54cd\u5e94\u8fd4\u56de]\n</code></pre>"},{"location":"real-time-inference/#_4","title":"\u6838\u5fc3\u7ec4\u4ef6","text":""},{"location":"real-time-inference/#_5","title":"\u63a8\u7406\u5f15\u64ce","text":"<ul> <li>\u6a21\u578b\u52a0\u8f7d\u4e0e\u7ba1\u7406</li> <li>\u6279\u5904\u7406\u4f18\u5316</li> <li>\u5185\u5b58\u7ba1\u7406</li> </ul>"},{"location":"real-time-inference/#_6","title":"\u7f13\u5b58\u7cfb\u7edf","text":"<ul> <li>\u6a21\u578b\u7f13\u5b58</li> <li>\u7ed3\u679c\u7f13\u5b58</li> <li>\u9884\u70ed\u673a\u5236</li> </ul>"},{"location":"real-time-inference/#_7","title":"\u76d1\u63a7\u7cfb\u7edf","text":"<ul> <li>\u6027\u80fd\u76d1\u63a7</li> <li>\u8d44\u6e90\u76d1\u63a7</li> <li>\u9519\u8bef\u8ffd\u8e2a</li> </ul>"},{"location":"real-time-inference/#_8","title":"\u5feb\u901f\u5f00\u59cb","text":"<p>\u8bf7\u67e5\u770b \u5feb\u901f\u5f00\u59cb\u6307\u5357 \u4e86\u89e3\u5982\u4f55\u90e8\u7f72\u548c\u4f7f\u7528\u7cfb\u7edf\u3002</p>"},{"location":"real-time-inference/architecture/","title":"\u7cfb\u7edf\u67b6\u6784","text":""},{"location":"real-time-inference/architecture/#_2","title":"\u6574\u4f53\u67b6\u6784","text":"<p>Real-Time Inference System \u91c7\u7528\u5fae\u670d\u52a1\u67b6\u6784\uff0c\u7531\u4ee5\u4e0b\u6838\u5fc3\u7ec4\u4ef6\u7ec4\u6210\uff1a</p>"},{"location":"real-time-inference/architecture/#_3","title":"\u7ec4\u4ef6\u8be6\u89e3","text":""},{"location":"real-time-inference/architecture/#api-gateway","title":"API Gateway","text":"<ul> <li>\u8bf7\u6c42\u8def\u7531</li> <li>\u8eab\u4efd\u9a8c\u8bc1</li> <li>\u9650\u6d41\u63a7\u5236</li> <li>\u65e5\u5fd7\u8bb0\u5f55</li> </ul>"},{"location":"real-time-inference/architecture/#inference-engine","title":"Inference Engine","text":"<ul> <li>\u6a21\u578b\u7ba1\u7406</li> <li>\u63a8\u7406\u6267\u884c</li> <li>\u6279\u5904\u7406\u4f18\u5316</li> <li>\u8d44\u6e90\u8c03\u5ea6</li> </ul>"},{"location":"real-time-inference/architecture/#cache-layer","title":"Cache Layer","text":"<ul> <li>Redis \u96c6\u7fa4</li> <li>\u6a21\u578b\u7f13\u5b58</li> <li>\u7ed3\u679c\u7f13\u5b58</li> </ul>"},{"location":"real-time-inference/architecture/#monitoring","title":"Monitoring","text":"<ul> <li>Prometheus + Grafana</li> <li>\u5b9e\u65f6\u76d1\u63a7</li> <li>\u544a\u8b66\u7cfb\u7edf</li> </ul>"},{"location":"real-time-inference/architecture/#_4","title":"\u6570\u636e\u6d41","text":"<ol> <li>\u5ba2\u6237\u7aef\u53d1\u9001\u63a8\u7406\u8bf7\u6c42</li> <li>API Gateway \u9a8c\u8bc1\u548c\u8def\u7531</li> <li>Inference Engine \u5904\u7406\u8bf7\u6c42</li> <li>\u8fd4\u56de\u63a8\u7406\u7ed3\u679c</li> </ol>"},{"location":"real-time-inference/architecture/#_5","title":"\u90e8\u7f72\u67b6\u6784","text":"<p>\u652f\u6301\u591a\u79cd\u90e8\u7f72\u65b9\u5f0f\uff1a - \u5355\u673a\u90e8\u7f72 - \u96c6\u7fa4\u90e8\u7f72 - \u4e91\u539f\u751f\u90e8\u7f72</p>"},{"location":"real-time-inference/configuration/","title":"\u914d\u7f6e\u6307\u5357","text":"<p>\u8be6\u7ec6\u7684\u914d\u7f6e\u9009\u9879\u8bf4\u660e...</p>"},{"location":"real-time-inference/configuration/#_2","title":"\u670d\u52a1\u5668\u914d\u7f6e","text":""},{"location":"real-time-inference/configuration/#_3","title":"\u6a21\u578b\u914d\u7f6e","text":""},{"location":"real-time-inference/configuration/#_4","title":"\u7f13\u5b58\u914d\u7f6e","text":""},{"location":"real-time-inference/configuration/#_5","title":"\u5b89\u5168\u914d\u7f6e","text":""},{"location":"real-time-inference/parameter/","title":"\u53c2\u6570\u6307\u5357","text":"<p>StreamMUSE Client \u662f\u4e00\u4e2a\u5b9e\u65f6\u97f3\u4e50\u751f\u6210\u7cfb\u7edf\u7684\u5ba2\u6237\u7aef\u5e94\u7528\u7a0b\u5e8f\uff0c\u652f\u6301\u591a\u79cd\u8f93\u5165\u6a21\u5f0f\u5e76\u4e0e StreamMUSE \u670d\u52a1\u5668\u901a\u4fe1\u751f\u6210\u97f3\u4e50\u4f34\u594f\u3002</p>"},{"location":"real-time-inference/parameter/#_2","title":"\u57fa\u672c\u7528\u6cd5","text":"<pre><code>python client.py [\u9009\u9879]\n</code></pre>"},{"location":"real-time-inference/parameter/#_3","title":"\u7f51\u7edc\u53c2\u6570","text":""},{"location":"real-time-inference/parameter/#-server_url","title":"<code>--server_url</code>","text":"<ul> <li>\u7c7b\u578b: \u5b57\u7b26\u4e32</li> <li>\u9ed8\u8ba4\u503c: <code>http://localhost:8988/generate_accompaniment</code></li> <li>\u8bf4\u660e: StreamMUSE \u670d\u52a1\u5668\u7684 URL \u5730\u5740</li> <li>\u793a\u4f8b: <code>--server_url http://192.168.1.100:8988/generate_accompaniment</code></li> </ul>"},{"location":"real-time-inference/parameter/#_4","title":"\u97f3\u4e50\u65f6\u95f4\u53c2\u6570","text":""},{"location":"real-time-inference/parameter/#-tempo","title":"<code>--tempo</code>","text":"<ul> <li>\u7c7b\u578b: \u6d6e\u70b9\u6570</li> <li>\u9ed8\u8ba4\u503c: <code>90.0</code></li> <li>\u8bf4\u660e: \u97f3\u4e50\u901f\u5ea6\uff0c\u5355\u4f4d\u4e3a BPM (\u6bcf\u5206\u949f\u8282\u62cd\u6570)</li> <li>\u793a\u4f8b: <code>--tempo 120</code></li> </ul>"},{"location":"real-time-inference/parameter/#-ticks_per_beat","title":"<code>--ticks_per_beat</code>","text":"<ul> <li>\u7c7b\u578b: \u6574\u6570</li> <li>\u9ed8\u8ba4\u503c: <code>4</code></li> <li>\u8bf4\u660e: \u6bcf\u4e2a\u8282\u62cd\u5305\u542b\u7684 tick \u6570\u91cf\u3002\u5728\u6b64\u7cfb\u7edf\u4e2d\uff0c1 tick = 1/4 beat</li> <li>\u793a\u4f8b: <code>--ticks_per_beat 8</code></li> </ul>"},{"location":"real-time-inference/parameter/#-beats_per_bar","title":"<code>--beats_per_bar</code>","text":"<ul> <li>\u7c7b\u578b: \u6574\u6570</li> <li>\u9ed8\u8ba4\u503c: <code>4</code></li> <li>\u8bf4\u660e: \u6bcf\u5c0f\u8282\u5305\u542b\u7684\u8282\u62cd\u6570\u91cf</li> <li>\u793a\u4f8b: <code>--beats_per_bar 3</code> (3/4 \u62cd\u5b50)</li> </ul>"},{"location":"real-time-inference/parameter/#-generation_interval_ticks","title":"<code>--generation_interval_ticks</code>","text":"<ul> <li>\u7c7b\u578b: \u6574\u6570</li> <li>\u9ed8\u8ba4\u503c: <code>2</code></li> <li>\u8bf4\u660e: \u97f3\u4e50\u751f\u6210\u8bf7\u6c42\u4e4b\u95f4\u7684\u95f4\u9694\uff0c\u5355\u4f4d\u4e3a tick</li> <li>\u793a\u4f8b: <code>--generation_interval_ticks 4</code></li> </ul>"},{"location":"real-time-inference/parameter/#_5","title":"\u663e\u793a\u53c2\u6570","text":""},{"location":"real-time-inference/parameter/#-log_lines","title":"<code>--log_lines</code>","text":"<ul> <li>\u7c7b\u578b: \u6574\u6570</li> <li>\u9ed8\u8ba4\u503c: <code>10</code></li> <li>\u8bf4\u660e: \u63a7\u5236\u53f0\u663e\u793a\u7684\u65e5\u5fd7\u884c\u6570</li> <li>\u793a\u4f8b: <code>--log_lines 20</code></li> </ul>"},{"location":"real-time-inference/parameter/#-metronome","title":"<code>--metronome</code>","text":"<ul> <li>\u7c7b\u578b: \u5f00\u5173</li> <li>\u9ed8\u8ba4\u503c: <code>False</code></li> <li>\u8bf4\u660e: \u542f\u7528\u53ef\u542c\u89c1\u7684 MIDI \u8282\u62cd\u5668\u58f0\u97f3</li> <li>\u793a\u4f8b: <code>--metronome</code></li> </ul>"},{"location":"real-time-inference/parameter/#midi","title":"MIDI \u8f93\u5165\u8f93\u51fa\u53c2\u6570","text":""},{"location":"real-time-inference/parameter/#-midi_output_name","title":"<code>--midi_output_name</code>","text":"<ul> <li>\u7c7b\u578b: \u5b57\u7b26\u4e32</li> <li>\u9ed8\u8ba4\u503c: <code>None</code> (\u81ea\u52a8\u9009\u62e9)</li> <li>\u8bf4\u660e: \u6307\u5b9a MIDI \u8f93\u51fa\u7aef\u53e3\u540d\u79f0</li> <li>\u793a\u4f8b: <code>--midi_output_name \"MIDI Out 1\"</code></li> </ul>"},{"location":"real-time-inference/parameter/#-midi_input_name","title":"<code>--midi_input_name</code>","text":"<ul> <li>\u7c7b\u578b: \u5b57\u7b26\u4e32</li> <li>\u9ed8\u8ba4\u503c: <code>None</code> (\u81ea\u52a8\u9009\u62e9\u7b2c\u4e00\u4e2a\u53ef\u7528\u7aef\u53e3)</li> <li>\u8bf4\u660e: \u6307\u5b9a MIDI \u8f93\u5165\u7aef\u53e3\u540d\u79f0</li> <li>\u793a\u4f8b: <code>--midi_input_name \"Digital Piano\"</code></li> </ul>"},{"location":"real-time-inference/parameter/#-accompaniment-velocity","title":"<code>--accompaniment-velocity</code>","text":"<ul> <li>\u7c7b\u578b: \u6574\u6570</li> <li>\u9ed8\u8ba4\u503c: <code>50</code></li> <li>\u8303\u56f4: <code>0-127</code></li> <li>\u8bf4\u660e: \u751f\u6210\u7684\u4f34\u594f\u97f3\u7b26\u7684 MIDI \u529b\u5ea6\u503c</li> <li>\u793a\u4f8b: <code>--accompaniment-velocity 80</code></li> </ul>"},{"location":"real-time-inference/parameter/#_6","title":"\u8f93\u5165\u6a21\u5f0f\u53c2\u6570","text":""},{"location":"real-time-inference/parameter/#-use-keyboard-input","title":"<code>--use-keyboard-input</code>","text":"<ul> <li>\u7c7b\u578b: \u5f00\u5173</li> <li>\u9ed8\u8ba4\u503c: <code>False</code></li> <li>\u8bf4\u660e: \u4f7f\u7528\u8ba1\u7b97\u673a\u952e\u76d8\u4f5c\u4e3a MIDI \u8f93\u5165\u8bbe\u5907</li> <li>\u793a\u4f8b: <code>--use-keyboard-input</code></li> <li>\u952e\u76d8\u6620\u5c04:</li> <li>\u767d\u952e: <code>a s d f g h j k l</code></li> <li>\u9ed1\u952e: <code>w e t y u</code></li> </ul>"},{"location":"real-time-inference/parameter/#-midi-file-input","title":"<code>--midi-file-input</code>","text":"<ul> <li>\u7c7b\u578b: \u5b57\u7b26\u4e32</li> <li>\u9ed8\u8ba4\u503c: <code>None</code></li> <li>\u8bf4\u660e: \u6307\u5b9a MIDI \u6587\u4ef6\u8def\u5f84\u6765\u6a21\u62df\u7528\u6237\u8f93\u5165</li> <li>\u793a\u4f8b: <code>--midi-file-input path/to/song.mid</code></li> </ul>"},{"location":"real-time-inference/parameter/#-midi-file-delay-ticks","title":"<code>--midi-file-delay-ticks</code>","text":"<ul> <li>\u7c7b\u578b: \u6574\u6570</li> <li>\u9ed8\u8ba4\u503c: <code>0</code></li> <li>\u8bf4\u660e: MIDI \u6587\u4ef6\u5f00\u59cb\u64ad\u653e\u524d\u7684\u5ef6\u8fdf tick \u6570</li> <li>\u793a\u4f8b: <code>--midi-file-delay-ticks 8</code></li> </ul>"},{"location":"real-time-inference/parameter/#-midi-file-use-original-duration","title":"<code>--midi-file-use-original-duration</code>","text":"<ul> <li>\u7c7b\u578b: \u5f00\u5173</li> <li>\u9ed8\u8ba4\u503c: <code>False</code></li> <li>\u8bf4\u660e: \u4f7f\u7528 MIDI \u6587\u4ef6\u4e2d\u7684\u539f\u59cb\u97f3\u7b26\u65f6\u957f\uff0c\u800c\u4e0d\u662f\u56fa\u5b9a\u65f6\u957f</li> <li>\u793a\u4f8b: <code>--midi-file-use-original-duration</code></li> </ul>"},{"location":"real-time-inference/parameter/#_7","title":"\u97f3\u4e50\u6ce8\u5165\u53c2\u6570","text":""},{"location":"real-time-inference/parameter/#-injection-file","title":"<code>--injection-file</code>","text":"<ul> <li>\u7c7b\u578b: \u5b57\u7b26\u4e32</li> <li>\u9ed8\u8ba4\u503c: <code>None</code></li> <li>\u8bf4\u660e: \u8981\u6ce8\u5165\u5230\u63a8\u7406\u5f15\u64ce\u5386\u53f2\u4e2d\u7684 MIDI \u6587\u4ef6\u8def\u5f84</li> <li>\u8981\u6c42: \u5fc5\u987b\u662f\u65cb\u5f8b\u6587\u4ef6 (\u5305\u542b \"mel\" \u7684\u8def\u5f84)\uff0c\u7cfb\u7edf\u4f1a\u81ea\u52a8\u5bfb\u627e\u5bf9\u5e94\u7684\u4f34\u594f\u6587\u4ef6</li> <li>\u793a\u4f8b: <code>--injection-file data/prompts/prelude_mel.mid</code></li> </ul>"},{"location":"real-time-inference/parameter/#-injection-length","title":"<code>--injection-length</code>","text":"<ul> <li>\u7c7b\u578b: \u6574\u6570</li> <li>\u9ed8\u8ba4\u503c: <code>0</code></li> <li>\u8bf4\u660e: \u4ece\u6ce8\u5165\u6587\u4ef6\u4e2d\u6ce8\u5165\u7684 tick \u6570\u91cf</li> <li>\u8981\u6c42: \u5f53\u6307\u5b9a <code>--injection-file</code> \u65f6\u5fc5\u987b\u4e3a\u6b63\u6570</li> <li>\u793a\u4f8b: <code>--injection-length 100</code></li> </ul>"},{"location":"real-time-inference/parameter/#_8","title":"\u4f7f\u7528\u793a\u4f8b","text":""},{"location":"real-time-inference/parameter/#_9","title":"\u57fa\u672c\u7528\u6cd5","text":"<pre><code># \u4f7f\u7528\u9ed8\u8ba4 MIDI \u8bbe\u5907\npython client.py\n\n# \u4f7f\u7528\u952e\u76d8\u8f93\u5165\uff0c120 BPM\npython client.py --use-keyboard-input --tempo 120\n\n# \u4f7f\u7528 MIDI \u6587\u4ef6\u8f93\u5165\uff0c\u5ef6\u8fdf 8 tick\npython client.py --midi-file-input song.mid --midi-file-delay-ticks 8\n\n# \u542f\u7528\u8282\u62cd\u5668\u548c\u66f4\u9ad8\u7684\u4f34\u594f\u529b\u5ea6\npython client.py --metronome --accompaniment-velocity 80\n</code></pre>"},{"location":"real-time-inference/parameter/#_10","title":"\u97f3\u4e50\u6ce8\u5165\u793a\u4f8b","text":"<pre><code># \u6ce8\u5165\u524d\u594f\u7136\u540e\u4f7f\u7528\u9ed8\u8ba4 MIDI \u8bbe\u5907\u8f93\u5165\u5e76\u542f\u7528\u8282\u62cd\u5668\npython client.py --injection-file prompt_mel.mid --injection-length 50 --use-keyboard-input --metronome\n\n# \u6ce8\u5165\u524d\u594f\u7136\u540e\u4f7f\u7528\u952e\u76d8\u8f93\u5165\u5e76\u542f\u7528\u8282\u62cd\u5668\npython client.py --injection-file prompt_mel.mid --injection-length 50 --use-keyboard-input --metronome\n\n# \u6ce8\u5165\u540e\u4f7f\u7528 MIDI \u6587\u4ef6\u7ee7\u7eed\u5e76\u542f\u7528\u8282\u62cd\u5668\npython client.py --injection-file prompt_mel.mid --injection-length 100 --midi-file-input continuation.mid --metronome\n</code></pre>"},{"location":"real-time-inference/parameter/#_11","title":"\u9ad8\u7ea7\u914d\u7f6e","text":"<pre><code># \u81ea\u5b9a\u4e49\u8282\u62cd\u548c\u751f\u6210\u95f4\u9694\npython client.py --beats_per_bar 3 --ticks_per_beat 8 --generation_interval_ticks 4\n\n# \u6307\u5b9a\u7279\u5b9a\u7684 MIDI \u7aef\u53e3\npython client.py --midi_input_name \"Piano\" --midi_output_name \"Speakers\"\n\n# \u8fde\u63a5\u5230\u8fdc\u7a0b\u670d\u52a1\u5668\npython client.py --server_url http://192.168.1.100:8988/generate_accompaniment\n</code></pre>"},{"location":"real-time-inference/parameter/#_12","title":"\u6ce8\u610f\u4e8b\u9879","text":"<ol> <li>\u97f3\u4e50\u6ce8\u5165: \u6ce8\u5165\u6587\u4ef6\u5fc5\u987b\u5305\u542b \"mel\" (\u65cb\u5f8b) \u548c\u5bf9\u5e94\u7684 \"acc\" (\u4f34\u594f) \u6587\u4ef6</li> <li>\u65f6\u95f4\u5355\u4f4d: \u7cfb\u7edf\u4e2d 1 tick = 1/4 beat</li> <li>\u6587\u4ef6\u8f93\u51fa: \u6bcf\u6b21\u4f1a\u8bdd\u90fd\u4f1a\u5728 <code>app/logs/session_TIMESTAMP/</code> \u76ee\u5f55\u4e0b\u751f\u6210\u65e5\u5fd7\u6587\u4ef6</li> <li>\u952e\u76d8\u9000\u51fa: \u4f7f\u7528 <code>Ctrl+C</code> \u5b89\u5168\u9000\u51fa\u7a0b\u5e8f\u5e76\u4fdd\u5b58\u6240\u6709\u4f1a\u8bdd\u6570\u636e</li> </ol>"},{"location":"real-time-inference/parameter/#_13","title":"\u8f93\u51fa\u6587\u4ef6","text":"<p>\u7a0b\u5e8f\u8fd0\u884c\u7ed3\u675f\u540e\u4f1a\u5728\u4f1a\u8bdd\u76ee\u5f55\u4e2d\u751f\u6210\uff1a - <code>performance.mid</code>: \u5b8c\u6574\u7684\u7528\u6237\u8f93\u5165\u548c\u6a21\u578b\u751f\u6210\u7684 MIDI \u6587\u4ef6 - <code>prompt.mid</code>: \u6ce8\u5165\u7684 prompt MIDI \u6587\u4ef6 (\u5982\u679c\u4f7f\u7528\u4e86\u6ce8\u5165\u529f\u80fd) - <code>inferences.json</code>: \u8be6\u7ec6\u7684\u63a8\u7406\u65e5\u5fd7 - <code>session.csv</code>: \u4fdd\u5b58\u63a8\u7406\u65f6\u95f4\u3001latency \u7b49\u6570\u636e\u7684\u7edf\u8ba1\u6587\u4ef6 - <code>session.txt</code>: \u4fdd\u5b58\u63a8\u7406\u65f6\u95f4\u3001latency \u7b49\u6570\u636e\u7684 summary</p>"},{"location":"real-time-inference/quickstart/","title":"\u5feb\u901f\u5f00\u59cb","text":"<p>\u672c\u6307\u5357\u5c06\u5e2e\u52a9\u60a8\u5feb\u901f\u90e8\u7f72\u548c\u8fd0\u884c Real-Time Inference System\u3002</p>"},{"location":"real-time-inference/quickstart/#_2","title":"\u524d\u7f6e\u8981\u6c42","text":"<ul> <li>UV \u5305\u7ba1\u7406\u5de5\u5177</li> </ul>"},{"location":"real-time-inference/quickstart/#_3","title":"\u5b89\u88c5","text":""},{"location":"real-time-inference/quickstart/#_4","title":"\u514b\u9686\u4ed3\u5e93","text":"<pre><code>git clone https://github.com/AHY123/StreamMUSE.git\n</code></pre>"},{"location":"real-time-inference/quickstart/#_5","title":"\u542f\u52a8\u670d\u52a1","text":"<p>\u672c\u7cfb\u7edf\u6709 Server \u7aef\u548c Client \u7aef\uff0c\u6240\u4ee5\u9700\u8981\u8fd0\u884c\u4e24\u4e2a\u7a0b\u5e8f\u3002</p>"},{"location":"real-time-inference/quickstart/#server","title":"Server \u7aef","text":"<p>\u4e00\u4e0b\u64cd\u4f5c\u90fd\u5728 Server \u7aef\u7684 terminal \u5185\u8fdb\u884c\u3002</p>"},{"location":"real-time-inference/quickstart/#_6","title":"\u8bbe\u7f6e\u73af\u5883\u53d8\u91cf","text":"<p>\u9996\u5148\u6211\u4eec\u9700\u8981\u8bbe\u7f6e\u5fc5\u987b\u7684\u73af\u5883\u53d8\u91cf\uff1a</p> <ul> <li> <p><code>CHECKPOINT_PATH</code> \u8bbe\u7f6e\u4e3a\u4f60\u7684\u6a21\u578b checkpoint \u8def\u5f84</p> </li> <li> <p><code>MODEL_MAX_SEQ_LEN_FRAMES</code> \u8bbe\u7f6e\u4e3a inference window \u7684\u957f\u5ea6\uff0c\u4e5f\u5c31\u662f\u6a21\u578b\u6700\u591a\u53ef\u4ee5\u770b\u5230\u591a\u4e45\u7684\u97f3\u4e50\uff08\u5355\u4f4d\u662f tick\uff09</p> </li> <li> <p><code>GENERATION_LENGTH_FRAMES</code> \u8bbe\u7f6e\u4e3a\u6bcf\u6b21 inference \u751f\u6210\u7684\u957f\u5ea6\uff08\u5355\u4f4d\u662f tick\uff09</p> </li> </ul> <pre><code>export CHECKPOINT_PATH=results/Baseline/cp_transformer_909+ac+1k7_trackemb_interleavepos_v0.2_large_batch_40_schedule.epoch=00.val_loss=0.90296.ckpt\nexport MODEL_MAX_SEQ_LEN_FRAMES=384\nexport GENERATION_LENGTH_FRAMES=6\n</code></pre>"},{"location":"real-time-inference/quickstart/#server_1","title":"\u542f\u52a8 Server \u7aef\u7a0b\u5e8f","text":"<pre><code>uv run -- uvicorn app.server:app --host 0.0.0.0 --port 8988\n</code></pre> <p>\u7b2c\u4e00\u6b21\u8fd0\u884c <code>uv run</code> \u7684\u65f6\u5019\uff0cUV \u5305\u7ba1\u7406\u5de5\u5177\u4f1a\u81ea\u52a8\u4e0b\u8f7d\u9700\u8981\u4e0b\u8f7d\u7684\u5305\u3002</p>"},{"location":"real-time-inference/quickstart/#port-forwarding","title":"Port Forwarding","text":"<p>\u5f53\u524d\u7248\u672c\u662f\u4f7f\u7528\u6700\u7b80\u5355\u7684\u65b9\u6cd5\u8fdb\u884c Server \u7aef\u4e0e Client \u7aef\u7684\u901a\u8baf\u7684\uff0c\u6211\u4eec\u7528 SSH \u628a Server \u7aef\u7684\u5bf9\u5e94\u7aef\u53e3\u6620\u5c04\u5230 Client \u8fd9\u8fb9\u7684\u4e00\u4e2a\u6307\u5b9a\u7aef\u53e3\u4e0a\uff0c\u7136\u540e\u6b63\u5e38\u8fd0\u884c\u7a0b\u5e8f\u3002</p> <p>\u5728\u4f60\u7684 Server terminal \u4e0a\uff0c\u8fd0\u884c\u4e00\u4e0b\u4ee3\u7801\uff1a</p> <pre><code>ssh -L 8000:localhost:8988 user@server_ip\n</code></pre> <p><code>user@server_ip</code> \u6362\u6210\u4f60\u5bf9\u5e94\u7684 username \u548c server ip\u3002</p>"},{"location":"real-time-inference/quickstart/#notes","title":"Notes","text":"<p>\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u5728\u505a port forwarding \u7684\u65f6\u5019\uff0c\u6709\u7684\u65f6\u5019\u6211\u4eec Server \u7aef\u7684\u7a0b\u5e8f\u5e76\u6ca1\u6709\u7ed1\u5728 localhost \u7aef\u53e3\u4e0a\uff0c\u5982\u679c\u6309\u7167\u4e0a\u9762\u7684\u65b9\u6cd5\u5c1d\u8bd5\u8fd0\u884c\u5931\u8d25\u4e86\uff0c\u8bd5\u4e00\u4e0b <code>hostname -i</code> \u547d\u4ee4\uff0c\u770b\u4e00\u4e0b Server \u7aef\u673a\u5668\u5bf9\u5e94\u7684 IP\uff0c\u7136\u540e\u628a localhost \u6362\u6210\u8fd9\u4e2a IP\u3002</p>"},{"location":"real-time-inference/quickstart/#client","title":"Client \u7aef","text":"<p>\u4ee5\u4e0b\u64cd\u4f5c\u90fd\u5728 Client terminal \u5185\u5b8c\u6210\u3002</p>"},{"location":"real-time-inference/quickstart/#set-up-synthesizer","title":"Set Up Synthesizer","text":"<p>\u672c\u9879\u76ee\u6211\u4eec\u7528\u7684 soundfont \u6587\u4ef6\u662f FluidR3_GM.sf2\uff0c\u6240\u4ee5\u9700\u8981\u5148\u4e0b\u8f7d\u8fd9\u4e2a\u6587\u4ef6\u3002</p> <p>\u4e0b\u5728\u5b8c\u6210\u540e\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4\uff0c\u6765\u6253\u5f00\u8fd0\u884c fluidsynth\u3002</p> <pre><code>fluidsynth 'PathToYourFluidR3_GMFile/FluidR3_GM.sf2'\n</code></pre>"},{"location":"real-time-inference/quickstart/#client_1","title":"\u542f\u52a8 Client \u7aef\u7a0b\u5e8f","text":"<p>Client \u7aef\u6709\u5f88\u591a\u53c2\u6570\u53ef\u4ee5\u9009\u62e9\uff0c\u6211\u8fd9\u91cc\u7ed9\u51fa\u51e0\u4e2a\u5e38\u7528\u7684\u4f8b\u5b50\uff1a</p> <pre><code>PYTHONPATH=\"$(pwd)\" uv run app/client.py --use-keyboard-input --metronome\n</code></pre> <p>\u8fd9\u884c\u547d\u4ee4\u8868\u793a\u4f60\u4f7f\u7528 computer keyboard \u8fdb\u884c\u8f93\u5165\uff0c\u540c\u65f6\u6253\u5f00\u4e86 metronome\u3002</p> <pre><code>PYTHONPATH=\"$(pwd)\" uv run app/client.py --injection-file input/mel/001.mid --injection-length 75 --metronome\n</code></pre> <p>\u8fd9\u884c\u547d\u4ee4\u8868\u793a\u4f60\u4f7f\u7528\u4e86 midi input\uff08\u9ed8\u8ba4\uff09\uff0c\u540c\u65f6 inject \u4e86\u4e00\u9996\u6b4c\uff0cinject \u7684\u957f\u5ea6\u662f 75 ticks\uff0c\u6253\u5f00\u4e86 metronome\u3002</p>"},{"location":"real-time-inference/quickstart/#notes_1","title":"Notes","text":"<p>\u4f60\u5728\u8fd0\u884c Client \u7a0b\u5e8f\u7684\u65f6\u5019\uff0c\u5982\u679c\u4f60\u7684\u7cfb\u7edf\u6b63\u786e\u8bc6\u522b\u4e86\u76f8\u5e94\u7684 port\uff0c\u7a0b\u5e8f\u4f1a\u628a\u76f8\u5e94\u7684 port \u6253\u5370\u51fa\u6765\uff0c\u4f60\u53ef\u80fd\u9700\u8981\u4eba\u5de5\u9009\u62e9 input port \u7528\u54ea\u4e2a\uff0coutput port \u7528\u54ea\u4e2a\uff0c \u673a\u5668\u81ea\u52a8 load \u53ef\u80fd\u4f1a\u51fa\u9519\u3002\u8be6\u60c5\u53ef\u4ee5\u67e5\u770b \u53c2\u6570\u6307\u5357\u3002</p>"},{"location":"real-time-inference/quickstart/#api","title":"\u6d4b\u8bd5API","text":"<pre><code>curl -X POST http://localhost:8080/predict \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"input\": \"your input data\"}'\n</code></pre>"},{"location":"real-time-inference/quickstart/#_7","title":"\u4e0b\u4e00\u6b65","text":"<ul> <li>\u67e5\u770b \u53c2\u6570\u6307\u5357 \u4e86\u89e3\u66f4\u8be6\u7ec6\u7684\u53c2\u6570\u914d\u7f6e</li> <li>\u67e5\u770b \u914d\u7f6e\u6307\u5357 \u4e86\u89e3\u8be6\u7ec6\u914d\u7f6e\u9009\u9879</li> <li>\u67e5\u770b API \u53c2\u8003 \u4e86\u89e3\u5b8c\u6574\u7684API\u6587\u6863</li> </ul>"},{"location":"training-framework/","title":"Documentation","text":"<p>English | \u4e2d\u6587</p> <p>Welcome to the Model Training Framework documentation! This directory contains comprehensive documentation for the framework, including architecture specifications, module guides, and usage examples.</p>"},{"location":"training-framework/#documentation-structure","title":"Documentation Structure","text":""},{"location":"training-framework/#project-architecture","title":"\ud83d\udccb Project Architecture","text":"<ul> <li>Project Specifications (\u4e2d\u6587) - Project folder and file naming conventions, design principles</li> <li>Project Specifications (English) - English version of project specifications</li> </ul>"},{"location":"training-framework/#module-documentation","title":"\ud83d\udcda Module Documentation","text":"<ul> <li>Modules Overview (\u4e2d\u6587) - Index of all framework modules in Chinese</li> <li>Modules Overview (English) - Index of all framework modules in English</li> </ul>"},{"location":"training-framework/#core-modules","title":"Core Modules","text":"<ul> <li>Model Module - Core model abstraction layer</li> <li>Network Module - Neural network architecture definitions</li> <li>Dataset Module - Data loading and preprocessing</li> </ul>"},{"location":"training-framework/#tool-modules","title":"Tool Modules","text":"<ul> <li>Callback Module - Training callbacks and hooks</li> <li>DataModule Module - Data module management</li> <li>Logger Module - Experiment logging and tracking</li> <li>LR Scheduler Module - Learning rate scheduling</li> <li>Optimizer Module - Model optimization algorithms</li> <li>Trainer Module - Training process configuration</li> <li>Utils Module - Utility functions and base classes</li> <li>Project Module - Project management and orchestration</li> <li>Metric Module - Metrics calculation and monitoring</li> </ul>"},{"location":"training-framework/#quick-start","title":"Quick Start","text":"<ol> <li>New to the framework? Start with the Project Specifications to understand the design principles</li> <li>Looking for specific modules? Check the Modules Overview for detailed guides</li> <li>Need implementation examples? Each module contains usage examples and configuration samples</li> </ol>"},{"location":"training-framework/#language-support","title":"Language Support","text":"<p>All documentation is available in both languages:</p> <ul> <li>\ud83c\udde8\ud83c\uddf3 Chinese (\u4e2d\u6587): <code>README_zh.md</code> files</li> <li>\ud83c\uddfa\ud83c\uddf8 English: <code>README.md</code> files</li> </ul>"},{"location":"training-framework/#contributing-to-documentation","title":"Contributing to Documentation","text":"<p>We welcome contributions to improve the documentation! Here's how you can help:</p>"},{"location":"training-framework/#for-module-documentation","title":"For Module Documentation","text":"<ol> <li>Navigate to the specific module directory under <code>modules/</code></li> <li>Edit the corresponding <code>README.md</code> (English) or <code>README_zh.md</code> (Chinese)</li> <li>Follow the established format and include:</li> <li>Module overview and purpose</li> <li>Directory structure</li> <li>Core components and APIs</li> <li>Usage examples</li> <li>Extension guidelines</li> </ol>"},{"location":"training-framework/#for-general-documentation","title":"For General Documentation","text":"<ol> <li>Edit files in the root <code>docs/</code> directory</li> <li>Maintain consistency with existing documentation style</li> <li>Update links and references as needed</li> </ol>"},{"location":"training-framework/#guidelines","title":"Guidelines","text":"<ul> <li>Keep technical content accurate and up-to-date</li> <li>Include code examples where helpful</li> <li>Use clear, concise language</li> <li>Test links and cross-references</li> <li>Follow Markdown best practices</li> </ul>"},{"location":"training-framework/#support","title":"Support","text":"<p>If you have questions about the documentation or need help with the framework:</p> <ul> <li>Check the Modules Overview for detailed guides</li> <li>Review the Project Specifications for design principles</li> <li>Explore the source code in the <code>src/</code> directory for implementation details</li> </ul> <p>This documentation is maintained by the Model Training Framework development team.</p>"},{"location":"training-framework/index_zh/","title":"Training Framework \u6982\u8ff0","text":"<p>English | \u4e2d\u6587</p> <p>\u6b22\u8fce\u6765\u5230\u6a21\u578b\u8bad\u7ec3\u6846\u67b6\u6587\u6863\uff01\u6b64\u76ee\u5f55\u5305\u542b\u6846\u67b6\u7684\u5b8c\u6574\u6587\u6863\uff0c\u5305\u62ec\u67b6\u6784\u89c4\u8303\u3001\u6a21\u5757\u6307\u5357\u548c\u4f7f\u7528\u793a\u4f8b\u3002</p>"},{"location":"training-framework/index_zh/#_1","title":"\u6587\u6863\u7ed3\u6784","text":""},{"location":"training-framework/index_zh/#_2","title":"\ud83d\udccb \u9879\u76ee\u67b6\u6784","text":"<ul> <li>\u9879\u76ee\u89c4\u8303 (\u4e2d\u6587) - \u9879\u76ee\u6587\u4ef6\u5939\u548c\u6587\u4ef6\u547d\u540d\u89c4\u8303\u3001\u8bbe\u8ba1\u539f\u5219</li> <li>\u9879\u76ee\u89c4\u8303 (English) - \u9879\u76ee\u89c4\u8303\u7684\u82f1\u6587\u7248\u672c</li> </ul>"},{"location":"training-framework/index_zh/#_3","title":"\ud83d\udcda \u6a21\u5757\u6587\u6863","text":"<ul> <li>\u6a21\u5757\u6982\u89c8 (\u4e2d\u6587) - \u6240\u6709\u6846\u67b6\u6a21\u5757\u7684\u4e2d\u6587\u7d22\u5f15</li> <li>\u6a21\u5757\u6982\u89c8 (English) - \u6240\u6709\u6846\u67b6\u6a21\u5757\u7684\u82f1\u6587\u7d22\u5f15</li> </ul>"},{"location":"training-framework/index_zh/#_4","title":"\u6838\u5fc3\u6a21\u5757","text":"<ul> <li>\u6a21\u578b\u6a21\u5757 - \u6838\u5fc3\u6a21\u578b\u62bd\u8c61\u5c42</li> <li>\u7f51\u7edc\u6a21\u5757 - \u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u5b9a\u4e49</li> <li>\u6570\u636e\u96c6\u6a21\u5757 - \u6570\u636e\u52a0\u8f7d\u548c\u9884\u5904\u7406</li> </ul>"},{"location":"training-framework/index_zh/#_5","title":"\u5de5\u5177\u6a21\u5757","text":"<ul> <li>\u56de\u8c03\u6a21\u5757 - \u8bad\u7ec3\u56de\u8c03\u548c\u94a9\u5b50</li> <li>\u6570\u636e\u6a21\u5757 - \u6570\u636e\u6a21\u5757\u7ba1\u7406</li> <li>\u65e5\u5fd7\u5668\u6a21\u5757 - \u5b9e\u9a8c\u65e5\u5fd7\u548c\u8ddf\u8e2a</li> <li>\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\u6a21\u5757 - \u5b66\u4e60\u7387\u8c03\u5ea6</li> <li>\u4f18\u5316\u5668\u6a21\u5757 - \u6a21\u578b\u4f18\u5316\u7b97\u6cd5</li> <li>\u8bad\u7ec3\u5668\u6a21\u5757 - \u8bad\u7ec3\u8fc7\u7a0b\u914d\u7f6e</li> <li>\u5de5\u5177\u6a21\u5757 - \u5de5\u5177\u51fd\u6570\u548c\u57fa\u7c7b</li> <li>\u9879\u76ee\u6a21\u5757 - \u9879\u76ee\u7ba1\u7406\u548c\u7f16\u6392</li> <li>\u6307\u6807\u6a21\u5757 - \u6307\u6807\u8ba1\u7b97\u548c\u76d1\u63a7</li> </ul>"},{"location":"training-framework/index_zh/#_6","title":"\u5feb\u901f\u5f00\u59cb","text":"<ol> <li>\u60f3\u8981\u7acb\u523b\u4e0a\u624b\u8bad\u7ec3\uff1f \u4ece\u5feb\u901f\u5f00\u59cb\u76f4\u63a5\u4e0a\u624b\u8bad\u7ec3\u6a21\u578b</li> <li>\u521d\u6b21\u4f7f\u7528\u6846\u67b6\uff1f \u4ece\u9879\u76ee\u89c4\u8303\u5f00\u59cb\u4e86\u89e3\u8bbe\u8ba1\u539f\u5219</li> <li>\u67e5\u627e\u7279\u5b9a\u6a21\u5757\uff1f \u67e5\u770b\u6a21\u5757\u6982\u89c8\u83b7\u53d6\u8be6\u7ec6\u6307\u5357</li> <li>\u9700\u8981\u5b9e\u73b0\u793a\u4f8b\uff1f \u6bcf\u4e2a\u6a21\u5757\u90fd\u5305\u542b\u4f7f\u7528\u793a\u4f8b\u548c\u914d\u7f6e\u6837\u672c</li> </ol>"},{"location":"training-framework/index_zh/#_7","title":"\u8bed\u8a00\u652f\u6301","text":"<p>\u6240\u6709\u6587\u6863\u90fd\u63d0\u4f9b\u53cc\u8bed\u7248\u672c\uff1a</p> <ul> <li>\ud83c\udde8\ud83c\uddf3 \u4e2d\u6587 (\u4e2d\u6587): <code>README_zh.md</code> \u6587\u4ef6</li> <li>\ud83c\uddfa\ud83c\uddf8 English: <code>README.md</code> \u6587\u4ef6</li> </ul>"},{"location":"training-framework/index_zh/#_8","title":"\u8d21\u732e\u6587\u6863","text":"<p>\u6211\u4eec\u6b22\u8fce\u5927\u5bb6\u4e3a\u6539\u8fdb\u6587\u6863\u505a\u51fa\u8d21\u732e\uff01\u4ee5\u4e0b\u662f\u60a8\u53ef\u4ee5\u63d0\u4f9b\u5e2e\u52a9\u7684\u65b9\u5f0f\uff1a</p>"},{"location":"training-framework/index_zh/#_9","title":"\u6a21\u5757\u6587\u6863\u8d21\u732e","text":"<ol> <li>\u5bfc\u822a\u5230 <code>modules/</code> \u4e0b\u7684\u7279\u5b9a\u6a21\u5757\u76ee\u5f55</li> <li>\u7f16\u8f91\u76f8\u5e94\u7684 <code>README.md</code>\uff08\u82f1\u6587\uff09\u6216 <code>README_zh.md</code>\uff08\u4e2d\u6587\uff09</li> <li>\u9075\u5faa\u65e2\u5b9a\u683c\u5f0f\u5e76\u5305\u542b\uff1a</li> <li>\u6a21\u5757\u6982\u8ff0\u548c\u7528\u9014</li> <li>\u76ee\u5f55\u7ed3\u6784</li> <li>\u6838\u5fc3\u7ec4\u4ef6\u548cAPI</li> <li>\u4f7f\u7528\u793a\u4f8b</li> <li>\u6269\u5c55\u6307\u5357</li> </ol>"},{"location":"training-framework/index_zh/#_10","title":"\u901a\u7528\u6587\u6863\u8d21\u732e","text":"<ol> <li>\u7f16\u8f91\u6839 <code>docs/</code> \u76ee\u5f55\u4e2d\u7684\u6587\u4ef6</li> <li>\u4fdd\u6301\u4e0e\u73b0\u6709\u6587\u6863\u98ce\u683c\u7684\u4e00\u81f4\u6027</li> <li>\u6839\u636e\u9700\u8981\u66f4\u65b0\u94fe\u63a5\u548c\u5f15\u7528</li> </ol>"},{"location":"training-framework/index_zh/#_11","title":"\u6307\u5357","text":"<ul> <li>\u4fdd\u6301\u6280\u672f\u5185\u5bb9\u7684\u51c6\u786e\u6027\u548c\u65f6\u6548\u6027</li> <li>\u5728\u6709\u5e2e\u52a9\u7684\u5730\u65b9\u5305\u542b\u4ee3\u7801\u793a\u4f8b</li> <li>\u4f7f\u7528\u6e05\u6670\u7b80\u6d01\u7684\u8bed\u8a00</li> <li>\u6d4b\u8bd5\u94fe\u63a5\u548c\u4ea4\u53c9\u5f15\u7528</li> <li>\u9075\u5faaMarkdown\u6700\u4f73\u5b9e\u8df5</li> </ul>"},{"location":"training-framework/index_zh/#_12","title":"\u652f\u6301","text":"<p>\u5982\u679c\u60a8\u5bf9\u6587\u6863\u6709\u7591\u95ee\u6216\u9700\u8981\u6846\u67b6\u5e2e\u52a9\uff1a</p> <ul> <li>\u67e5\u770b\u6a21\u5757\u6982\u89c8\u83b7\u53d6\u8be6\u7ec6\u6307\u5357</li> <li>\u5ba1\u67e5\u9879\u76ee\u89c4\u8303\u4e86\u89e3\u8bbe\u8ba1\u539f\u5219</li> <li>\u63a2\u7d22 <code>src/</code> \u76ee\u5f55\u4e2d\u7684\u6e90\u4ee3\u7801\u4e86\u89e3\u5b9e\u73b0\u7ec6\u8282</li> </ul> <p>\u6b64\u6587\u6863\u7531\u6a21\u578b\u8bad\u7ec3\u6846\u67b6\u5f00\u53d1\u56e2\u961f\u7ef4\u62a4\u3002</p>"},{"location":"training-framework/project-structure/","title":"Project Specifications","text":"<p>English | \u4e2d\u6587</p>"},{"location":"training-framework/project-structure/#folder-specifications","title":"Folder Specifications","text":"<ul> <li><code>_xxx</code>: Utility classes, commonly used and relatively stable</li> <li><code>xxx</code>: Core business classes</li> <li><code>xxx_</code>: Temporary classes, for temporary use</li> </ul>"},{"location":"training-framework/project-structure/#file-specifications","title":"File Specifications","text":"<ul> <li><code>${component}/${type}</code> structure:</li> <li><code>component.py</code>: Implementation class for ${type} type business component</li> <li><code>config.py</code>: Configuration class for ${type} type business component implementation<ul> <li>Usually needs to include <code>_target_</code> field for automatic instantiation</li> <li><code>Config</code> suffix: Component class can be passed directly during instantiation, corresponding to automatic instantiation method <code>get_class + cls(config)</code></li> <li><code>Params</code> suffix: Configuration parameter class that supports direct component instantiation via <code>hydra.instantiate</code>, without manual field conversion</li> </ul> </li> </ul>"},{"location":"training-framework/project-structure_zh/","title":"\u9879\u76ee\u89c4\u8303","text":"<p>English | \u4e2d\u6587</p>"},{"location":"training-framework/project-structure_zh/#_2","title":"\u6587\u4ef6\u5939\u89c4\u8303","text":"<ul> <li><code>_xxx</code>: \u5de5\u5177\u7c7b\uff0c\u5e38\u7528\u4e0d\u5e38\u6539</li> <li><code>xxx</code>: \u6b63\u5e38\u4e1a\u52a1\u7c7b</li> <li><code>xxx_</code>: \u6682\u7528\u7c7b\uff0c\u4e34\u65f6\u4f7f\u7528\u7684\uff0c\u6216\u8005\u662f\u5b9e\u9a8c\u4e3b\u8981\u5f00\u53d1\u7684\u7ec4\u4ef6</li> </ul>"},{"location":"training-framework/project-structure_zh/#_3","title":"\u6587\u4ef6\u89c4\u8303","text":"<ul> <li><code>${component}/${type}</code> \u7ed3\u6784\uff1a</li> <li><code>component.py</code>: type\u4e1a\u52a1\u7684component\u7684\u5b9e\u73b0\u7c7b</li> <li><code>config.py</code>: type\u4e1a\u52a1\u7684component\u5b9e\u73b0\u7c7b\u7684\u914d\u7f6e\u7c7b<ul> <li>\u4e00\u822c\u9700\u8981\u5305\u542b <code>_target_</code> \u7528\u4e8e\u81ea\u52a8\u521b\u5efa</li> <li><code>Config</code> \u7ed3\u5c3e\uff1acomponent\u7c7b\u5b9e\u4f8b\u5316\u53ef\u76f4\u63a5\u4f20\u5165\uff0c\u5bf9\u5e94\u81ea\u52a8\u5b9e\u4f8b\u5316\u65b9\u6cd5 <code>get_class + cls(config)</code></li> <li><code>Params</code> \u7ed3\u5c3e\uff1acomponent\u7c7b\u9700\u8981\u5c06 <code>_target_</code> \u53bb\u6389\u540e\uff0c\u5c06field\u8f6c\u4e3adict\u5e76 <code>**</code> \u89e3\u6790\uff0c\u53ef\u5229\u7528 <code>instantiate</code></li> </ul> </li> </ul>"},{"location":"training-framework/quickstart_zh/","title":"\u5feb\u901f\u5f00\u59cb","text":""},{"location":"training-framework/modules/","title":"Module Documentation Index","text":"<p>English | \u4e2d\u6587</p> <p>This directory contains detailed documentation for all modules in the model training framework.</p>"},{"location":"training-framework/modules/#core-modules","title":"Core Modules","text":""},{"location":"training-framework/modules/#model-module","title":"Model Module","text":"<p>The model module is the core abstraction layer of the deep learning training framework, built on PyTorch Lightning.</p>"},{"location":"training-framework/modules/#network-module","title":"Network Module","text":"<p>The network module focuses on neural network architecture definitions.</p>"},{"location":"training-framework/modules/#dataset-module","title":"Dataset Module","text":"<p>The dataset module focuses on unified management of data loading, preprocessing, and model input.</p>"},{"location":"training-framework/modules/#tool-modules","title":"Tool Modules","text":""},{"location":"training-framework/modules/#callback-module","title":"Callback Module","text":"<p>The callback module focuses on callback function configuration during PyTorch Lightning training.</p>"},{"location":"training-framework/modules/#datamodule-module","title":"DataModule Module","text":"<p>The datamodule focuses on data loading and preparation, decoupled from training logic.</p>"},{"location":"training-framework/modules/#logger-module","title":"Logger Module","text":"<p>The logger module focuses on experiment logging and management.</p>"},{"location":"training-framework/modules/#lr-scheduler-module","title":"LR Scheduler Module","text":"<p>The learning rate scheduler module focuses on learning rate adjustment strategies during training.</p>"},{"location":"training-framework/modules/#optimizer-module","title":"Optimizer Module","text":"<p>The optimizer module focuses on configuration and management of model parameter optimization.</p>"},{"location":"training-framework/modules/#trainer-module","title":"Trainer Module","text":"<p>The trainer module focuses on PyTorch Lightning Trainer configuration and management.</p>"},{"location":"training-framework/modules/#utils-module","title":"Utils Module","text":"<p>The utils module provides general configuration base classes and utility functions.</p>"},{"location":"training-framework/modules/#project-module","title":"Project Module","text":"<p>The project module focuses on the organization and execution of the entire training project.</p>"},{"location":"training-framework/modules/#metric-module","title":"Metric Module","text":"<p>The metric module focuses on metric calculation, recording, and management.</p>"},{"location":"training-framework/modules/#documentation-navigation","title":"Documentation Navigation","text":"<ul> <li>Project Architecture Specification - Overall project specifications and architecture description</li> <li>Quick Start - Project usage guide</li> <li>Configuration Examples - Configuration examples and instructions</li> </ul>"},{"location":"training-framework/modules/#contribution-guidelines","title":"Contribution Guidelines","text":"<p>To add or update documentation for a specific module, please:</p> <ol> <li>Edit the <code>README.md</code> in the corresponding module folder</li> <li>Maintain consistency in documentation format</li> <li>Update the links in this index file</li> <li>Submit a Pull Request for review</li> </ol>"},{"location":"training-framework/modules/index_zh/","title":"\u6a21\u5757\u6587\u6863\u7d22\u5f15","text":"<p>English | \u4e2d\u6587</p> <p>\u672c\u76ee\u5f55\u5305\u542b\u4e86\u6a21\u578b\u8bad\u7ec3\u6846\u67b6\u6240\u6709\u6a21\u5757\u7684\u8be6\u7ec6\u6587\u6863\u8bf4\u660e\u3002</p>"},{"location":"training-framework/modules/index_zh/#_2","title":"\u6838\u5fc3\u6a21\u5757","text":""},{"location":"training-framework/modules/index_zh/#model-module","title":"Model Module","text":"<p>\u6a21\u578b\u6a21\u5757\u662f\u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u6846\u67b6\u7684\u6838\u5fc3\u62bd\u8c61\u5c42\uff0c\u57fa\u4e8e PyTorch Lightning \u6784\u5efa\u3002</p>"},{"location":"training-framework/modules/index_zh/#network-module","title":"Network Module","text":"<p>\u7f51\u7edc\u6a21\u5757\u4e13\u6ce8\u4e8e\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u7684\u5b9a\u4e49\u3002</p>"},{"location":"training-framework/modules/index_zh/#dataset-module","title":"Dataset Module","text":"<p>\u6570\u636e\u96c6\u6a21\u5757\u4e13\u6ce8\u4e8e\u6570\u636e\u52a0\u8f7d\u3001\u9884\u5904\u7406\u548c\u6a21\u578b\u8f93\u5165\u7684\u7edf\u4e00\u7ba1\u7406\u3002</p>"},{"location":"training-framework/modules/index_zh/#_3","title":"\u5de5\u5177\u6a21\u5757","text":""},{"location":"training-framework/modules/index_zh/#callback-module","title":"Callback Module","text":"<p>\u56de\u8c03\u6a21\u5757\u4e13\u6ce8\u4e8e PyTorch Lightning \u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u56de\u8c03\u529f\u80fd\u914d\u7f6e\u3002</p>"},{"location":"training-framework/modules/index_zh/#datamodule-module","title":"DataModule Module","text":"<p>\u6570\u636e\u6a21\u5757\u4e13\u6ce8\u4e8e\u6570\u636e\u52a0\u8f7d\u548c\u51c6\u5907\uff0c\u4e0e\u8bad\u7ec3\u903b\u8f91\u89e3\u8026\u3002</p>"},{"location":"training-framework/modules/index_zh/#logger-module","title":"Logger Module","text":"<p>\u65e5\u5fd7\u5668\u6a21\u5757\u4e13\u6ce8\u4e8e\u5b9e\u9a8c\u65e5\u5fd7\u8bb0\u5f55\u548c\u7ba1\u7406\u3002</p>"},{"location":"training-framework/modules/index_zh/#lr-scheduler-module","title":"LR Scheduler Module","text":"<p>\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\u6a21\u5757\u4e13\u6ce8\u4e8e\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u5b66\u4e60\u7387\u8c03\u6574\u7b56\u7565\u3002</p>"},{"location":"training-framework/modules/index_zh/#optimizer-module","title":"Optimizer Module","text":"<p>\u4f18\u5316\u5668\u6a21\u5757\u4e13\u6ce8\u4e8e\u6a21\u578b\u53c2\u6570\u4f18\u5316\u7684\u914d\u7f6e\u548c\u7ba1\u7406\u3002</p>"},{"location":"training-framework/modules/index_zh/#trainer-module","title":"Trainer Module","text":"<p>\u8bad\u7ec3\u5668\u6a21\u5757\u4e13\u6ce8\u4e8e PyTorch Lightning Trainer \u7684\u914d\u7f6e\u548c\u7ba1\u7406\u3002</p>"},{"location":"training-framework/modules/index_zh/#utils-module","title":"Utils Module","text":"<p>\u5de5\u5177\u6a21\u5757\u63d0\u4f9b\u901a\u7528\u7684\u914d\u7f6e\u57fa\u7840\u7c7b\u548c\u5de5\u5177\u51fd\u6570\u3002</p>"},{"location":"training-framework/modules/index_zh/#project-module","title":"Project Module","text":"<p>\u9879\u76ee\u6a21\u5757\u4e13\u6ce8\u4e8e\u6574\u4e2a\u8bad\u7ec3\u9879\u76ee\u7684\u7ec4\u7ec7\u548c\u6267\u884c\u3002</p>"},{"location":"training-framework/modules/index_zh/#metric-module","title":"Metric Module","text":"<p>\u6307\u6807\u6a21\u5757\u4e13\u6ce8\u4e8e\u6307\u6807\u8ba1\u7b97\u3001\u8bb0\u5f55\u548c\u7ba1\u7406\u3002</p>"},{"location":"training-framework/modules/index_zh/#_4","title":"\u6587\u6863\u5bfc\u822a","text":"<ul> <li>\u9879\u76ee\u67b6\u6784\u89c4\u8303 - \u6574\u4f53\u9879\u76ee\u89c4\u8303\u548c\u67b6\u6784\u8bf4\u660e</li> <li>\u5feb\u901f\u5f00\u59cb - \u9879\u76ee\u4f7f\u7528\u6307\u5357</li> <li>\u914d\u7f6e\u8bf4\u660e - \u914d\u7f6e\u793a\u4f8b\u548c\u8bf4\u660e</li> </ul>"},{"location":"training-framework/modules/index_zh/#_5","title":"\u8d21\u732e\u6307\u5357","text":"<p>\u5982\u9700\u4e3a\u7279\u5b9a\u6a21\u5757\u6dfb\u52a0\u6216\u66f4\u65b0\u6587\u6863\uff0c\u8bf7\uff1a</p> <ol> <li>\u5728\u5bf9\u5e94\u7684\u6a21\u5757\u6587\u4ef6\u5939\u4e2d\u7f16\u8f91 <code>README_zh.md</code></li> <li>\u4fdd\u6301\u6587\u6863\u683c\u5f0f\u7684\u4e00\u81f4\u6027</li> <li>\u66f4\u65b0\u6b64\u7d22\u5f15\u6587\u4ef6\u4e2d\u7684\u94fe\u63a5</li> <li>\u63d0\u4ea4 Pull Request \u8fdb\u884c\u5ba1\u67e5</li> </ol>"},{"location":"training-framework/modules/callback/","title":"Callback Module","text":"<p>English | \u4e2d\u6587</p> <p>The callback module focuses on callback function configuration during PyTorch Lightning training processes, currently providing configuration support for training sample saving, model checkpointing, and early stopping functions.</p> <p>Note: This module is a tool class (prefixed with <code>_</code>), following the tool class definitions in the project specifications, commonly used but not frequently modified. For more information, please refer to the Project Architecture Specification.</p>"},{"location":"training-framework/modules/callback/#directory-structure","title":"Directory Structure","text":"<pre><code>_callback/\n\u251c\u2500\u2500 sample_saver/                  # Sample saving callback\n\u2502   \u251c\u2500\u2500 __init__.py               # Submodule initialization\n\u2502   \u251c\u2500\u2500 config.py                 # Sample saving configuration class\n\u2502   \u2514\u2500\u2500 callback.py               # Sample saving callback implementation\n\u251c\u2500\u2500 checkpoint/                   # Model checkpoint configuration\n\u2502   \u251c\u2500\u2500 __init__.py               # Submodule initialization\n\u2502   \u2514\u2500\u2500 config.py                 # Checkpoint configuration class\n\u251c\u2500\u2500 early_stopping/               # Early stopping configuration\n\u2502   \u251c\u2500\u2500 __init__.py               # Submodule initialization\n\u2502   \u2514\u2500\u2500 config.py                 # Early stopping configuration class\n\u251c\u2500\u2500 __init__.py                   # Module initialization and type definitions\n\u251c\u2500\u2500 README_zh.md                  # Chinese documentation\n\u2514\u2500\u2500 README.md                     # English documentation\n</code></pre>"},{"location":"training-framework/modules/callback/#core-components","title":"Core Components","text":""},{"location":"training-framework/modules/callback/#samplesavercallback","title":"SampleSaverCallback","text":"<p>Training sample saving callback - automatically saves key sample data during training:</p> <pre><code>class SampleSaverCallback(Callback):\n    \"\"\"\n    Training sample saving callback - used to save key content during training\n    \"\"\"\n    # Complete callback implementation supporting multiple data format saving\n</code></pre>"},{"location":"training-framework/modules/callback/#modelcheckpointparams","title":"ModelCheckpointParams","text":"<p>Model checkpoint configuration class - encapsulates all configurations of PyTorch Lightning ModelCheckpoint:</p> <pre><code>@dataclass\nclass ModelCheckpointParams:\n    \"\"\"ModelCheckpoint callback configuration class\"\"\"\n\n    _target_: str = Field(\n        default=\"pytorch_lightning.callbacks.ModelCheckpoint\"\n    )\n\n    # Basic saving configuration\n    dirpath: Optional[str] = Field(default=\"./checkpoints\")\n    filename: Optional[str] = Field(default=None)\n    monitor: Optional[str] = Field(default=None)\n    save_top_k: Union[int, Literal[-1]] = Field(default=1)\n    mode: Literal[\"min\", \"max\"] = Field(default=\"min\")\n\n    # More configuration options...\n</code></pre>"},{"location":"training-framework/modules/callback/#earlystoppingparams","title":"EarlyStoppingParams","text":"<p>Early stopping configuration class - encapsulates all configurations of PyTorch Lightning EarlyStopping:</p> <pre><code>@dataclass\nclass EarlyStoppingParams:\n    \"\"\"EarlyStopping callback configuration class\"\"\"\n\n    _target_: str = Field(\n        default=\"pytorch_lightning.callbacks.EarlyStopping\"\n    )\n\n    # Core monitoring configuration\n    monitor: str = Field(description=\"Name of the metric to monitor\")\n    patience: int = Field(default=3, description=\"Patience value\")\n    mode: Literal[\"min\", \"max\"] = Field(default=\"min\")\n    min_delta: Union[int, float] = Field(default=0.0)\n\n    # More configuration options...\n</code></pre>"},{"location":"training-framework/modules/callback/#main-features","title":"Main Features","text":""},{"location":"training-framework/modules/callback/#sample-saving-sample-saver","title":"Sample Saving (Sample Saver)","text":"<ul> <li>Multi-format support: Supports image, text, tensor, json, custom five saving formats</li> <li>Nested key access: Supports complex data structure nested access, such as <code>[\"model_output\", \"logits\"]</code></li> <li>Flexible configuration: Each saving key can have independent frequency, sample count, stage settings</li> <li>Directory structure: Supports multiple directory organization methods (flat, epoch, step, epoch_step)</li> </ul>"},{"location":"training-framework/modules/callback/#model-checkpoint-model-checkpoint","title":"Model Checkpoint (Model Checkpoint)","text":"<ul> <li>Multiple saving strategies: Supports saving based on metrics, time intervals, training steps</li> <li>Flexible filenames: Supports formatted strings such as <code>best-{epoch:02d}-{val_loss:.2f}</code></li> <li>Automatic management: Automatically saves the best N models, or regular backups</li> </ul>"},{"location":"training-framework/modules/callback/#early-stopping-early-stopping","title":"Early Stopping (Early Stopping)","text":"<ul> <li>Metric monitoring: Makes training stop decisions based on specified metrics</li> <li>Patience mechanism: Waits for a specified number of rounds when metrics no longer improve</li> <li>Flexible threshold: Supports minimum improvement threshold settings</li> </ul>"},{"location":"training-framework/modules/callback/README_zh/","title":"Callback Module","text":"<p>English | \u4e2d\u6587</p> <p>\u56de\u8c03\u6a21\u5757\u4e13\u6ce8\u4e8e PyTorch Lightning \u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u56de\u8c03\u529f\u80fd\u914d\u7f6e\uff0c\u76ee\u524d\u63d0\u4f9b\u8bad\u7ec3\u6837\u672c\u4fdd\u5b58\u3001\u6a21\u578b\u68c0\u67e5\u70b9\u548c\u65e9\u505c\u7b49\u529f\u80fd\u7684\u914d\u7f6e\u652f\u6301\u3002</p> <p>\u6ce8\u610f: \u6b64\u6a21\u5757\u4e3a\u5de5\u5177\u7c7b\uff08\u4ee5 <code>_</code> \u5f00\u5934\uff09\uff0c\u9075\u5faa\u9879\u76ee\u89c4\u8303\u4e2d\u5de5\u5177\u7c7b\u7684\u5b9a\u4e49\uff0c\u5e38\u7528\u4f46\u4e0d\u5e38\u4fee\u6539\u3002\u5982\u9700\u4e86\u89e3\u66f4\u591a\uff0c\u8bf7\u53c2\u8003 \u9879\u76ee\u67b6\u6784\u89c4\u8303\u3002</p>"},{"location":"training-framework/modules/callback/README_zh/#_1","title":"\u76ee\u5f55\u7ed3\u6784","text":"<pre><code>_callback/\n\u251c\u2500\u2500 sample_saver/                  # \u6837\u672c\u4fdd\u5b58\u56de\u8c03\n\u2502   \u251c\u2500\u2500 __init__.py               # \u5b50\u6a21\u5757\u521d\u59cb\u5316\n\u2502   \u251c\u2500\u2500 config.py                 # \u6837\u672c\u4fdd\u5b58\u914d\u7f6e\u7c7b\n\u2502   \u2514\u2500\u2500 callback.py               # \u6837\u672c\u4fdd\u5b58\u56de\u8c03\u5b9e\u73b0\n\u251c\u2500\u2500 checkpoint/                   # \u6a21\u578b\u68c0\u67e5\u70b9\u914d\u7f6e\n\u2502   \u251c\u2500\u2500 __init__.py               # \u5b50\u6a21\u5757\u521d\u59cb\u5316\n\u2502   \u2514\u2500\u2500 config.py                 # \u68c0\u67e5\u70b9\u914d\u7f6e\u7c7b\n\u251c\u2500\u2500 early_stopping/               # \u65e9\u505c\u914d\u7f6e\n\u2502   \u251c\u2500\u2500 __init__.py               # \u5b50\u6a21\u5757\u521d\u59cb\u5316\n\u2502   \u2514\u2500\u2500 config.py                 # \u65e9\u505c\u914d\u7f6e\u7c7b\n\u251c\u2500\u2500 __init__.py                   # \u6a21\u5757\u521d\u59cb\u5316\u548c\u7c7b\u578b\u5b9a\u4e49\n\u251c\u2500\u2500 README_zh.md                  # \u4e2d\u6587\u6587\u6863\n\u2514\u2500\u2500 README.md                     # \u82f1\u6587\u6587\u6863\n</code></pre>"},{"location":"training-framework/modules/callback/README_zh/#_2","title":"\u6838\u5fc3\u7ec4\u4ef6","text":""},{"location":"training-framework/modules/callback/README_zh/#samplesavercallback","title":"SampleSaverCallback","text":"<p>\u8bad\u7ec3\u6837\u672c\u4fdd\u5b58\u56de\u8c03 - \u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u81ea\u52a8\u4fdd\u5b58\u5173\u952e\u6837\u672c\u6570\u636e\uff1a</p> <pre><code>class SampleSaverCallback(Callback):\n    \"\"\"\n    \u8bad\u7ec3\u6837\u672c\u4fdd\u5b58\u56de\u8c03 - \u7528\u4e8e\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4fdd\u5b58\u5173\u952e\u5185\u5bb9\n    \"\"\"\n    # \u5b8c\u6574\u7684\u56de\u8c03\u5b9e\u73b0\uff0c\u652f\u6301\u591a\u79cd\u6570\u636e\u683c\u5f0f\u4fdd\u5b58\n</code></pre>"},{"location":"training-framework/modules/callback/README_zh/#modelcheckpointparams","title":"ModelCheckpointParams","text":"<p>\u6a21\u578b\u68c0\u67e5\u70b9\u914d\u7f6e\u7c7b - \u5c01\u88c5 PyTorch Lightning ModelCheckpoint \u7684\u6240\u6709\u914d\u7f6e\uff1a</p> <pre><code>@dataclass\nclass ModelCheckpointParams:\n    \"\"\"ModelCheckpoint \u56de\u8c03\u914d\u7f6e\u7c7b\"\"\"\n\n    _target_: str = Field(\n        default=\"pytorch_lightning.callbacks.ModelCheckpoint\"\n    )\n\n    # \u57fa\u672c\u4fdd\u5b58\u914d\u7f6e\n    dirpath: Optional[str] = Field(default=\"./checkpoints\")\n    filename: Optional[str] = Field(default=None)\n    monitor: Optional[str] = Field(default=None)\n    save_top_k: Union[int, Literal[-1]] = Field(default=1)\n    mode: Literal[\"min\", \"max\"] = Field(default=\"min\")\n\n    # \u66f4\u591a\u914d\u7f6e\u9009\u9879...\n</code></pre>"},{"location":"training-framework/modules/callback/README_zh/#earlystoppingparams","title":"EarlyStoppingParams","text":"<p>\u65e9\u505c\u914d\u7f6e\u7c7b - \u5c01\u88c5 PyTorch Lightning EarlyStopping \u7684\u6240\u6709\u914d\u7f6e\uff1a</p> <pre><code>@dataclass\nclass EarlyStoppingParams:\n    \"\"\"EarlyStopping \u56de\u8c03\u914d\u7f6e\u7c7b\"\"\"\n\n    _target_: str = Field(\n        default=\"pytorch_lightning.callbacks.EarlyStopping\"\n    )\n\n    # \u6838\u5fc3\u76d1\u63a7\u914d\u7f6e\n    monitor: str = Field(description=\"\u76d1\u63a7\u7684\u6307\u6807\u540d\u79f0\")\n    patience: int = Field(default=3, description=\"\u8010\u5fc3\u503c\")\n    mode: Literal[\"min\", \"max\"] = Field(default=\"min\")\n    min_delta: Union[int, float] = Field(default=0.0)\n\n    # \u66f4\u591a\u914d\u7f6e\u9009\u9879...\n</code></pre>"},{"location":"training-framework/modules/callback/README_zh/#_3","title":"\u4e3b\u8981\u529f\u80fd","text":""},{"location":"training-framework/modules/callback/README_zh/#sample-saver","title":"\u6837\u672c\u4fdd\u5b58 (Sample Saver)","text":"<ul> <li>\u591a\u683c\u5f0f\u652f\u6301\uff1a\u652f\u6301 image\u3001text\u3001tensor\u3001json\u3001custom \u4e94\u79cd\u4fdd\u5b58\u683c\u5f0f</li> <li>\u5d4c\u5957\u952e\u8bbf\u95ee\uff1a\u652f\u6301\u590d\u6742\u7684\u6570\u636e\u7ed3\u6784\u5d4c\u5957\u8bbf\u95ee\uff0c\u5982 <code>[\"model_output\", \"logits\"]</code></li> <li>\u7075\u6d3b\u914d\u7f6e\uff1a\u6bcf\u4e2a\u4fdd\u5b58\u952e\u53ef\u4ee5\u6709\u72ec\u7acb\u7684\u9891\u7387\u3001\u6837\u672c\u6570\u3001\u9636\u6bb5\u8bbe\u7f6e</li> <li>\u76ee\u5f55\u7ed3\u6784\uff1a\u652f\u6301\u591a\u79cd\u76ee\u5f55\u7ec4\u7ec7\u65b9\u5f0f\uff08flat\u3001epoch\u3001step\u3001epoch_step\uff09</li> </ul>"},{"location":"training-framework/modules/callback/README_zh/#model-checkpoint","title":"\u6a21\u578b\u68c0\u67e5\u70b9 (Model Checkpoint)","text":"<ul> <li>\u591a\u79cd\u4fdd\u5b58\u7b56\u7565\uff1a\u652f\u6301\u57fa\u4e8e\u6307\u6807\u3001\u65f6\u95f4\u95f4\u9694\u3001\u8bad\u7ec3\u6b65\u9aa4\u7684\u4fdd\u5b58</li> <li>\u7075\u6d3b\u6587\u4ef6\u540d\uff1a\u652f\u6301\u683c\u5f0f\u5316\u5b57\u7b26\u4e32\uff0c\u5982 <code>best-{epoch:02d}-{val_loss:.2f}</code></li> <li>\u81ea\u52a8\u7ba1\u7406\uff1a\u81ea\u52a8\u4fdd\u5b58\u6700\u597d\u7684 N \u4e2a\u6a21\u578b\uff0c\u6216\u5b9a\u671f\u5907\u4efd</li> </ul>"},{"location":"training-framework/modules/callback/README_zh/#early-stopping","title":"\u65e9\u505c (Early Stopping)","text":"<ul> <li>\u6307\u6807\u76d1\u63a7\uff1a\u57fa\u4e8e\u6307\u5b9a\u6307\u6807\u8fdb\u884c\u8bad\u7ec3\u505c\u6b62\u51b3\u7b56</li> <li>\u8010\u5fc3\u673a\u5236\uff1a\u5728\u6307\u6807\u4e0d\u518d\u6539\u5584\u65f6\u7b49\u5f85\u6307\u5b9a\u8f6e\u6570</li> <li>\u7075\u6d3b\u9608\u503c\uff1a\u652f\u6301\u6700\u5c0f\u6539\u5584\u9608\u503c\u8bbe\u7f6e</li> </ul>"},{"location":"training-framework/modules/datamodule/","title":"DataModule Module","text":"<p>English | \u4e2d\u6587</p> <p>The datamodule focuses on data loading and preparation, decoupled from training logic.</p> <p>Note: This module is a tool class (prefixed with <code>_</code>), following the tool class definitions in the project specifications, commonly used but not frequently modified. For more information, please refer to the Project Architecture Specification.</p>"},{"location":"training-framework/modules/datamodule/#directory-structure","title":"Directory Structure","text":"<pre><code>_datamodule/\n\u251c\u2500\u2500 base/              # Base datamodule abstract classes\n\u2502   \u251c\u2500\u2500 datamodule.py  # BaseDataModule base class\n\u2502   \u2514\u2500\u2500 config.py      # Datamodule configuration class\n\u2514\u2500\u2500 __init__.py        # Module initialization\n</code></pre>"},{"location":"training-framework/modules/datamodule/#core-components","title":"Core Components","text":""},{"location":"training-framework/modules/datamodule/#basedatamodule","title":"BaseDataModule","text":"<p>Base class for all datamodules, inherits from PyTorch Lightning's LightningDataModule, providing unified data loading interfaces:</p> <pre><code>class BaseDataModule(LightningDataModule, ABC):\n    def __init__(self, config: BaseDataModuleConfig):\n        super().__init__()\n        self.config = config\n\n    def setup(self, stage: Optional[str] = None):\n        \"\"\"Set up datamodule for training/validation/testing\"\"\"\n        pass\n\n    def train_dataloader(self) -&gt; DataLoader:\n        \"\"\"Return training dataloader\"\"\"\n        pass\n</code></pre>"},{"location":"training-framework/modules/datamodule/#basedatamoduleconfig","title":"BaseDataModuleConfig","text":"<p>Datamodule configuration base class:</p> <pre><code>@dataclass\nclass BaseDataModuleConfig:\n    \"\"\"Datamodule configuration base class\"\"\"\n\n    _target_: Literal[\"src._datamodule.base.datamodule.BaseDataModule\"]\n    train: Optional[UnionDatasetConfig] = None\n    val: Optional[UnionDatasetConfig] = None\n    test: Optional[UnionDatasetConfig] = None\n    predict: Optional[UnionDatasetConfig] = None\n</code></pre>"},{"location":"training-framework/modules/datamodule/#main-features","title":"Main Features","text":""},{"location":"training-framework/modules/datamodule/#data-pipeline-management","title":"Data Pipeline Management","text":"<ul> <li>Unified interface: Standardized data loading and preparation processes</li> <li>Stage separation: Supports different stages of training, validation, testing, prediction</li> <li>Configuration-driven: Manages all data parameters through configuration classes</li> </ul>"},{"location":"training-framework/modules/datamodule/#dataloader-configuration","title":"DataLoader Configuration","text":"<ul> <li>Batch size: Configurable batch processing size</li> <li>Worker processes: Support for multi-process data loading</li> <li>Memory optimization: Support for memory pinning and data shuffling</li> </ul>"},{"location":"training-framework/modules/datamodule/#extension-guidelines","title":"Extension Guidelines","text":"<p>To add new datamodule implementations:</p> <ol> <li>Create a new folder under <code>_datamodule/</code></li> <li>Implement datamodule class inheriting from <code>BaseDataModule</code> (not mandatory)</li> <li>Create corresponding configuration class inheriting from <code>BaseDataModuleConfig</code></li> <li>Update <code>__init__.py</code> to export the new datamodule</li> </ol>"},{"location":"training-framework/modules/datamodule/README_zh/","title":"DataModule Module","text":"<p>English | \u4e2d\u6587</p> <p>\u6570\u636e\u6a21\u5757\u4e13\u6ce8\u4e8e\u6570\u636e\u52a0\u8f7d\u548c\u51c6\u5907\uff0c\u4e0e\u8bad\u7ec3\u903b\u8f91\u89e3\u8026\u3002</p> <p>\u6ce8\u610f: \u6b64\u6a21\u5757\u4e3a\u5de5\u5177\u7c7b\uff08\u4ee5 <code>_</code> \u5f00\u5934\uff09\uff0c\u9075\u5faa\u9879\u76ee\u89c4\u8303\u4e2d\u5de5\u5177\u7c7b\u7684\u5b9a\u4e49\uff0c\u5e38\u7528\u4f46\u4e0d\u5e38\u4fee\u6539\u3002\u5982\u9700\u4e86\u89e3\u66f4\u591a\uff0c\u8bf7\u53c2\u8003 \u9879\u76ee\u67b6\u6784\u89c4\u8303\u3002</p>"},{"location":"training-framework/modules/datamodule/README_zh/#_1","title":"\u76ee\u5f55\u7ed3\u6784","text":"<pre><code>_datamodule/\n\u251c\u2500\u2500 base/              # \u57fa\u7840\u6570\u636e\u6a21\u5757\u62bd\u8c61\u7c7b\n\u2502   \u251c\u2500\u2500 datamodule.py  # BaseDataModule \u57fa\u7c7b\n\u2502   \u2514\u2500\u2500 config.py      # \u6570\u636e\u6a21\u5757\u914d\u7f6e\u7c7b\n\u2514\u2500\u2500 __init__.py        # \u6a21\u5757\u521d\u59cb\u5316\n</code></pre>"},{"location":"training-framework/modules/datamodule/README_zh/#_2","title":"\u6838\u5fc3\u7ec4\u4ef6","text":""},{"location":"training-framework/modules/datamodule/README_zh/#basedatamodule","title":"BaseDataModule","text":"<p>\u6240\u6709\u6570\u636e\u6a21\u5757\u7684\u57fa\u7c7b\uff0c\u7ee7\u627f\u81ea PyTorch Lightning \u7684 LightningDataModule\uff0c\u63d0\u4f9b\u7edf\u4e00\u7684\u6570\u636e\u52a0\u8f7d\u63a5\u53e3\uff1a</p> <pre><code>class BaseDataModule(LightningDataModule, ABC):\n    def __init__(self, config: BaseDataModuleConfig):\n        super().__init__()\n        self.config = config\n\n    def setup(self, stage: Optional[str] = None):\n        \"\"\"\u8bbe\u7f6e\u6570\u636e\u6a21\u5757\u7528\u4e8e\u8bad\u7ec3/\u9a8c\u8bc1/\u6d4b\u8bd5\"\"\"\n        pass\n\n    def train_dataloader(self) -&gt; DataLoader:\n        \"\"\"\u8fd4\u56de\u8bad\u7ec3\u6570\u636e\u52a0\u8f7d\u5668\"\"\"\n        pass\n</code></pre>"},{"location":"training-framework/modules/datamodule/README_zh/#basedatamoduleconfig","title":"BaseDataModuleConfig","text":"<p>\u6570\u636e\u6a21\u5757\u914d\u7f6e\u57fa\u7c7b\uff1a</p> <pre><code>@dataclass\nclass BaseDataModuleConfig:\n    \"\"\"\u6570\u636e\u6a21\u5757\u914d\u7f6e\u57fa\u7c7b\"\"\"\n\n    _target_: Literal[\"src._datamodule.base.datamodule.BaseDataModule\"]\n    train: Optional[UnionDatasetConfig] = None\n    val: Optional[UnionDatasetConfig] = None\n    test: Optional[UnionDatasetConfig] = None\n    predict: Optional[UnionDatasetConfig] = None\n</code></pre>"},{"location":"training-framework/modules/datamodule/README_zh/#_3","title":"\u4e3b\u8981\u529f\u80fd","text":""},{"location":"training-framework/modules/datamodule/README_zh/#_4","title":"\u6570\u636e\u7ba1\u9053\u7ba1\u7406","text":"<ul> <li>\u7edf\u4e00\u63a5\u53e3\uff1a\u6807\u51c6\u5316\u7684\u6570\u636e\u52a0\u8f7d\u548c\u51c6\u5907\u6d41\u7a0b</li> <li>\u9636\u6bb5\u5206\u79bb\uff1a\u652f\u6301\u8bad\u7ec3\u3001\u9a8c\u8bc1\u3001\u6d4b\u8bd5\u3001\u9884\u6d4b\u4e0d\u540c\u9636\u6bb5</li> <li>\u914d\u7f6e\u9a71\u52a8\uff1a\u901a\u8fc7\u914d\u7f6e\u7c7b\u7ba1\u7406\u6240\u6709\u6570\u636e\u53c2\u6570</li> </ul>"},{"location":"training-framework/modules/datamodule/README_zh/#_5","title":"\u6570\u636e\u52a0\u8f7d\u5668\u914d\u7f6e","text":"<ul> <li>\u6279\u91cf\u5927\u5c0f\uff1a\u53ef\u914d\u7f6e\u7684\u6279\u5904\u7406\u5927\u5c0f</li> <li>\u5de5\u4f5c\u8fdb\u7a0b\uff1a\u652f\u6301\u591a\u8fdb\u7a0b\u6570\u636e\u52a0\u8f7d</li> <li>\u5185\u5b58\u4f18\u5316\uff1a\u652f\u6301\u5185\u5b58\u56fa\u5b9a\u548c\u968f\u673a\u6253\u4e71</li> </ul>"},{"location":"training-framework/modules/datamodule/README_zh/#_6","title":"\u6269\u5c55\u6307\u5357","text":"<p>\u8981\u6dfb\u52a0\u65b0\u7684\u6570\u636e\u6a21\u5757\u5b9e\u73b0\uff1a</p> <ol> <li>\u5728 <code>_datamodule/</code> \u4e0b\u521b\u5efa\u65b0\u6587\u4ef6\u5939</li> <li>\u7ee7\u627f <code>BaseDataModule</code> \u5b9e\u73b0\u6570\u636e\u6a21\u5757\u7c7b\uff08\u4e0d\u5f3a\u5236\uff09</li> <li>\u521b\u5efa\u5bf9\u5e94\u7684\u914d\u7f6e\u7c7b\u7ee7\u627f <code>BaseDataModuleConfig</code></li> <li>\u66f4\u65b0 <code>__init__.py</code> \u5bfc\u51fa\u65b0\u6570\u636e\u6a21\u5757</li> </ol>"},{"location":"training-framework/modules/dataset/","title":"Dataset Module","text":"<p>English | \u4e2d\u6587</p> <p>The dataset module focuses on unified management of data loading, preprocessing, and model input.</p>"},{"location":"training-framework/modules/dataset/#directory-structure","title":"Directory Structure","text":"<pre><code>dataset/\n\u251c\u2500\u2500 base/              # Base dataset abstract classes\n\u2502   \u251c\u2500\u2500 dataset.py     # BaseDataset base class\n\u2502   \u251c\u2500\u2500 config.py      # Dataset configuration class\n\u2502   \u2514\u2500\u2500 model_input.py # Model input definition\n\u2514\u2500\u2500 tutorial_mnist/    # MNIST tutorial implementation\n    \u251c\u2500\u2500 dataset.py     # MNIST dataset implementation\n    \u251c\u2500\u2500 config.py      # MNIST configuration\n    \u2514\u2500\u2500 model_input.py # MNIST model input\n</code></pre>"},{"location":"training-framework/modules/dataset/#core-components","title":"Core Components","text":""},{"location":"training-framework/modules/dataset/#basedataset","title":"BaseDataset","text":"<p>Base class for all datasets, inherits from <code>torch.utils.data.Dataset</code>:</p> <pre><code>class BaseDataset(Dataset, ABC):\n    def __init__(self, config: BaseDatasetConfig):\n        self.config = config\n\n    @abstractmethod\n    def setup(self, stage: Optional[str] = None):\n        pass\n\n    @abstractmethod\n    def __len__(self):\n        pass\n\n    @abstractmethod\n    def __getitem__(self, idx) -&gt; BaseModelInput:\n        pass\n</code></pre>"},{"location":"training-framework/modules/dataset/#basedatasetconfig","title":"BaseDatasetConfig","text":"<p>Dataset configuration base class, some of which is used to construct dataloader, using Pydantic for type safety:</p> <pre><code>@dataclass\nclass BaseDatasetConfig:\n    _target_: str = \"src.dataset.base.dataset.BaseDataset\"\n    batch_size: int = 32\n    num_workers: int = 4\n    shuffle: bool = True\n    pin_memory: bool = True\n    drop_last: bool = False\n</code></pre>"},{"location":"training-framework/modules/dataset/#basemodelinput","title":"BaseModelInput","text":"<p>Base definition for model input, using DictAccessMixin to ensure dataclass can be accessed as dict for data:</p> <pre><code>@dataclass\nclass BaseModelInput(DictAccessMixin):\n    pass\n</code></pre>"},{"location":"training-framework/modules/dataset/#mnist-dataset-implementation","title":"MNIST Dataset Implementation","text":"<p>For detailed MNIST dataset implementation, please refer to: tutorial_mnist/README.md</p> <p>It includes:</p> <ul> <li>Complete data loading and preprocessing pipeline</li> <li>Data augmentation functionality (random rotation, cropping)</li> <li>Subset sampling support (for quick experiments)</li> <li>Standardized model input format</li> </ul>"},{"location":"training-framework/modules/dataset/#main-features","title":"Main Features","text":""},{"location":"training-framework/modules/dataset/#data-pipeline-management","title":"Data Pipeline Management","text":"<ul> <li>Unified interface: Standardized dataset access interface</li> <li>Preprocessing flow: Complete data preprocessing and augmentation</li> <li>Memory optimization: Efficient data loading and caching mechanisms</li> <li>Multi-process support: Support for multi-process data loading</li> </ul>"},{"location":"training-framework/modules/dataset/#configuration-management","title":"Configuration Management","text":"<ul> <li>Batch configuration: Flexible batch size settings</li> <li>Worker processes: Configurable data loading process count</li> <li>Memory management: Memory pinning and data shuffling control</li> <li>Type safety: Configuration validation using Pydantic</li> </ul>"},{"location":"training-framework/modules/dataset/#model-input-standardization","title":"Model Input Standardization","text":"<ul> <li>Unified format: Standardized model input data structure</li> <li>Dictionary access: Support for dictionary-style data access</li> <li>Type conversion: Automatic handling of data type conversion</li> <li>Extensibility: Easy addition of new input fields</li> </ul>"},{"location":"training-framework/modules/dataset/#extension-guidelines","title":"Extension Guidelines","text":"<p>To add new datasets, follow these steps:</p> <ol> <li>Create new folder: Create a new folder under <code>dataset/</code> (e.g., <code>cifar10/</code>)</li> <li>Implement dataset class: Inherit from <code>BaseDataset</code> and implement necessary methods</li> <li>Configuration inheritance: Inherit from <code>BaseDatasetConfig</code> and add specific configurations</li> <li>Define input format: Create specific <code>ModelInput</code> data structure</li> <li>Implement data logic: Complete data loading, preprocessing, and augmentation functionality</li> <li>Export update: Export new dataset class in <code>__init__.py</code></li> </ol>"},{"location":"training-framework/modules/dataset/README_zh/","title":"Dataset Module","text":"<p>English | \u4e2d\u6587</p> <p>\u6570\u636e\u96c6\u6a21\u5757\u4e13\u6ce8\u4e8e\u6570\u636e\u52a0\u8f7d\u3001\u9884\u5904\u7406\u548c\u6a21\u578b\u8f93\u5165\u7684\u7edf\u4e00\u7ba1\u7406\u3002</p>"},{"location":"training-framework/modules/dataset/README_zh/#_1","title":"\u76ee\u5f55\u7ed3\u6784","text":"<pre><code>dataset/\n\u251c\u2500\u2500 base/              # \u57fa\u7840\u6570\u636e\u96c6\u62bd\u8c61\u7c7b\n\u2502   \u251c\u2500\u2500 dataset.py     # BaseDataset \u57fa\u7c7b\n\u2502   \u251c\u2500\u2500 config.py      # \u6570\u636e\u96c6\u914d\u7f6e\u7c7b\n\u2502   \u2514\u2500\u2500 model_input.py # \u6a21\u578b\u8f93\u5165\u5b9a\u4e49\n\u2514\u2500\u2500 tutorial_mnist/    # MNIST \u6559\u7a0b\u5b9e\u73b0\n    \u251c\u2500\u2500 dataset.py     # MNIST \u6570\u636e\u96c6\u5b9e\u73b0\n    \u251c\u2500\u2500 config.py      # MNIST \u914d\u7f6e\n    \u2514\u2500\u2500 model_input.py # MNIST \u6a21\u578b\u8f93\u5165\n</code></pre>"},{"location":"training-framework/modules/dataset/README_zh/#_2","title":"\u6838\u5fc3\u7ec4\u4ef6","text":""},{"location":"training-framework/modules/dataset/README_zh/#basedataset","title":"BaseDataset","text":"<p>\u6240\u6709\u6570\u636e\u96c6\u7684\u57fa\u7c7b\uff0c\u7ee7\u627f\u81ea <code>torch.utils.data.Dataset</code>\uff1a</p> <pre><code>class BaseDataset(Dataset, ABC):\n    def __init__(self, config: BaseDatasetConfig):\n        self.config = config\n\n    @abstractmethod\n    def setup(self, stage: Optional[str] = None):\n        pass\n\n    @abstractmethod\n    def __len__(self):\n        pass\n\n    @abstractmethod\n    def __getitem__(self, idx) -&gt; BaseModelInput:\n        pass\n</code></pre>"},{"location":"training-framework/modules/dataset/README_zh/#basedatasetconfig","title":"BaseDatasetConfig","text":"<p>\u6570\u636e\u96c6\u914d\u7f6e\u57fa\u7c7b\uff0c\u5176\u4e2d\u4e00\u90e8\u5206\u4f1a\u7528\u4e8e\u6784\u9020dataloader\uff0c\u4f7f\u7528 Pydantic \u8fdb\u884c\u7c7b\u578b\u5b89\u5168\uff1a</p> <pre><code>@dataclass\nclass BaseDatasetConfig:\n    _target_: str = \"src.dataset.base.dataset.BaseDataset\"\n    batch_size: int = 32\n    num_workers: int = 4\n    shuffle: bool = True\n    pin_memory: bool = True\n    drop_last: bool = False\n</code></pre>"},{"location":"training-framework/modules/dataset/README_zh/#basemodelinput","title":"BaseModelInput","text":"<p>\u6a21\u578b\u8f93\u5165\u7684\u57fa\u7840\u5b9a\u4e49\uff0c\u4f7f\u7528DictAccessMixin \u4fdd\u8bc1dataclass\u53ef\u4ee5\u540c\u65f6\u4f5c\u4e3adict\u8bbf\u95ee\u6570\u636e\uff1a</p> <pre><code>@dataclass\nclass BaseModelInput(DictAccessMixin):\n    pass\n</code></pre>"},{"location":"training-framework/modules/dataset/README_zh/#mnist","title":"MNIST \u6570\u636e\u96c6\u5b9e\u73b0","text":"<p>\u8be6\u7ec6\u7684 MNIST \u6570\u636e\u96c6\u5b9e\u73b0\u8bf7\u53c2\u8003\uff1atutorial_mnist/README.md</p> <p>\u8be5\u5b9e\u73b0\u5305\u542b\uff1a</p> <ul> <li>\u5b8c\u6574\u7684\u6570\u636e\u52a0\u8f7d\u548c\u9884\u5904\u7406\u6d41\u7a0b</li> <li>\u6570\u636e\u589e\u5f3a\u529f\u80fd\uff08\u968f\u673a\u65cb\u8f6c\u3001\u88c1\u526a\uff09</li> <li>\u5b50\u96c6\u91c7\u6837\u652f\u6301\uff08\u7528\u4e8e\u5feb\u901f\u5b9e\u9a8c\uff09</li> <li>\u6807\u51c6\u5316\u7684\u6a21\u578b\u8f93\u5165\u683c\u5f0f</li> </ul>"},{"location":"training-framework/modules/dataset/README_zh/#_3","title":"\u4e3b\u8981\u529f\u80fd","text":""},{"location":"training-framework/modules/dataset/README_zh/#_4","title":"\u6570\u636e\u7ba1\u9053\u7ba1\u7406","text":"<ul> <li>\u7edf\u4e00\u63a5\u53e3\uff1a\u6807\u51c6\u5316\u7684\u6570\u636e\u96c6\u8bbf\u95ee\u63a5\u53e3</li> <li>\u9884\u5904\u7406\u6d41\u7a0b\uff1a\u5b8c\u6574\u7684\u6570\u636e\u9884\u5904\u7406\u548c\u589e\u5f3a</li> <li>\u5185\u5b58\u4f18\u5316\uff1a\u9ad8\u6548\u7684\u6570\u636e\u52a0\u8f7d\u548c\u7f13\u5b58\u673a\u5236</li> <li>\u591a\u8fdb\u7a0b\u652f\u6301\uff1a\u652f\u6301\u591a\u8fdb\u7a0b\u6570\u636e\u52a0\u8f7d</li> </ul>"},{"location":"training-framework/modules/dataset/README_zh/#_5","title":"\u914d\u7f6e\u7ba1\u7406","text":"<ul> <li>\u6279\u91cf\u914d\u7f6e\uff1a\u7075\u6d3b\u7684\u6279\u5904\u7406\u5927\u5c0f\u8bbe\u7f6e</li> <li>\u5de5\u4f5c\u8fdb\u7a0b\uff1a\u53ef\u914d\u7f6e\u7684\u6570\u636e\u52a0\u8f7d\u8fdb\u7a0b\u6570</li> <li>\u5185\u5b58\u7ba1\u7406\uff1a\u5185\u5b58\u56fa\u5b9a\u548c\u6570\u636e\u6253\u4e71\u63a7\u5236</li> <li>\u7c7b\u578b\u5b89\u5168\uff1a\u57fa\u4e8e Pydantic \u7684\u914d\u7f6e\u9a8c\u8bc1</li> </ul>"},{"location":"training-framework/modules/dataset/README_zh/#_6","title":"\u6a21\u578b\u8f93\u5165\u6807\u51c6\u5316","text":"<ul> <li>\u7edf\u4e00\u683c\u5f0f\uff1a\u6807\u51c6\u5316\u7684\u6a21\u578b\u8f93\u5165\u6570\u636e\u7ed3\u6784</li> <li>\u5b57\u5178\u8bbf\u95ee\uff1a\u652f\u6301\u5b57\u5178\u98ce\u683c\u7684\u6570\u636e\u8bbf\u95ee</li> <li>\u7c7b\u578b\u8f6c\u6362\uff1a\u81ea\u52a8\u5904\u7406\u6570\u636e\u7c7b\u578b\u8f6c\u6362</li> <li>\u6269\u5c55\u6027\uff1a\u6613\u4e8e\u6dfb\u52a0\u65b0\u7684\u8f93\u5165\u5b57\u6bb5</li> </ul>"},{"location":"training-framework/modules/dataset/README_zh/#_7","title":"\u6269\u5c55\u6307\u5357","text":"<p>\u8981\u6dfb\u52a0\u65b0\u7684\u6570\u636e\u96c6\uff0c\u8bf7\u9075\u5faa\u4ee5\u4e0b\u6b65\u9aa4\uff1a</p> <ol> <li>\u521b\u5efa\u65b0\u6587\u4ef6\u5939\uff1a\u5728 <code>dataset/</code> \u4e0b\u521b\u5efa\u65b0\u6587\u4ef6\u5939\uff08\u5982 <code>cifar10/</code>\uff09</li> <li>\u5b9e\u73b0\u6570\u636e\u96c6\u7c7b\uff1a\u7ee7\u627f <code>BaseDataset</code> \u5e76\u5b9e\u73b0\u5fc5\u8981\u65b9\u6cd5</li> <li>\u914d\u7f6e\u7c7b\u7ee7\u627f\uff1a\u7ee7\u627f <code>BaseDatasetConfig</code> \u5e76\u6dfb\u52a0\u7279\u5b9a\u914d\u7f6e</li> <li>\u5b9a\u4e49\u8f93\u5165\u683c\u5f0f\uff1a\u521b\u5efa\u5177\u4f53\u7684 <code>ModelInput</code> \u6570\u636e\u7ed3\u6784</li> <li>\u5b9e\u73b0\u6570\u636e\u903b\u8f91\uff1a\u5b8c\u6210\u6570\u636e\u52a0\u8f7d\u3001\u9884\u5904\u7406\u548c\u589e\u5f3a\u529f\u80fd</li> <li>\u5bfc\u51fa\u66f4\u65b0\uff1a\u5728 <code>__init__.py</code> \u4e2d\u5bfc\u51fa\u65b0\u6570\u636e\u96c6\u7c7b</li> </ol>"},{"location":"training-framework/modules/logger/","title":"Logger Module","text":"<p>English | \u4e2d\u6587</p> <p>The logger module focuses on experiment logging and management, decoupled from training logic.</p> <p>Note: This module is a tool class (prefixed with <code>_</code>), following the tool class definitions in the project specifications, commonly used but not frequently modified. For more information, please refer to the Project Architecture Specification.</p>"},{"location":"training-framework/modules/logger/#directory-structure","title":"Directory Structure","text":"<pre><code>_logger/\n\u251c\u2500\u2500 base/              # Base logger parameter abstract classes\n\u2502   \u2514\u2500\u2500 config.py      # BaseLoggerParams base class\n\u251c\u2500\u2500 wandb/             # Weights &amp; Biases logger\n\u2502   \u2514\u2500\u2500 config.py      # WandbLoggerParams parameter class\n\u251c\u2500\u2500 tensorboard/       # TensorBoard logger\n\u2502   \u2514\u2500\u2500 config.py      # TensorBoardLoggerParams parameter class\n\u251c\u2500\u2500 csv/               # CSV format logger\n\u2502   \u2514\u2500\u2500 config.py      # CSVLoggerParams parameter class\n\u251c\u2500\u2500 mlflow/            # MLflow logger\n\u2502   \u2514\u2500\u2500 config.py      # MLFlowLoggerParams parameter class\n\u251c\u2500\u2500 neptune/           # Neptune logger\n\u2502   \u2514\u2500\u2500 config.py      # NeptuneLoggerParams parameter class\n\u251c\u2500\u2500 config.py          # Module configuration and Union type definitions\n\u2514\u2500\u2500 __init__.py        # Module initialization\n</code></pre>"},{"location":"training-framework/modules/logger/#core-components","title":"Core Components","text":""},{"location":"training-framework/modules/logger/#baseloggerparams","title":"BaseLoggerParams","text":"<p>Base class for all logger parameters:</p> <pre><code>@dataclass\nclass BaseLoggerParams(DictAccessMixin):\n    \"\"\"Logger parameters base class\"\"\"\n\n    _target_: str = Field(..., description=\"Complete path to Logger class\")\n    version: Optional[Union[int, str]] = Field(None, description=\"Experiment version\")\n    prefix: str = Field(\"\", description=\"Log prefix\")\n</code></pre>"},{"location":"training-framework/modules/logger/#unionloggerparams","title":"UnionLoggerParams","text":"<p>Unified logger parameters type:</p> <pre><code>UnionLoggerParams = Union[\n    WandbLoggerParams,\n    TensorBoardLoggerParams,\n    CSVLoggerParams,\n    MLFlowLoggerParams,\n    NeptuneLoggerParams,\n]\n</code></pre>"},{"location":"training-framework/modules/logger/#supported-loggers","title":"Supported Loggers","text":"<ul> <li>WandbLogger: Weights &amp; Biases experiment tracking</li> <li>TensorBoardLogger: TensorBoard visualization logging</li> <li>CSVLogger: CSV format local logging</li> <li>MLFlowLogger: MLflow experiment management</li> <li>NeptuneLogger: Neptune AI platform integration</li> </ul>"},{"location":"training-framework/modules/logger/#main-features","title":"Main Features","text":""},{"location":"training-framework/modules/logger/#multi-platform-support","title":"Multi-Platform Support","text":"<ul> <li>Experiment tracking: Complete experiment lifecycle management</li> <li>Metric recording: Automatic recording of training metrics and hyperparameters</li> <li>Visualization: Support for multiple visualization tools integration</li> <li>Version control: Experiment version management and comparison</li> </ul>"},{"location":"training-framework/modules/logger/#configuration-flexibility","title":"Configuration Flexibility","text":"<ul> <li>Unified interface: Standardized logger configuration interface</li> <li>Type safety: Complete type checking and validation using Pydantic</li> <li>Extensibility: Easy addition of new logger support</li> </ul>"},{"location":"training-framework/modules/logger/#usage-example","title":"Usage Example","text":"<pre><code>from src._logger import UnionLoggerParams, WandbLoggerParams\n\n# Create WandB logger parameters\nwandb_params = WandbLoggerParams(\n    project=\"my_project\",\n    name=\"experiment_1\",\n    save_dir=\"./logs\"\n)\n\n# Use in configuration\nconfig = SomeConfig(\n    logger=wandb_params\n)\n</code></pre>"},{"location":"training-framework/modules/logger/#extension-guidelines","title":"Extension Guidelines","text":"<p>To add new logger support:</p> <ol> <li>Create a new folder under <code>_logger/</code> (e.g., <code>new_logger/</code>)</li> <li>Create <code>config.py</code> implementing <code>NewLoggerParams</code> class inheriting from <code>BaseLoggerParams</code></li> <li>Add imports and Union type updates in <code>__init__.py</code></li> <li>Update main <code>config.py</code> imports if needed</li> <li>Update <code>__all__</code> export list</li> </ol>"},{"location":"training-framework/modules/logger/README_zh/","title":"Logger Module","text":"<p>English | \u4e2d\u6587</p> <p>\u65e5\u5fd7\u5668\u6a21\u5757\u4e13\u6ce8\u4e8e\u5b9e\u9a8c\u65e5\u5fd7\u8bb0\u5f55\u548c\u7ba1\u7406\uff0c\u4e0e\u8bad\u7ec3\u903b\u8f91\u89e3\u8026\u3002</p> <p>\u6ce8\u610f: \u6b64\u6a21\u5757\u4e3a\u5de5\u5177\u7c7b\uff08\u4ee5 <code>_</code> \u5f00\u5934\uff09\uff0c\u9075\u5faa\u9879\u76ee\u89c4\u8303\u4e2d\u5de5\u5177\u7c7b\u7684\u5b9a\u4e49\uff0c\u5e38\u7528\u4f46\u4e0d\u5e38\u4fee\u6539\u3002\u5982\u9700\u4e86\u89e3\u66f4\u591a\uff0c\u8bf7\u53c2\u8003 \u9879\u76ee\u67b6\u6784\u89c4\u8303\u3002</p>"},{"location":"training-framework/modules/logger/README_zh/#_1","title":"\u76ee\u5f55\u7ed3\u6784","text":"<pre><code>_logger/\n\u251c\u2500\u2500 base/              # \u57fa\u7840\u65e5\u5fd7\u5668\u53c2\u6570\u62bd\u8c61\u7c7b\n\u2502   \u2514\u2500\u2500 config.py      # BaseLoggerParams \u57fa\u7c7b\n\u251c\u2500\u2500 wandb/             # Weights &amp; Biases \u65e5\u5fd7\u5668\n\u2502   \u2514\u2500\u2500 config.py      # WandbLoggerParams \u53c2\u6570\u7c7b\n\u251c\u2500\u2500 tensorboard/       # TensorBoard \u65e5\u5fd7\u5668\n\u2502   \u2514\u2500\u2500 config.py      # TensorBoardLoggerParams \u53c2\u6570\u7c7b\n\u251c\u2500\u2500 csv/               # CSV \u683c\u5f0f\u65e5\u5fd7\u5668\n\u2502   \u2514\u2500\u2500 config.py      # CSVLoggerParams \u53c2\u6570\u7c7b\n\u251c\u2500\u2500 mlflow/            # MLflow \u65e5\u5fd7\u5668\n\u2502   \u2514\u2500\u2500 config.py      # MLFlowLoggerParams \u53c2\u6570\u7c7b\n\u251c\u2500\u2500 neptune/           # Neptune \u65e5\u5fd7\u5668\n\u2502   \u2514\u2500\u2500 config.py      # NeptuneLoggerParams \u53c2\u6570\u7c7b\n\u251c\u2500\u2500 config.py          # \u6a21\u5757\u914d\u7f6e\u548c Union \u7c7b\u578b\u5b9a\u4e49\n\u2514\u2500\u2500 __init__.py        # \u6a21\u5757\u521d\u59cb\u5316\n</code></pre>"},{"location":"training-framework/modules/logger/README_zh/#_2","title":"\u6838\u5fc3\u7ec4\u4ef6","text":""},{"location":"training-framework/modules/logger/README_zh/#baseloggerparams","title":"BaseLoggerParams","text":"<p>\u6240\u6709\u65e5\u5fd7\u5668\u53c2\u6570\u7684\u57fa\u7c7b\uff1a</p> <pre><code>@dataclass\nclass BaseLoggerParams(DictAccessMixin):\n    \"\"\"\u65e5\u5fd7\u5668\u53c2\u6570\u57fa\u7c7b\"\"\"\n\n    _target_: str = Field(..., description=\"Logger \u7c7b\u7684\u5b8c\u6574\u8def\u5f84\")\n    version: Optional[Union[int, str]] = Field(None, description=\"\u5b9e\u9a8c\u7248\u672c\")\n    prefix: str = Field(\"\", description=\"\u65e5\u5fd7\u524d\u7f00\")\n</code></pre>"},{"location":"training-framework/modules/logger/README_zh/#unionloggerparams","title":"UnionLoggerParams","text":"<p>\u7edf\u4e00\u7684\u65e5\u5fd7\u5668\u53c2\u6570\u7c7b\u578b\uff1a</p> <pre><code>UnionLoggerParams = Union[\n    WandbLoggerParams,\n    TensorBoardLoggerParams,\n    CSVLoggerParams,\n    MLFlowLoggerParams,\n    NeptuneLoggerParams,\n]\n</code></pre>"},{"location":"training-framework/modules/logger/README_zh/#_3","title":"\u652f\u6301\u7684\u65e5\u5fd7\u5668","text":"<ul> <li>WandbLogger: Weights &amp; Biases \u5b9e\u9a8c\u8ddf\u8e2a</li> <li>TensorBoardLogger: TensorBoard \u53ef\u89c6\u5316\u65e5\u5fd7</li> <li>CSVLogger: CSV \u683c\u5f0f\u672c\u5730\u65e5\u5fd7</li> <li>MLFlowLogger: MLflow \u5b9e\u9a8c\u7ba1\u7406</li> <li>NeptuneLogger: Neptune AI \u5e73\u53f0\u96c6\u6210</li> </ul>"},{"location":"training-framework/modules/logger/README_zh/#_4","title":"\u4e3b\u8981\u529f\u80fd","text":""},{"location":"training-framework/modules/logger/README_zh/#_5","title":"\u591a\u5e73\u53f0\u652f\u6301","text":"<ul> <li>\u5b9e\u9a8c\u8ddf\u8e2a\uff1a\u5b8c\u6574\u7684\u5b9e\u9a8c\u751f\u547d\u5468\u671f\u7ba1\u7406</li> <li>\u6307\u6807\u8bb0\u5f55\uff1a\u81ea\u52a8\u8bb0\u5f55\u8bad\u7ec3\u6307\u6807\u548c\u8d85\u53c2\u6570</li> <li>\u53ef\u89c6\u5316\uff1a\u652f\u6301\u591a\u79cd\u53ef\u89c6\u5316\u5de5\u5177\u96c6\u6210</li> <li>\u7248\u672c\u63a7\u5236\uff1a\u5b9e\u9a8c\u7248\u672c\u7ba1\u7406\u548c\u6bd4\u8f83</li> </ul>"},{"location":"training-framework/modules/logger/README_zh/#_6","title":"\u914d\u7f6e\u7075\u6d3b\u6027","text":"<ul> <li>\u7edf\u4e00\u63a5\u53e3\uff1a\u6807\u51c6\u5316\u7684\u65e5\u5fd7\u5668\u914d\u7f6e\u63a5\u53e3</li> <li>\u7c7b\u578b\u5b89\u5168\uff1a\u57fa\u4e8e Pydantic \u7684\u914d\u7f6e\u9a8c\u8bc1</li> <li>\u6269\u5c55\u6027\uff1a\u6613\u4e8e\u6dfb\u52a0\u65b0\u7684\u65e5\u5fd7\u5668\u652f\u6301</li> </ul>"},{"location":"training-framework/modules/logger/README_zh/#_7","title":"\u4f7f\u7528\u793a\u4f8b","text":"<pre><code>from src._logger import UnionLoggerParams, WandbLoggerParams\n\n# \u521b\u5efa WandB \u65e5\u5fd7\u5668\u53c2\u6570\nwandb_params = WandbLoggerParams(\n    project=\"my_project\",\n    name=\"experiment_1\",\n    save_dir=\"./logs\"\n)\n\n# \u5728\u914d\u7f6e\u4e2d\u4f7f\u7528\nconfig = SomeConfig(\n    logger=wandb_params\n)\n</code></pre>"},{"location":"training-framework/modules/logger/README_zh/#_8","title":"\u6269\u5c55\u6307\u5357","text":"<p>\u8981\u6dfb\u52a0\u65b0\u7684\u65e5\u5fd7\u5668\u652f\u6301\uff1a</p> <ol> <li>\u5728 <code>_logger/</code> \u4e0b\u521b\u5efa\u65b0\u6587\u4ef6\u5939\uff08\u5982 <code>new_logger/</code>\uff09</li> <li>\u521b\u5efa <code>config.py</code> \u5b9e\u73b0 <code>NewLoggerParams</code> \u7c7b\u7ee7\u627f <code>BaseLoggerParams</code></li> <li>\u5728 <code>__init__.py</code> \u4e2d\u6dfb\u52a0\u5bfc\u5165\u548c Union \u7c7b\u578b\u66f4\u65b0</li> <li>\u66f4\u65b0\u4e3b <code>config.py</code> \u7684\u5bfc\u5165\uff08\u5982\u679c\u9700\u8981\uff09</li> <li>\u66f4\u65b0 <code>__all__</code> \u5bfc\u51fa\u5217\u8868</li> </ol>"},{"location":"training-framework/modules/lr_scheduler/","title":"LR Scheduler Module","text":"<p>English | \u4e2d\u6587</p> <p>The learning rate scheduler module focuses on learning rate adjustment strategies during training, decoupled from training logic.</p> <p>Note: This module is a tool class (prefixed with <code>_</code>), following the tool class definitions in the project specifications, commonly used but not frequently modified. For more information, please refer to the Project Architecture Specification.</p>"},{"location":"training-framework/modules/lr_scheduler/#directory-structure","title":"Directory Structure","text":"<pre><code>_lr_scheduler/\n\u251c\u2500\u2500 base/                      # Base scheduler parameter abstract classes\n\u2502   \u2514\u2500\u2500 config.py              # BaseLRSchedulerParams base class\n\u251c\u2500\u2500 step/                      # StepLR scheduler\n\u2502   \u2514\u2500\u2500 config.py              # StepLRParams parameter class\n\u251c\u2500\u2500 multistep/                 # MultiStepLR scheduler\n\u2502   \u2514\u2500\u2500 config.py              # MultiStepLRParams parameter class\n\u251c\u2500\u2500 exponential/               # ExponentialLR scheduler\n\u2502   \u2514\u2500\u2500 config.py              # ExponentialLRParams parameter class\n\u251c\u2500\u2500 cosine/                    # CosineAnnealingLR scheduler\n\u2502   \u2514\u2500\u2500 config.py              # CosineAnnealingLRParams parameter class\n\u251c\u2500\u2500 reduce_on_plateau/         # ReduceLROnPlateau scheduler\n\u2502   \u2514\u2500\u2500 config.py              # ReduceLROnPlateauParams parameter class\n\u251c\u2500\u2500 cyclic/                    # CyclicLR scheduler\n\u2502   \u2514\u2500\u2500 config.py              # CyclicLRParams parameter class\n\u251c\u2500\u2500 onecycle/                  # OneCycleLR scheduler\n\u2502   \u2514\u2500\u2500 config.py              # OneCycleLRParams parameter class\n\u251c\u2500\u2500 cosine_warm_restarts/      # CosineAnnealingWarmRestarts scheduler\n\u2502   \u2514\u2500\u2500 config.py              # CosineAnnealingWarmRestartsParams parameter class\n\u2514\u2500\u2500 __init__.py                # Module initialization\n</code></pre>"},{"location":"training-framework/modules/lr_scheduler/#core-components","title":"Core Components","text":""},{"location":"training-framework/modules/lr_scheduler/#baselrschedulerparams","title":"BaseLRSchedulerParams","text":"<p>Base class for all learning rate scheduler parameters:</p> <pre><code>@dataclass\nclass BaseLRSchedulerParams:\n    \"\"\"Learning rate scheduler parameters base class\"\"\"\n\n    _target_: str = Field(\"torch.optim.lr_scheduler.CosineAnnealingLR\", description=\"Learning rate scheduler class\")\n    optimizer: Optional[Any] = Field(None, description=\"Optimizer object\")\n    interval: Literal[\"step\", \"epoch\"] = Field(\"step\", description=\"Interval for updating the learning rate\")\n    frequency: int = Field(1, description=\"Frequency of updating the learning rate\")\n    monitor: Optional[str] = Field(None, description=\"Metric to monitor for learning rate scheduling\")\n    strict: bool = Field(True, description=\"Whether to strictly enforce the configuration\")\n    name: Optional[str] = Field(None, description=\"Name of the learning rate scheduler\")\n    T_max: int = Field(10000, description=\"Total number of training steps\")\n    eta_min: float = Field(1e-6, description=\"Minimum learning rate\")\n</code></pre>"},{"location":"training-framework/modules/lr_scheduler/#unionlrschedulerparams","title":"UnionLRSchedulerParams","text":"<p>Unified learning rate scheduler parameters type:</p> <pre><code>UnionLRSchedulerParams = Union[\n    BaseLRSchedulerParams,\n    StepLRParams,\n    MultiStepLRParams,\n    ExponentialLRParams,\n    CosineAnnealingLRParams,\n    ReduceLROnPlateauParams,\n    CyclicLRParams,\n    OneCycleLRParams,\n    CosineAnnealingWarmRestartsParams,\n    dict,  # Allow dict for backward compatibility\n]\n</code></pre>"},{"location":"training-framework/modules/lr_scheduler/#supported-learning-rate-schedulers","title":"Supported Learning Rate Schedulers","text":"<ul> <li>StepLR: Decay learning rate by a fixed factor at fixed steps</li> <li>MultiStepLR: Decay learning rate at specified milestones</li> <li>ExponentialLR: Exponential decay of learning rate</li> <li>CosineAnnealingLR: Cosine annealing decay</li> <li>ReduceLROnPlateau: Adjust learning rate based on metric changes</li> <li>CyclicLR: Cyclic learning rate scheduling</li> <li>OneCycleLR: Single cycle learning rate scheduling</li> <li>CosineAnnealingWarmRestarts: Cosine annealing with warm restarts</li> </ul>"},{"location":"training-framework/modules/lr_scheduler/#main-features","title":"Main Features","text":""},{"location":"training-framework/modules/lr_scheduler/#scheduling-strategy-diversity","title":"Scheduling Strategy Diversity","text":"<ul> <li>Fixed scheduling: Adjust learning rate by step or milestone</li> <li>Adaptive scheduling: Dynamically adjust learning rate based on training metrics</li> <li>Periodic scheduling: Cyclic or single-cycle learning rate changes</li> <li>Exponential decay: Exponential form of decay strategies</li> </ul>"},{"location":"training-framework/modules/lr_scheduler/#configuration-flexibility","title":"Configuration Flexibility","text":"<ul> <li>Interval control: Support updating by step or epoch</li> <li>Frequency setting: Configurable update frequency</li> <li>Metric monitoring: Support for metric-based scheduling decisions</li> <li>Parameter validation: Strict configuration validation and type checking</li> </ul>"},{"location":"training-framework/modules/lr_scheduler/#usage-example","title":"Usage Example","text":"<pre><code>from src._lr_scheduler import UnionLRSchedulerParams, StepLRParams\n\n# Create StepLR scheduler parameters\nstep_params = StepLRParams(\n    step_size=30,\n    gamma=0.1,\n    interval=\"epoch\"\n)\n\n# Use in configuration\nconfig = SomeConfig(\n    lr_scheduler=step_params\n)\n</code></pre>"},{"location":"training-framework/modules/lr_scheduler/README_zh/","title":"LR Scheduler Module","text":"<p>English | \u4e2d\u6587</p> <p>\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\u6a21\u5757\u4e13\u6ce8\u4e8e\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u5b66\u4e60\u7387\u8c03\u6574\u7b56\u7565\uff0c\u4e0e\u8bad\u7ec3\u903b\u8f91\u89e3\u8026\u3002</p> <p>\u6ce8\u610f: \u6b64\u6a21\u5757\u4e3a\u5de5\u5177\u7c7b\uff08\u4ee5 <code>_</code> \u5f00\u5934\uff09\uff0c\u9075\u5faa\u9879\u76ee\u89c4\u8303\u4e2d\u5de5\u5177\u7c7b\u7684\u5b9a\u4e49\uff0c\u5e38\u7528\u4f46\u4e0d\u5e38\u4fee\u6539\u3002\u5982\u9700\u4e86\u89e3\u66f4\u591a\uff0c\u8bf7\u53c2\u8003 \u9879\u76ee\u67b6\u6784\u89c4\u8303\u3002</p>"},{"location":"training-framework/modules/lr_scheduler/README_zh/#_1","title":"\u76ee\u5f55\u7ed3\u6784","text":"<pre><code>_lr_scheduler/\n\u251c\u2500\u2500 base/                      # \u57fa\u7840\u8c03\u5ea6\u5668\u53c2\u6570\u62bd\u8c61\u7c7b\n\u2502   \u2514\u2500\u2500 config.py              # BaseLRSchedulerParams \u57fa\u7c7b\n\u251c\u2500\u2500 step/                      # StepLR \u8c03\u5ea6\u5668\n\u2502   \u2514\u2500\u2500 config.py              # StepLRParams \u53c2\u6570\u7c7b\n\u251c\u2500\u2500 multistep/                 # MultiStepLR \u8c03\u5ea6\u5668\n\u2502   \u2514\u2500\u2500 config.py              # MultiStepLRParams \u53c2\u6570\u7c7b\n\u251c\u2500\u2500 exponential/               # ExponentialLR \u8c03\u5ea6\u5668\n\u2502   \u2514\u2500\u2500 config.py              # ExponentialLRParams \u53c2\u6570\u7c7b\n\u251c\u2500\u2500 cosine/                    # CosineAnnealingLR \u8c03\u5ea6\u5668\n\u2502   \u2514\u2500\u2500 config.py              # CosineAnnealingLRParams \u53c2\u6570\u7c7b\n\u251c\u2500\u2500 reduce_on_plateau/         # ReduceLROnPlateau \u8c03\u5ea6\u5668\n\u2502   \u2514\u2500\u2500 config.py              # ReduceLROnPlateauParams \u53c2\u6570\u7c7b\n\u251c\u2500\u2500 cyclic/                    # CyclicLR \u8c03\u5ea6\u5668\n\u2502   \u2514\u2500\u2500 config.py              # CyclicLRParams \u53c2\u6570\u7c7b\n\u251c\u2500\u2500 onecycle/                  # OneCycleLR \u8c03\u5ea6\u5668\n\u2502   \u2514\u2500\u2500 config.py              # OneCycleLRParams \u53c2\u6570\u7c7b\n\u251c\u2500\u2500 cosine_warm_restarts/      # CosineAnnealingWarmRestarts \u8c03\u5ea6\u5668\n\u2502   \u2514\u2500\u2500 config.py              # CosineAnnealingWarmRestartsParams \u53c2\u6570\u7c7b\n\u2514\u2500\u2500 __init__.py                # \u6a21\u5757\u521d\u59cb\u5316\n</code></pre>"},{"location":"training-framework/modules/lr_scheduler/README_zh/#_2","title":"\u6838\u5fc3\u7ec4\u4ef6","text":""},{"location":"training-framework/modules/lr_scheduler/README_zh/#baselrschedulerparams","title":"BaseLRSchedulerParams","text":"<p>\u6240\u6709\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\u53c2\u6570\u7684\u57fa\u7c7b\uff1a</p> <pre><code>@dataclass\nclass BaseLRSchedulerParams:\n    \"\"\"\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\u53c2\u6570\u57fa\u7c7b\"\"\"\n\n    _target_: str = Field(\"torch.optim.lr_scheduler.CosineAnnealingLR\", description=\"Learning rate scheduler class\")\n    optimizer: Optional[Any] = Field(None, description=\"Optimizer object\")\n    interval: Literal[\"step\", \"epoch\"] = Field(\"step\", description=\"Interval for updating the learning rate\")\n    frequency: int = Field(1, description=\"Frequency of updating the learning rate\")\n    monitor: Optional[str] = Field(None, description=\"Metric to monitor for learning rate scheduling\")\n    strict: bool = Field(True, description=\"Whether to strictly enforce the configuration\")\n    name: Optional[str] = Field(None, description=\"Name of the learning rate scheduler\")\n    T_max: int = Field(10000, description=\"Total number of training steps\")\n    eta_min: float = Field(1e-6, description=\"Minimum learning rate\")\n</code></pre>"},{"location":"training-framework/modules/lr_scheduler/README_zh/#unionlrschedulerparams","title":"UnionLRSchedulerParams","text":"<p>\u7edf\u4e00\u7684\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\u53c2\u6570\u7c7b\u578b\uff1a</p> <pre><code>UnionLRSchedulerParams = Union[\n    BaseLRSchedulerParams,\n    StepLRParams,\n    MultiStepLRParams,\n    ExponentialLRParams,\n    CosineAnnealingLRParams,\n    ReduceLROnPlateauParams,\n    CyclicLRParams,\n    OneCycleLRParams,\n    CosineAnnealingWarmRestartsParams,\n    dict,  # Allow dict for backward compatibility\n]\n</code></pre>"},{"location":"training-framework/modules/lr_scheduler/README_zh/#_3","title":"\u652f\u6301\u7684\u5b66\u4e60\u7387\u8c03\u5ea6\u5668","text":"<ul> <li>StepLR: \u6309\u56fa\u5b9a\u6b65\u957f\u8870\u51cf\u5b66\u4e60\u7387</li> <li>MultiStepLR: \u5728\u6307\u5b9a\u91cc\u7a0b\u7891\u5904\u8870\u51cf\u5b66\u4e60\u7387</li> <li>ExponentialLR: \u6307\u6570\u8870\u51cf\u5b66\u4e60\u7387</li> <li>CosineAnnealingLR: \u4f59\u5f26\u9000\u706b\u8870\u51cf</li> <li>ReduceLROnPlateau: \u6839\u636e\u6307\u6807\u53d8\u5316\u8c03\u6574\u5b66\u4e60\u7387</li> <li>CyclicLR: \u5faa\u73af\u5b66\u4e60\u7387\u8c03\u5ea6</li> <li>OneCycleLR: \u5355\u5468\u671f\u5b66\u4e60\u7387\u8c03\u5ea6</li> <li>CosineAnnealingWarmRestarts: \u5e26\u91cd\u542f\u7684\u4f59\u5f26\u9000\u706b</li> </ul>"},{"location":"training-framework/modules/lr_scheduler/README_zh/#_4","title":"\u4e3b\u8981\u529f\u80fd","text":""},{"location":"training-framework/modules/lr_scheduler/README_zh/#_5","title":"\u8c03\u5ea6\u7b56\u7565\u591a\u6837\u6027","text":"<ul> <li>\u56fa\u5b9a\u8c03\u5ea6\uff1a\u6309\u6b65\u957f\u6216\u91cc\u7a0b\u7891\u8c03\u6574\u5b66\u4e60\u7387</li> <li>\u81ea\u9002\u5e94\u8c03\u5ea6\uff1a\u6839\u636e\u8bad\u7ec3\u6307\u6807\u52a8\u6001\u8c03\u6574</li> <li>\u5468\u671f\u8c03\u5ea6\uff1a\u5faa\u73af\u6216\u5355\u5468\u671f\u5b66\u4e60\u7387\u53d8\u5316</li> <li>\u6307\u6570\u8870\u51cf\uff1a\u6307\u6570\u5f62\u5f0f\u7684\u8870\u51cf\u7b56\u7565</li> </ul>"},{"location":"training-framework/modules/lr_scheduler/README_zh/#_6","title":"\u914d\u7f6e\u7075\u6d3b\u6027","text":"<ul> <li>\u95f4\u9694\u63a7\u5236\uff1a\u652f\u6301\u6309\u6b65\u957f\u6216\u8f6e\u6b21\u66f4\u65b0</li> <li>\u9891\u7387\u8bbe\u7f6e\uff1a\u53ef\u914d\u7f6e\u66f4\u65b0\u9891\u7387</li> <li>\u76d1\u63a7\u6307\u6807\uff1a\u652f\u6301\u57fa\u4e8e\u6307\u6807\u7684\u8c03\u5ea6\u51b3\u7b56</li> <li>\u53c2\u6570\u9a8c\u8bc1\uff1a\u4e25\u683c\u7684\u914d\u7f6e\u9a8c\u8bc1\u548c\u7c7b\u578b\u68c0\u67e5</li> </ul>"},{"location":"training-framework/modules/lr_scheduler/README_zh/#_7","title":"\u4f7f\u7528\u793a\u4f8b","text":"<pre><code>from src._lr_scheduler import UnionLRSchedulerParams, StepLRParams\n\n# \u521b\u5efa StepLR \u8c03\u5ea6\u5668\u53c2\u6570\nstep_params = StepLRParams(\n    step_size=30,\n    gamma=0.1,\n    interval=\"epoch\"\n)\n\n# \u5728\u914d\u7f6e\u4e2d\u4f7f\u7528\nconfig = SomeConfig(\n    lr_scheduler=step_params\n)\n</code></pre>"},{"location":"training-framework/modules/metric/","title":"Metric Module","text":"<p>English | \u4e2d\u6587</p> <p>The metric module focuses on metric calculation, recording, and management during deep learning training, built on PyTorch Lightning and TorchMetrics, providing unified metric configuration and management interfaces.</p> <p>Note: This module is a tool class (prefixed with <code>_</code>), following the tool class definitions in the project specifications, commonly used but not frequently modified. For more information, please refer to the Project Architecture Specification.</p>"},{"location":"training-framework/modules/metric/#directory-structure","title":"Directory Structure","text":"<pre><code>metric/\n\u251c\u2500\u2500 __init__.py                   # Module initialization\n\u251c\u2500\u2500 base/                         # Base metric configuration\n\u2502   \u251c\u2500\u2500 __init__.py              # Submodule initialization\n\u2502   \u2514\u2500\u2500 config.py                # Base metric configuration class\n\u251c\u2500\u2500 _manager/                     # Metric manager\n\u2502   \u251c\u2500\u2500 __init__.py              # Submodule initialization\n\u2502   \u251c\u2500\u2500 config.py                # Metric manager configuration class\n\u2502   \u2514\u2500\u2500 manager.py               # Metric manager implementation\n\u251c\u2500\u2500 value_recoder/                # Value recorder metric\n\u2502   \u251c\u2500\u2500 __init__.py              # Submodule initialization\n\u2502   \u251c\u2500\u2500 config.py                # Value recorder configuration class\n\u2502   \u2514\u2500\u2500 metric.py                # Value recorder metric implementation\n\u251c\u2500\u2500 README_zh.md                  # Chinese documentation\n\u2514\u2500\u2500 README.md                     # English documentation\n</code></pre>"},{"location":"training-framework/modules/metric/#core-components","title":"Core Components","text":""},{"location":"training-framework/modules/metric/#basemetricparams","title":"BaseMetricParams","text":"<p>Base metric configuration class - provides unified configuration interfaces for all metrics:</p> <pre><code>@dataclass(config=ConfigDict(extra=\"allow\"))\nclass BaseMetricParams:\n    \"\"\"Base metric configuration class\"\"\"\n    _target_: str = Field(default=\"torchmetrics.Metric\")\n    # Support passing additional configuration parameters through extra=\"allow\"\n</code></pre>"},{"location":"training-framework/modules/metric/#metricmanager","title":"MetricManager","text":"<p>Metric manager - unifies management of all training metrics:</p> <pre><code>class MetricManager(torch.nn.Module):\n    \"\"\"\n    Metric manager - manages metric collection state, calculation, and logging strategies\n    Supports DDP distributed training\n    \"\"\"\n    # Two-layer ModuleDict structure: group_name -&gt; metric_name -&gt; Metric\n</code></pre>"},{"location":"training-framework/modules/metric/#valuerecordermetric","title":"ValueRecorderMetric","text":"<p>Value recorder metric - specialized for recording scalar values:</p> <pre><code>class ValueRecorderMetric(Metric):\n    \"\"\"\n    Numerical recording metric - records and aggregates scalar values during training\n    Supports multiple aggregation methods: mean, sum, last\n    \"\"\"\n</code></pre>"},{"location":"training-framework/modules/metric/#main-features","title":"Main Features","text":""},{"location":"training-framework/modules/metric/#metric-configuration-management","title":"Metric Configuration Management","text":"<ul> <li>Multiple configuration methods: Support configuration-driven, direct instantiation, string, dictionary four configuration methods</li> <li>Type safety: Use Pydantic to provide complete type checking and validation</li> <li>Flexible extension: Support passing additional parameters through <code>extra=\"allow\"</code></li> </ul>"},{"location":"training-framework/modules/metric/#metric-grouping-management","title":"Metric Grouping Management","text":"<ul> <li>Grouping organization: Support organizing related metrics into different groups</li> <li>Independent configuration: Each group can have independent logging configuration</li> <li>Modular management: Use ModuleDict to ensure DDP compatibility</li> </ul>"},{"location":"training-framework/modules/metric/#logging-configuration-management","title":"Logging Configuration Management","text":"<ul> <li>Stage control: Support train/val/test different stage logging control</li> <li>Frequency control: Support independent configuration of update frequency and calculation frequency</li> <li>Multi-target logging: Support progress bar, logger, per-step/per-epoch logging</li> </ul>"},{"location":"training-framework/modules/metric/#value-recording-functionality","title":"Value Recording Functionality","text":"<ul> <li>Scalar recording: Specialized for recording loss values, learning rates and other scalar metrics</li> <li>Aggregation calculation: Support mean, sum, take last value and other aggregation methods</li> <li>Automatic type conversion: Automatically handle Tensor and numerical type conversion</li> </ul>"},{"location":"training-framework/modules/metric/#usage-example","title":"Usage Example","text":""},{"location":"training-framework/modules/metric/#basic-usage","title":"Basic Usage","text":"<pre><code>from src.metric._manager import MetricManager, MetricManagerConfig\nfrom src.metric.value_recoder import ValueRecorderParams\n\n# Create metric manager configuration\nmetric_config = MetricManagerConfig(\n    groups={\n        \"train\": {\n            \"loss\": ValueRecorderParams(name=\"train_loss\"),\n            \"accuracy\": {\"_target_\": \"torchmetrics.Accuracy\", \"task\": \"multiclass\", \"num_classes\": 10}\n        }\n    }\n)\n\n# Create metric manager\nmetric_manager = MetricManager(metric_config)\n</code></pre>"},{"location":"training-framework/modules/metric/#advanced-configuration","title":"Advanced Configuration","text":"<pre><code># Configure logging strategy\nlog_config = MetricLogConfig(\n    on_step=True,\n    on_epoch=True,\n    prog_bar=True,\n    logger=True\n)\n\n# Use group management\nmetric_manager.log_group(\"train\", {\"loss\": 0.5, \"acc\": 0.9}, log_config)\n</code></pre>"},{"location":"training-framework/modules/metric/README_zh/","title":"Metric Module","text":"<p>English | \u4e2d\u6587</p> <p>\u6307\u6807\u6a21\u5757\u4e13\u6ce8\u4e8e\u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u6307\u6807\u8ba1\u7b97\u3001\u8bb0\u5f55\u548c\u7ba1\u7406\uff0c\u57fa\u4e8e PyTorch Lightning \u548c TorchMetrics \u6784\u5efa\uff0c\u63d0\u4f9b\u7edf\u4e00\u7684\u6307\u6807\u914d\u7f6e\u548c\u7ba1\u7406\u63a5\u53e3\u3002</p> <p>\u6ce8\u610f: \u6b64\u6a21\u5757\u4e3a\u5de5\u5177\u7c7b\uff08\u4ee5 <code>_</code> \u5f00\u5934\uff09\uff0c\u9075\u5faa\u9879\u76ee\u89c4\u8303\u4e2d\u5de5\u5177\u7c7b\u7684\u5b9a\u4e49\uff0c\u5e38\u7528\u4f46\u4e0d\u5e38\u4fee\u6539\u3002\u5982\u9700\u4e86\u89e3\u66f4\u591a\uff0c\u8bf7\u53c2\u8003 \u9879\u76ee\u67b6\u6784\u89c4\u8303\u3002</p>"},{"location":"training-framework/modules/metric/README_zh/#_1","title":"\u76ee\u5f55\u7ed3\u6784","text":"<pre><code>metric/\n\u251c\u2500\u2500 __init__.py                   # \u6a21\u5757\u521d\u59cb\u5316\n\u251c\u2500\u2500 base/                         # \u57fa\u7840\u6307\u6807\u914d\u7f6e\n\u2502   \u251c\u2500\u2500 __init__.py              # \u5b50\u6a21\u5757\u521d\u59cb\u5316\n\u2502   \u2514\u2500\u2500 config.py                # \u57fa\u7840\u6307\u6807\u914d\u7f6e\u7c7b\n\u251c\u2500\u2500 _manager/                     # \u6307\u6807\u7ba1\u7406\u5668\n\u2502   \u251c\u2500\u2500 __init__.py              # \u5b50\u6a21\u5757\u521d\u59cb\u5316\n\u2502   \u251c\u2500\u2500 config.py                # \u6307\u6807\u7ba1\u7406\u5668\u914d\u7f6e\u7c7b\n\u2502   \u2514\u2500\u2500 manager.py               # \u6307\u6807\u7ba1\u7406\u5668\u5b9e\u73b0\n\u251c\u2500\u2500 value_recoder/                # \u503c\u8bb0\u5f55\u5668\u6307\u6807\n\u2502   \u251c\u2500\u2500 __init__.py              # \u5b50\u6a21\u5757\u521d\u59cb\u5316\n\u2502   \u251c\u2500\u2500 config.py                # \u503c\u8bb0\u5f55\u5668\u914d\u7f6e\u7c7b\n\u2502   \u2514\u2500\u2500 metric.py                # \u503c\u8bb0\u5f55\u5668\u6307\u6807\u5b9e\u73b0\n\u251c\u2500\u2500 README_zh.md                  # \u4e2d\u6587\u6587\u6863\n\u2514\u2500\u2500 README.md                     # \u82f1\u6587\u6587\u6863\n</code></pre>"},{"location":"training-framework/modules/metric/README_zh/#_2","title":"\u6838\u5fc3\u7ec4\u4ef6","text":""},{"location":"training-framework/modules/metric/README_zh/#basemetricparams","title":"BaseMetricParams","text":"<p>\u57fa\u7840\u6307\u6807\u914d\u7f6e\u7c7b - \u4e3a\u6240\u6709\u6307\u6807\u63d0\u4f9b\u7edf\u4e00\u7684\u914d\u7f6e\u63a5\u53e3\uff1a</p> <pre><code>@dataclass(config=ConfigDict(extra=\"allow\"))\nclass BaseMetricParams:\n    \"\"\"\u57fa\u7840\u6307\u6807\u914d\u7f6e\u7c7b\"\"\"\n    _target_: str = Field(default=\"torchmetrics.Metric\")\n    # \u652f\u6301\u901a\u8fc7 extra=\"allow\" \u4f20\u9012\u989d\u5916\u7684\u914d\u7f6e\u53c2\u6570\n</code></pre>"},{"location":"training-framework/modules/metric/README_zh/#metricmanager","title":"MetricManager","text":"<p>\u6307\u6807\u7ba1\u7406\u5668 - \u7edf\u4e00\u7ba1\u7406\u6240\u6709\u8bad\u7ec3\u6307\u6807\uff1a</p> <pre><code>class MetricManager(torch.nn.Module):\n    \"\"\"\n    \u6307\u6807\u7ba1\u7406\u5668 - \u7ba1\u7406\u6307\u6807\u96c6\u5408\u7684\u72b6\u6001\u3001\u8ba1\u7b97\u548c\u65e5\u5fd7\u7b56\u7565\n    \u652f\u6301 DDP \u5206\u5e03\u5f0f\u8bad\u7ec3\n    \"\"\"\n    # \u53cc\u5c42 ModuleDict \u7ed3\u6784\uff1agroup_name -&gt; metric_name -&gt; Metric\n</code></pre>"},{"location":"training-framework/modules/metric/README_zh/#valuerecordermetric","title":"ValueRecorderMetric","text":"<p>\u503c\u8bb0\u5f55\u5668\u6307\u6807 - \u4e13\u95e8\u7528\u4e8e\u8bb0\u5f55\u6807\u91cf\u503c\u7684\u6307\u6807\uff1a</p> <pre><code>class ValueRecorderMetric(Metric):\n    \"\"\"\n    \u6570\u503c\u8bb0\u5f55\u6307\u6807 - \u8bb0\u5f55\u548c\u805a\u5408\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u6807\u91cf\u503c\n    \u652f\u6301\u591a\u79cd\u805a\u5408\u65b9\u5f0f\uff1amean, sum, last\n    \"\"\"\n</code></pre>"},{"location":"training-framework/modules/metric/README_zh/#_3","title":"\u4e3b\u8981\u529f\u80fd","text":""},{"location":"training-framework/modules/metric/README_zh/#_4","title":"\u6307\u6807\u914d\u7f6e\u7ba1\u7406","text":"<ul> <li>\u591a\u79cd\u914d\u7f6e\u65b9\u5f0f\uff1a\u652f\u6301\u914d\u7f6e\u9a71\u52a8\u3001\u76f4\u63a5\u5b9e\u4f8b\u5316\u3001\u5b57\u7b26\u4e32\u3001\u5b57\u5178\u56db\u79cd\u914d\u7f6e\u65b9\u5f0f</li> <li>\u7c7b\u578b\u5b89\u5168\uff1a\u4f7f\u7528 Pydantic \u63d0\u4f9b\u5b8c\u6574\u7684\u7c7b\u578b\u68c0\u67e5\u548c\u9a8c\u8bc1</li> <li>\u7075\u6d3b\u6269\u5c55\uff1a\u901a\u8fc7 <code>extra=\"allow\"</code> \u652f\u6301\u4f20\u9012\u989d\u5916\u53c2\u6570</li> </ul>"},{"location":"training-framework/modules/metric/README_zh/#_5","title":"\u6307\u6807\u5206\u7ec4\u7ba1\u7406","text":"<ul> <li>\u5206\u7ec4\u7ec4\u7ec7\uff1a\u652f\u6301\u5c06\u76f8\u5173\u6307\u6807\u7ec4\u7ec7\u5230\u4e0d\u540c\u7684\u5206\u7ec4\u4e2d</li> <li>\u72ec\u7acb\u914d\u7f6e\uff1a\u6bcf\u4e2a\u5206\u7ec4\u53ef\u4ee5\u6709\u72ec\u7acb\u7684\u65e5\u5fd7\u914d\u7f6e</li> <li>\u6a21\u5757\u5316\u7ba1\u7406\uff1a\u4f7f\u7528 ModuleDict \u4fdd\u8bc1 DDP \u517c\u5bb9\u6027</li> </ul>"},{"location":"training-framework/modules/metric/README_zh/#_6","title":"\u65e5\u5fd7\u914d\u7f6e\u7ba1\u7406","text":"<ul> <li>\u9636\u6bb5\u63a7\u5236\uff1a\u652f\u6301 train/val/test \u4e0d\u540c\u9636\u6bb5\u7684\u65e5\u5fd7\u63a7\u5236</li> <li>\u9891\u7387\u63a7\u5236\uff1a\u652f\u6301\u66f4\u65b0\u9891\u7387\u548c\u8ba1\u7b97\u9891\u7387\u7684\u72ec\u7acb\u914d\u7f6e</li> <li>\u591a\u76ee\u6807\u65e5\u5fd7\uff1a\u652f\u6301\u8fdb\u5ea6\u6761\u3001\u65e5\u5fd7\u8bb0\u5f55\u5668\u3001\u6309\u6b65/\u6309\u5468\u671f\u65e5\u5fd7</li> </ul>"},{"location":"training-framework/modules/metric/README_zh/#_7","title":"\u503c\u8bb0\u5f55\u529f\u80fd","text":"<ul> <li>\u6807\u91cf\u8bb0\u5f55\uff1a\u4e13\u95e8\u7528\u4e8e\u8bb0\u5f55\u635f\u5931\u503c\u3001\u5b66\u4e60\u7387\u7b49\u6807\u91cf\u6307\u6807</li> <li>\u805a\u5408\u8ba1\u7b97\uff1a\u652f\u6301\u5747\u503c\u3001\u6c42\u548c\u3001\u53d6\u6700\u540e\u4e00\u4e2a\u503c\u7b49\u591a\u79cd\u805a\u5408\u65b9\u5f0f</li> <li>\u81ea\u52a8\u7c7b\u578b\u8f6c\u6362\uff1a\u81ea\u52a8\u5904\u7406 Tensor \u548c\u6570\u503c\u7c7b\u578b\u7684\u8f6c\u6362</li> </ul>"},{"location":"training-framework/modules/metric/README_zh/#_8","title":"\u4f7f\u7528\u793a\u4f8b","text":""},{"location":"training-framework/modules/metric/README_zh/#_9","title":"\u57fa\u7840\u4f7f\u7528","text":"<pre><code>from src.metric._manager import MetricManager, MetricManagerConfig\nfrom src.metric.value_recoder import ValueRecorderParams\n\n# \u521b\u5efa\u6307\u6807\u7ba1\u7406\u5668\u914d\u7f6e\nmetric_config = MetricManagerConfig(\n    groups={\n        \"train\": {\n            \"loss\": ValueRecorderParams(name=\"train_loss\"),\n            \"accuracy\": {\"_target_\": \"torchmetrics.Accuracy\", \"task\": \"multiclass\", \"num_classes\": 10}\n        }\n    }\n)\n\n# \u521b\u5efa\u6307\u6807\u7ba1\u7406\u5668\nmetric_manager = MetricManager(metric_config)\n</code></pre>"},{"location":"training-framework/modules/metric/README_zh/#_10","title":"\u9ad8\u7ea7\u914d\u7f6e","text":"<pre><code># \u914d\u7f6e\u65e5\u5fd7\u7b56\u7565\nlog_config = MetricLogConfig(\n    on_step=True,\n    on_epoch=True,\n    prog_bar=True,\n    logger=True\n)\n\n# \u4f7f\u7528\u5206\u7ec4\u7ba1\u7406\nmetric_manager.log_group(\"train\", {\"loss\": 0.5, \"acc\": 0.9}, log_config)\n</code></pre>"},{"location":"training-framework/modules/model/","title":"Model Module","text":"<p>English | \u4e2d\u6587</p> <p>The model module is the core abstraction layer of the deep learning training framework, built on PyTorch Lightning, responsible for integrating networks, optimizers, learning rate schedulers, and metric management, providing unified model training interfaces.</p> <p>Note: This module is a tool class (prefixed with <code>_</code>), following the tool class definitions in the project specifications, commonly used but not frequently modified. For more information, please refer to the Project Architecture Specification.</p>"},{"location":"training-framework/modules/model/#directory-structure","title":"Directory Structure","text":"<pre><code>model/\n\u251c\u2500\u2500 __init__.py                   # Module initialization and type definitions\n\u251c\u2500\u2500 base/                         # Base model abstraction\n\u2502   \u251c\u2500\u2500 __init__.py              # Submodule initialization\n\u2502   \u251c\u2500\u2500 config.py                # Base model configuration class\n\u2502   \u2514\u2500\u2500 model.py                 # Base model implementation\n\u251c\u2500\u2500 tutorial_mnist/               # MNIST model example\n\u2502   \u251c\u2500\u2500 __init__.py              # Submodule initialization\n\u2502   \u251c\u2500\u2500 config.py                # MNIST model configuration class\n\u2502   \u2514\u2500\u2500 model.py                 # MNIST model implementation\n\u251c\u2500\u2500 README_zh.md                  # Chinese documentation\n\u2514\u2500\u2500 README.md                     # English documentation\n</code></pre>"},{"location":"training-framework/modules/model/#core-components","title":"Core Components","text":""},{"location":"training-framework/modules/model/#basemodel","title":"BaseModel","text":"<p>Base model class - inherits from PyTorch Lightning's LightningModule:</p> <pre><code>class BaseModel(LightningModule, ABC):\n    \"\"\"\n    Base model abstract class - provides unified model training interfaces\n    Integrates network, optimizer, scheduler, and metric management\n    \"\"\"\n    def __init__(self, config: BaseModelConfig):\n        super().__init__()\n        self.metric_manager = MetricManager(config.metric_manager)\n</code></pre>"},{"location":"training-framework/modules/model/#basemodelconfig","title":"BaseModelConfig","text":"<p>Base model configuration class - defines the basic configuration structure for models:</p> <pre><code>@dataclass\nclass BaseModelConfig:\n    _target_: str = Field(default=\"src.model.base.model.BaseModel\")\n\n    optimizer: Optional[UnionOptimizerParams] = Field(\n        default_factory=BaseOptimizerParams,\n        description=\"Optimizer configuration\"\n    )\n\n    lr_scheduler: Optional[UnionLRSchedulerParams] = Field(\n        default_factory=BaseLRSchedulerParams,\n        description=\"Learning rate scheduler configuration\"\n    )\n\n    metric_manager: Optional[MetricManagerConfig] = Field(\n        default_factory=MetricManagerConfig\n    )\n</code></pre>"},{"location":"training-framework/modules/model/#mnistmodel","title":"MnistModel","text":"<p>MNIST model example - an example of specific model implementation:</p> <pre><code>class MnistModel(BaseModel):\n    \"\"\"\n    MNIST handwritten digit recognition model\n    Integrates LeNet network and cross-entropy loss\n    \"\"\"\n    def __init__(self, config: MnistModelConfig):\n        super().__init__(config)\n        self.network = LeNet(config.network)\n        self.loss = nn.CrossEntropyLoss()\n</code></pre>"},{"location":"training-framework/modules/model/#main-features","title":"Main Features","text":""},{"location":"training-framework/modules/model/#model-abstraction-layer","title":"Model Abstraction Layer","text":"<ul> <li>Unified interface: Provides standardized training interfaces based on PyTorch Lightning</li> <li>Component integration: Automatically integrates networks, optimizers, schedulers, and metric management</li> <li>Configuration-driven: Supports model instantiation through configuration classes</li> <li>Type safety: Uses Pydantic to provide complete configuration validation</li> </ul>"},{"location":"training-framework/modules/model/#optimizer-management","title":"Optimizer Management","text":"<ul> <li>Flexible configuration: Supports single optimizer or module-level optimizer configuration</li> <li>Automatic instantiation: Automatically creates optimizers through Hydra's instantiate</li> <li>Parameter passing: Automatically passes model parameters to optimizers</li> </ul>"},{"location":"training-framework/modules/model/#learning-rate-scheduler","title":"Learning Rate Scheduler","text":"<ul> <li>Scheduler integration: Seamlessly integrates various learning rate scheduling strategies</li> <li>Dynamic adjustment: Supports dynamic learning rate adjustment during training</li> <li>Monitoring integration: Supports metric-based learning rate scheduling</li> </ul>"},{"location":"training-framework/modules/model/#metric-management","title":"Metric Management","text":"<ul> <li>Unified management: Centralized management of all training metrics</li> <li>Automatic calculation: Automatic calculation and recording of metrics</li> <li>Logging integration: Seamless integration with logging systems</li> </ul>"},{"location":"training-framework/modules/model/#usage-example","title":"Usage Example","text":""},{"location":"training-framework/modules/model/#basic-model-implementation","title":"Basic Model Implementation","text":"<pre><code>from src.model.base import BaseModel, BaseModelConfig\n\nclass MyModel(BaseModel):\n    def __init__(self, config: MyModelConfig):\n        super().__init__(config)\n        self.network = MyNetwork(config.network)\n        self.loss = nn.CrossEntropyLoss()\n\n    def forward(self, x):\n        return self.network(x)\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        y_hat = self(x)\n        loss = self.loss(y_hat, y)\n        return loss\n</code></pre>"},{"location":"training-framework/modules/model/#configuration-usage","title":"Configuration Usage","text":"<pre><code>from src.model import UnionModelConfig, MnistModelConfig\n\n# Create model configuration\nmodel_config = MnistModelConfig(\n    optimizer=AdamParams(lr=1e-3),\n    lr_scheduler=StepLRParams(step_size=30, gamma=0.1),\n    metric_manager=MetricManagerConfig(...)\n)\n\n# Use in project configuration\nproject_config = ProjectConfig(\n    model=model_config\n)\n</code></pre>"},{"location":"training-framework/modules/model/README_zh/","title":"Model Module","text":"<p>English | \u4e2d\u6587</p> <p>\u6a21\u578b\u6a21\u5757\u662f\u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u6846\u67b6\u7684\u6838\u5fc3\u62bd\u8c61\u5c42\uff0c\u57fa\u4e8e PyTorch Lightning \u6784\u5efa\uff0c\u8d1f\u8d23\u6574\u5408\u7f51\u7edc\u3001\u4f18\u5316\u5668\u3001\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\u548c\u6307\u6807\u7ba1\u7406\uff0c\u63d0\u4f9b\u7edf\u4e00\u7684\u6a21\u578b\u8bad\u7ec3\u63a5\u53e3\u3002</p> <p>\u6ce8\u610f: \u6b64\u6a21\u5757\u4e3a\u5de5\u5177\u7c7b\uff08\u4ee5 <code>_</code> \u5f00\u5934\uff09\uff0c\u9075\u5faa\u9879\u76ee\u89c4\u8303\u4e2d\u5de5\u5177\u7c7b\u7684\u5b9a\u4e49\uff0c\u5e38\u7528\u4f46\u4e0d\u5e38\u4fee\u6539\u3002\u5982\u9700\u4e86\u89e3\u66f4\u591a\uff0c\u8bf7\u53c2\u8003 \u9879\u76ee\u67b6\u6784\u89c4\u8303\u3002</p>"},{"location":"training-framework/modules/model/README_zh/#_1","title":"\u76ee\u5f55\u7ed3\u6784","text":"<pre><code>model/\n\u251c\u2500\u2500 __init__.py                   # \u6a21\u5757\u521d\u59cb\u5316\u548c\u7c7b\u578b\u5b9a\u4e49\n\u251c\u2500\u2500 base/                         # \u57fa\u7840\u6a21\u578b\u62bd\u8c61\n\u2502   \u251c\u2500\u2500 __init__.py              # \u5b50\u6a21\u5757\u521d\u59cb\u5316\n\u2502   \u251c\u2500\u2500 config.py                # \u57fa\u7840\u6a21\u578b\u914d\u7f6e\u7c7b\n\u2502   \u2514\u2500\u2500 model.py                 # \u57fa\u7840\u6a21\u578b\u5b9e\u73b0\n\u251c\u2500\u2500 tutorial_mnist/               # MNIST \u6a21\u578b\u793a\u4f8b\n\u2502   \u251c\u2500\u2500 __init__.py              # \u5b50\u6a21\u5757\u521d\u59cb\u5316\n\u2502   \u251c\u2500\u2500 config.py                # MNIST \u6a21\u578b\u914d\u7f6e\u7c7b\n\u2502   \u2514\u2500\u2500 model.py                 # MNIST \u6a21\u578b\u5b9e\u73b0\n\u251c\u2500\u2500 README_zh.md                  # \u4e2d\u6587\u6587\u6863\n\u2514\u2500\u2500 README.md                     # \u82f1\u6587\u6587\u6863\n</code></pre>"},{"location":"training-framework/modules/model/README_zh/#_2","title":"\u6838\u5fc3\u7ec4\u4ef6","text":""},{"location":"training-framework/modules/model/README_zh/#basemodel","title":"BaseModel","text":"<p>\u57fa\u7840\u6a21\u578b\u7c7b - \u7ee7\u627f\u81ea PyTorch Lightning \u7684 LightningModule\uff1a</p> <pre><code>class BaseModel(LightningModule, ABC):\n    \"\"\"\n    \u57fa\u7840\u6a21\u578b\u62bd\u8c61\u7c7b - \u63d0\u4f9b\u7edf\u4e00\u7684\u6a21\u578b\u8bad\u7ec3\u63a5\u53e3\n    \u96c6\u6210\u7f51\u7edc\u3001\u4f18\u5316\u5668\u3001\u8c03\u5ea6\u5668\u548c\u6307\u6807\u7ba1\u7406\n    \"\"\"\n    def __init__(self, config: BaseModelConfig):\n        super().__init__()\n        self.metric_manager = MetricManager(config.metric_manager)\n</code></pre>"},{"location":"training-framework/modules/model/README_zh/#basemodelconfig","title":"BaseModelConfig","text":"<p>\u57fa\u7840\u6a21\u578b\u914d\u7f6e\u7c7b - \u5b9a\u4e49\u6a21\u578b\u7684\u57fa\u672c\u914d\u7f6e\u7ed3\u6784\uff1a</p> <pre><code>@dataclass\nclass BaseModelConfig:\n    _target_: str = Field(default=\"src.model.base.model.BaseModel\")\n\n    optimizer: Optional[UnionOptimizerParams] = Field(\n        default_factory=BaseOptimizerParams,\n        description=\"\u4f18\u5316\u5668\u914d\u7f6e\"\n    )\n\n    lr_scheduler: Optional[UnionLRSchedulerParams] = Field(\n        default_factory=BaseLRSchedulerParams,\n        description=\"\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\u914d\u7f6e\"\n    )\n\n    metric_manager: Optional[MetricManagerConfig] = Field(\n        default_factory=MetricManagerConfig\n    )\n</code></pre>"},{"location":"training-framework/modules/model/README_zh/#mnistmodel","title":"MnistModel","text":"<p>MNIST \u6a21\u578b\u793a\u4f8b - \u5177\u4f53\u6a21\u578b\u5b9e\u73b0\u7684\u793a\u4f8b\uff1a</p> <pre><code>class MnistModel(BaseModel):\n    \"\"\"\n    MNIST \u624b\u5199\u6570\u5b57\u8bc6\u522b\u6a21\u578b\n    \u96c6\u6210 LeNet \u7f51\u7edc\u548c\u4ea4\u53c9\u71b5\u635f\u5931\n    \"\"\"\n    def __init__(self, config: MnistModelConfig):\n        super().__init__(config)\n        self.network = LeNet(config.network)\n        self.loss = nn.CrossEntropyLoss()\n</code></pre>"},{"location":"training-framework/modules/model/README_zh/#_3","title":"\u4e3b\u8981\u529f\u80fd","text":""},{"location":"training-framework/modules/model/README_zh/#_4","title":"\u6a21\u578b\u62bd\u8c61\u5c42","text":"<ul> <li>\u7edf\u4e00\u63a5\u53e3\uff1a\u57fa\u4e8e PyTorch Lightning \u63d0\u4f9b\u6807\u51c6\u5316\u7684\u8bad\u7ec3\u63a5\u53e3</li> <li>\u7ec4\u4ef6\u96c6\u6210\uff1a\u81ea\u52a8\u96c6\u6210\u7f51\u7edc\u3001\u4f18\u5316\u5668\u3001\u8c03\u5ea6\u5668\u548c\u6307\u6807\u7ba1\u7406</li> <li>\u914d\u7f6e\u9a71\u52a8\uff1a\u652f\u6301\u901a\u8fc7\u914d\u7f6e\u7c7b\u8fdb\u884c\u6a21\u578b\u5b9e\u4f8b\u5316</li> <li>\u7c7b\u578b\u5b89\u5168\uff1a\u4f7f\u7528 Pydantic \u63d0\u4f9b\u5b8c\u6574\u7684\u914d\u7f6e\u9a8c\u8bc1</li> </ul>"},{"location":"training-framework/modules/model/README_zh/#_5","title":"\u4f18\u5316\u5668\u7ba1\u7406","text":"<ul> <li>\u7075\u6d3b\u914d\u7f6e\uff1a\u652f\u6301\u5355\u4e2a\u4f18\u5316\u5668\u6216\u6a21\u5757\u7ea7\u4f18\u5316\u5668\u914d\u7f6e</li> <li>\u81ea\u52a8\u5b9e\u4f8b\u5316\uff1a\u901a\u8fc7 Hydra \u7684 instantiate \u81ea\u52a8\u521b\u5efa\u4f18\u5316\u5668</li> <li>\u53c2\u6570\u4f20\u9012\uff1a\u81ea\u52a8\u5c06\u6a21\u578b\u53c2\u6570\u4f20\u9012\u7ed9\u4f18\u5316\u5668</li> </ul>"},{"location":"training-framework/modules/model/README_zh/#_6","title":"\u5b66\u4e60\u7387\u8c03\u5ea6\u5668","text":"<ul> <li>\u8c03\u5ea6\u96c6\u6210\uff1a\u65e0\u7f1d\u96c6\u6210\u5404\u79cd\u5b66\u4e60\u7387\u8c03\u5ea6\u7b56\u7565</li> <li>\u52a8\u6001\u8c03\u6574\uff1a\u652f\u6301\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u5b66\u4e60\u7387\u52a8\u6001\u8c03\u6574</li> <li>\u76d1\u63a7\u96c6\u6210\uff1a\u652f\u6301\u57fa\u4e8e\u6307\u6807\u7684\u5b66\u4e60\u7387\u8c03\u5ea6</li> </ul>"},{"location":"training-framework/modules/model/README_zh/#_7","title":"\u6307\u6807\u7ba1\u7406","text":"<ul> <li>\u7edf\u4e00\u7ba1\u7406\uff1a\u96c6\u4e2d\u7ba1\u7406\u6240\u6709\u8bad\u7ec3\u6307\u6807</li> <li>\u81ea\u52a8\u8ba1\u7b97\uff1a\u81ea\u52a8\u8ba1\u7b97\u548c\u8bb0\u5f55\u6307\u6807</li> <li>\u65e5\u5fd7\u96c6\u6210\uff1a\u4e0e\u65e5\u5fd7\u7cfb\u7edf\u65e0\u7f1d\u96c6\u6210</li> </ul>"},{"location":"training-framework/modules/model/README_zh/#_8","title":"\u4f7f\u7528\u793a\u4f8b","text":""},{"location":"training-framework/modules/model/README_zh/#_9","title":"\u57fa\u7840\u6a21\u578b\u5b9e\u73b0","text":"<pre><code>from src.model.base import BaseModel, BaseModelConfig\n\nclass MyModel(BaseModel):\n    def __init__(self, config: MyModelConfig):\n        super().__init__(config)\n        self.network = MyNetwork(config.network)\n        self.loss = nn.CrossEntropyLoss()\n\n    def forward(self, x):\n        return self.network(x)\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        y_hat = self(x)\n        loss = self.loss(y_hat, y)\n        return loss\n</code></pre>"},{"location":"training-framework/modules/model/README_zh/#_10","title":"\u914d\u7f6e\u4f7f\u7528","text":"<pre><code>from src.model import UnionModelConfig, MnistModelConfig\n\n# \u521b\u5efa\u6a21\u578b\u914d\u7f6e\nmodel_config = MnistModelConfig(\n    optimizer=AdamParams(lr=1e-3),\n    lr_scheduler=StepLRParams(step_size=30, gamma=0.1),\n    metric_manager=MetricManagerConfig(...)\n)\n\n# \u5728\u9879\u76ee\u914d\u7f6e\u4e2d\u4f7f\u7528\nproject_config = ProjectConfig(\n    model=model_config\n)\n</code></pre>"},{"location":"training-framework/modules/network/","title":"Network Module","text":"<p>English | \u4e2d\u6587</p> <p>The network module focuses on neural network architecture definitions, decoupled from training logic.</p>"},{"location":"training-framework/modules/network/#directory-structure","title":"Directory Structure","text":"<pre><code>network/\n\u251c\u2500\u2500 base/              # Base network abstract classes\n\u2502   \u251c\u2500\u2500 network.py     # BaseNetwork base class\n\u2502   \u2514\u2500\u2500 config.py      # Network configuration class\n\u2514\u2500\u2500 tutorial_lenet/    # LeNet tutorial implementation\n    \u251c\u2500\u2500 network.py     # LeNet network implementation\n    \u2514\u2500\u2500 config.py      # LeNet configuration\n</code></pre>"},{"location":"training-framework/modules/network/#core-components","title":"Core Components","text":""},{"location":"training-framework/modules/network/#basenetwork","title":"BaseNetwork","text":"<p>Base class for all network architectures, providing unified interfaces:</p> <pre><code>class BaseNetwork(torch.nn.Module, ABC):\n    @abstractmethod\n    def forward(self, x):\n        \"\"\"Network forward propagation\"\"\"\n        pass\n</code></pre>"},{"location":"training-framework/modules/network/#usage-example","title":"Usage Example","text":"<pre><code>from src.network.tutorial_lenet.network import LeNet\nfrom src.network.tutorial_lenet.config import LeNetConfig\n\n# Configure network\nconfig = LeNetConfig(num_classes=10)\nnetwork = LeNet(config)\n\n# Use network\noutput = network(input_tensor)\n</code></pre>"},{"location":"training-framework/modules/network/#main-features","title":"Main Features","text":""},{"location":"training-framework/modules/network/#network-architecture-abstraction","title":"Network Architecture Abstraction","text":"<ul> <li>Unified interface: Standardized network forward propagation interface</li> <li>Modular design: Supports complex network architecture combinations</li> <li>Configuration management: Manages network parameters through configuration classes</li> <li>Type safety: Configuration validation using Pydantic</li> </ul>"},{"location":"training-framework/modules/network/#lenet-implementation","title":"LeNet Implementation","text":"<p>Specific implementation of LeNet network:</p> <pre><code>class LeNet(BaseNetwork):\n    def __init__(self, config: LeNetConfig):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, config.num_classes)\n\n    def forward(self, x):\n        # Convolutional layers\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n\n        # Fully connected layers\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n</code></pre>"},{"location":"training-framework/modules/network/#extension-guidelines","title":"Extension Guidelines","text":"<p>To add new network architectures:</p> <ol> <li>Create a new folder under <code>network/</code></li> <li>Implement network class inheriting from <code>BaseNetwork</code> (not mandatory)</li> <li>Create corresponding configuration class</li> <li>Update <code>__init__.py</code> to export new network</li> </ol>"},{"location":"training-framework/modules/network/README_zh/","title":"Network Module","text":"<p>English | \u4e2d\u6587</p> <p>\u7f51\u7edc\u6a21\u5757\u4e13\u6ce8\u4e8e\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u7684\u5b9a\u4e49\uff0c\u4e0e\u8bad\u7ec3\u903b\u8f91\u89e3\u8026\u3002</p>"},{"location":"training-framework/modules/network/README_zh/#_1","title":"\u76ee\u5f55\u7ed3\u6784","text":"<pre><code>network/\n\u251c\u2500\u2500 base/              # \u57fa\u7840\u7f51\u7edc\u62bd\u8c61\u7c7b\n\u2502   \u251c\u2500\u2500 network.py     # BaseNetwork \u57fa\u7c7b\n\u2502   \u2514\u2500\u2500 config.py      # \u7f51\u7edc\u914d\u7f6e\u7c7b\n\u2514\u2500\u2500 tutorial_lenet/    # LeNet \u6559\u7a0b\u5b9e\u73b0\n    \u251c\u2500\u2500 network.py     # LeNet \u7f51\u7edc\u5b9e\u73b0\n    \u2514\u2500\u2500 config.py      # LeNet \u914d\u7f6e\n</code></pre>"},{"location":"training-framework/modules/network/README_zh/#_2","title":"\u6838\u5fc3\u7ec4\u4ef6","text":""},{"location":"training-framework/modules/network/README_zh/#basenetwork","title":"BaseNetwork","text":"<p>\u6240\u6709\u7f51\u7edc\u67b6\u6784\u7684\u57fa\u7c7b\uff0c\u63d0\u4f9b\u7edf\u4e00\u7684\u63a5\u53e3\uff1a</p> <pre><code>class BaseNetwork(torch.nn.Module, ABC):\n    @abstractmethod\n    def forward(self, x):\n        \"\"\"\u7f51\u7edc\u524d\u5411\u4f20\u64ad\"\"\"\n        pass\n</code></pre>"},{"location":"training-framework/modules/network/README_zh/#_3","title":"\u4f7f\u7528\u793a\u4f8b","text":"<pre><code>from src.network.tutorial_lenet.network import LeNet\nfrom src.network.tutorial_lenet.config import LeNetConfig\n\n# \u914d\u7f6e\u7f51\u7edc\nconfig = LeNetConfig(num_classes=10)\nnetwork = LeNet(config)\n\n# \u4f7f\u7528\u7f51\u7edc\noutput = network(input_tensor)\n</code></pre>"},{"location":"training-framework/modules/network/README_zh/#_4","title":"\u4e3b\u8981\u529f\u80fd","text":""},{"location":"training-framework/modules/network/README_zh/#_5","title":"\u7f51\u7edc\u67b6\u6784\u62bd\u8c61","text":"<ul> <li>\u7edf\u4e00\u63a5\u53e3\uff1a\u6807\u51c6\u5316\u7684\u7f51\u7edc\u524d\u5411\u4f20\u64ad\u63a5\u53e3</li> <li>\u6a21\u5757\u5316\u8bbe\u8ba1\uff1a\u652f\u6301\u590d\u6742\u7684\u7f51\u7edc\u67b6\u6784\u7ec4\u5408</li> <li>\u914d\u7f6e\u7ba1\u7406\uff1a\u901a\u8fc7\u914d\u7f6e\u7c7b\u7ba1\u7406\u7f51\u7edc\u53c2\u6570</li> <li>\u7c7b\u578b\u5b89\u5168\uff1a\u57fa\u4e8e Pydantic \u7684\u914d\u7f6e\u9a8c\u8bc1</li> </ul>"},{"location":"training-framework/modules/network/README_zh/#lenet","title":"LeNet \u5b9e\u73b0","text":"<p>LeNet \u7f51\u7edc\u7684\u5177\u4f53\u5b9e\u73b0\uff1a</p> <pre><code>class LeNet(BaseNetwork):\n    def __init__(self, config: LeNetConfig):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, config.num_classes)\n\n    def forward(self, x):\n        # \u5377\u79ef\u5c42\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n\n        # \u5168\u8fde\u63a5\u5c42\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n</code></pre>"},{"location":"training-framework/modules/network/README_zh/#_6","title":"\u6269\u5c55\u6307\u5357","text":"<p>\u8981\u6dfb\u52a0\u65b0\u7684\u7f51\u7edc\u67b6\u6784\uff1a</p> <ol> <li>\u5728 <code>network/</code> \u4e0b\u521b\u5efa\u65b0\u6587\u4ef6\u5939</li> <li>\u7ee7\u627f <code>BaseNetwork</code> \u5b9e\u73b0\u7f51\u7edc\u7c7b\uff08\u4e0d\u5f3a\u5236\uff09</li> <li>\u521b\u5efa\u5bf9\u5e94\u7684\u914d\u7f6e\u7c7b</li> <li>\u66f4\u65b0 <code>__init__.py</code> \u5bfc\u51fa\u65b0\u7f51\u7edc</li> </ol>"},{"location":"training-framework/modules/optimizer/","title":"Optimizer Module","text":"<p>English | \u4e2d\u6587</p> <p>The optimizer module focuses on configuration and management of model parameter optimization, decoupled from training logic.</p> <p>Note: This module is a tool class (prefixed with <code>_</code>), following the tool class definitions in the project specifications, commonly used but not frequently modified. For more information, please refer to the Project Architecture Specification.</p>"},{"location":"training-framework/modules/optimizer/#directory-structure","title":"Directory Structure","text":"<pre><code>_optimizer/\n\u251c\u2500\u2500 base/              # Base optimizer parameter abstract classes\n\u2502   \u2514\u2500\u2500 config.py      # BaseOptimizerParams base class\n\u251c\u2500\u2500 adam/              # Adam optimizer\n\u2502   \u2514\u2500\u2500 config.py      # AdamParams parameter class\n\u251c\u2500\u2500 sgd/               # SGD optimizer\n\u2502   \u2514\u2500\u2500 config.py      # SGDParams parameter class\n\u251c\u2500\u2500 adamw/             # AdamW optimizer\n\u2502   \u2514\u2500\u2500 config.py      # AdamWParams parameter class\n\u251c\u2500\u2500 adadelta/          # AdaDelta optimizer\n\u2502   \u2514\u2500\u2500 config.py      # AdaDeltaParams parameter class\n\u251c\u2500\u2500 adagrad/           # AdaGrad optimizer\n\u2502   \u2514\u2500\u2500 config.py      # AdaGradParams parameter class\n\u251c\u2500\u2500 rmsprop/           # RMSProp optimizer\n\u2502   \u2514\u2500\u2500 config.py      # RMSPropParams parameter class\n\u251c\u2500\u2500 rprop/             # RProp optimizer\n\u2502   \u2514\u2500\u2500 config.py      # RPropParams parameter class\n\u251c\u2500\u2500 lbfgs/             # LBFGS optimizer\n\u2502   \u2514\u2500\u2500 config.py      # LBFGSParams parameter class\n\u2514\u2500\u2500 __init__.py        # Module initialization\n</code></pre>"},{"location":"training-framework/modules/optimizer/#core-components","title":"Core Components","text":""},{"location":"training-framework/modules/optimizer/#baseoptimizerparams","title":"BaseOptimizerParams","text":"<p>Base class for all optimizer parameters:</p> <pre><code>@dataclass\nclass BaseOptimizerParams:\n    \"\"\"Optimizer parameters base class\"\"\"\n\n    _target_: str = Field(\"torch.optim.Adam\", description=\"Optimizer class\")\n    lr: float = Field(1e-3, description=\"Learning rate\")\n    weight_decay: float = Field(0.0, description=\"Weight decay (L2 penalty)\")\n</code></pre>"},{"location":"training-framework/modules/optimizer/#unionoptimizerparams","title":"UnionOptimizerParams","text":"<p>Unified optimizer parameters type:</p> <pre><code>UnionOptimizerParams = Union[\n    BaseOptimizerParams,\n    AdamParams,\n    SGDParams,\n    AdamWParams,\n    AdaDeltaParams,\n    AdaGradParams,\n    RMSPropParams,\n    RPropParams,\n    LBFGSParams,\n    dict,  # Allow dict for backward compatibility\n]\n</code></pre>"},{"location":"training-framework/modules/optimizer/#supported-optimizers","title":"Supported Optimizers","text":"<ul> <li>Adam: Adaptive Moment Estimation optimizer</li> <li>SGD: Stochastic Gradient Descent</li> <li>AdamW: Adam with weight decay regularization</li> <li>AdaDelta: Adaptive learning rate optimizer</li> <li>AdaGrad: Adaptive Gradient optimizer</li> <li>RMSProp: Root Mean Square Propagation optimizer</li> <li>RProp: Resilient Backpropagation optimizer</li> <li>LBFGS: Limited-memory BFGS optimizer</li> </ul>"},{"location":"training-framework/modules/optimizer/#main-features","title":"Main Features","text":""},{"location":"training-framework/modules/optimizer/#optimization-algorithm-diversity","title":"Optimization Algorithm Diversity","text":"<ul> <li>First-order optimization: Gradient-based optimization algorithms</li> <li>Adaptive optimization: Adjust learning rate according to parameter history</li> <li>Regularization: Support for regularization techniques such as weight decay</li> <li>Momentum optimization: Support for momentum and Nesterov momentum</li> </ul>"},{"location":"training-framework/modules/optimizer/#configuration-management","title":"Configuration Management","text":"<ul> <li>Learning rate control: Flexible learning rate settings</li> <li>Weight decay: L2 regularization parameters</li> <li>Algorithm parameters: Specific parameters for each optimizer</li> <li>Type safety: Configuration validation and type checking using Pydantic</li> </ul>"},{"location":"training-framework/modules/optimizer/#usage-example","title":"Usage Example","text":"<pre><code>from src._optimizer import UnionOptimizerParams, AdamParams\n\n# Create Adam optimizer parameters\nadam_params = AdamParams(\n    lr=1e-3,\n    weight_decay=1e-4,\n    betas=(0.9, 0.999)\n)\n\n# Use in configuration\nconfig = SomeConfig(\n    optimizer=adam_params\n)\n</code></pre>"},{"location":"training-framework/modules/optimizer/README_zh/","title":"Optimizer Module","text":"<p>English | \u4e2d\u6587</p> <p>\u4f18\u5316\u5668\u6a21\u5757\u4e13\u6ce8\u4e8e\u6a21\u578b\u53c2\u6570\u4f18\u5316\u7684\u914d\u7f6e\u548c\u7ba1\u7406\uff0c\u4e0e\u8bad\u7ec3\u903b\u8f91\u89e3\u8026\u3002</p> <p>\u6ce8\u610f: \u6b64\u6a21\u5757\u4e3a\u5de5\u5177\u7c7b\uff08\u4ee5 <code>_</code> \u5f00\u5934\uff09\uff0c\u9075\u5faa\u9879\u76ee\u89c4\u8303\u4e2d\u5de5\u5177\u7c7b\u7684\u5b9a\u4e49\uff0c\u5e38\u7528\u4f46\u4e0d\u5e38\u4fee\u6539\u3002\u5982\u9700\u4e86\u89e3\u66f4\u591a\uff0c\u8bf7\u53c2\u8003 \u9879\u76ee\u67b6\u6784\u89c4\u8303\u3002</p>"},{"location":"training-framework/modules/optimizer/README_zh/#_1","title":"\u76ee\u5f55\u7ed3\u6784","text":"<pre><code>_optimizer/\n\u251c\u2500\u2500 base/              # \u57fa\u7840\u4f18\u5316\u5668\u53c2\u6570\u62bd\u8c61\u7c7b\n\u2502   \u2514\u2500\u2500 config.py      # BaseOptimizerParams \u57fa\u7c7b\n\u251c\u2500\u2500 adam/              # Adam \u4f18\u5316\u5668\n\u2502   \u2514\u2500\u2500 config.py      # AdamParams \u53c2\u6570\u7c7b\n\u251c\u2500\u2500 sgd/               # SGD \u4f18\u5316\u5668\n\u2502   \u2514\u2500\u2500 config.py      # SGDParams \u53c2\u6570\u7c7b\n\u251c\u2500\u2500 adamw/             # AdamW \u4f18\u5316\u5668\n\u2502   \u2514\u2500\u2500 config.py      # AdamWParams \u53c2\u6570\u7c7b\n\u251c\u2500\u2500 adadelta/          # AdaDelta \u4f18\u5316\u5668\n\u2502   \u2514\u2500\u2500 config.py      # AdaDeltaParams \u53c2\u6570\u7c7b\n\u251c\u2500\u2500 adagrad/           # AdaGrad \u4f18\u5316\u5668\n\u2502   \u2514\u2500\u2500 config.py      # AdaGradParams \u53c2\u6570\u7c7b\n\u251c\u2500\u2500 rmsprop/           # RMSProp \u4f18\u5316\u5668\n\u2502   \u2514\u2500\u2500 config.py      # RMSPropParams \u53c2\u6570\u7c7b\n\u251c\u2500\u2500 rprop/             # RProp \u4f18\u5316\u5668\n\u2502   \u2514\u2500\u2500 config.py      # RPropParams \u53c2\u6570\u7c7b\n\u251c\u2500\u2500 lbfgs/             # LBFGS \u4f18\u5316\u5668\n\u2502   \u2514\u2500\u2500 config.py      # LBFGSParams \u53c2\u6570\u7c7b\n\u2514\u2500\u2500 __init__.py        # \u6a21\u5757\u521d\u59cb\u5316\n</code></pre>"},{"location":"training-framework/modules/optimizer/README_zh/#_2","title":"\u6838\u5fc3\u7ec4\u4ef6","text":""},{"location":"training-framework/modules/optimizer/README_zh/#baseoptimizerparams","title":"BaseOptimizerParams","text":"<p>\u6240\u6709\u4f18\u5316\u5668\u53c2\u6570\u7684\u57fa\u7c7b\uff1a</p> <pre><code>@dataclass\nclass BaseOptimizerParams:\n    \"\"\"\u4f18\u5316\u5668\u53c2\u6570\u57fa\u7c7b\"\"\"\n\n    _target_: str = Field(\"torch.optim.Adam\", description=\"Optimizer class\")\n    lr: float = Field(1e-3, description=\"Learning rate\")\n    weight_decay: float = Field(0.0, description=\"Weight decay (L2 penalty)\")\n</code></pre>"},{"location":"training-framework/modules/optimizer/README_zh/#unionoptimizerparams","title":"UnionOptimizerParams","text":"<p>\u7edf\u4e00\u7684\u4f18\u5316\u5668\u53c2\u6570\u7c7b\u578b\uff1a</p> <pre><code>UnionOptimizerParams = Union[\n    BaseOptimizerParams,\n    AdamParams,\n    SGDParams,\n    AdamWParams,\n    AdaDeltaParams,\n    AdaGradParams,\n    RMSPropParams,\n    RPropParams,\n    LBFGSParams,\n    dict,  # Allow dict for backward compatibility\n]\n</code></pre>"},{"location":"training-framework/modules/optimizer/README_zh/#_3","title":"\u652f\u6301\u7684\u4f18\u5316\u5668","text":"<ul> <li>Adam: \u81ea\u9002\u5e94\u77e9\u4f30\u8ba1\u4f18\u5316\u5668</li> <li>SGD: \u968f\u673a\u68af\u5ea6\u4e0b\u964d</li> <li>AdamW: Adam with weight decay regularization</li> <li>AdaDelta: \u81ea\u9002\u5e94\u5b66\u4e60\u7387\u4f18\u5316\u5668</li> <li>AdaGrad: \u81ea\u9002\u5e94\u68af\u5ea6\u4f18\u5316\u5668</li> <li>RMSProp: \u5747\u65b9\u6839\u4f20\u64ad\u4f18\u5316\u5668</li> <li>RProp: \u5f39\u6027\u53cd\u5411\u4f20\u64ad\u4f18\u5316\u5668</li> <li>LBFGS: \u6709\u9650\u5185\u5b58 BFGS \u4f18\u5316\u5668</li> </ul>"},{"location":"training-framework/modules/optimizer/README_zh/#_4","title":"\u4e3b\u8981\u529f\u80fd","text":""},{"location":"training-framework/modules/optimizer/README_zh/#_5","title":"\u4f18\u5316\u7b97\u6cd5\u591a\u6837\u6027","text":"<ul> <li>\u4e00\u9636\u4f18\u5316\uff1a\u57fa\u4e8e\u68af\u5ea6\u7684\u4f18\u5316\u7b97\u6cd5</li> <li>\u81ea\u9002\u5e94\u4f18\u5316\uff1a\u6839\u636e\u53c2\u6570\u5386\u53f2\u8c03\u6574\u5b66\u4e60\u7387</li> <li>\u6b63\u5219\u5316\uff1a\u652f\u6301\u6743\u91cd\u8870\u51cf\u7b49\u6b63\u5219\u5316\u6280\u672f</li> <li>\u52a8\u91cf\u4f18\u5316\uff1a\u652f\u6301\u52a8\u91cf\u548c Nesterov \u52a8\u91cf</li> </ul>"},{"location":"training-framework/modules/optimizer/README_zh/#_6","title":"\u914d\u7f6e\u7ba1\u7406","text":"<ul> <li>\u5b66\u4e60\u7387\u63a7\u5236\uff1a\u7075\u6d3b\u7684\u5b66\u4e60\u7387\u8bbe\u7f6e</li> <li>\u6743\u91cd\u8870\u51cf\uff1aL2 \u6b63\u5219\u5316\u53c2\u6570</li> <li>\u7b97\u6cd5\u53c2\u6570\uff1a\u5404\u4f18\u5316\u5668\u7279\u6709\u7684\u53c2\u6570\u914d\u7f6e</li> <li>\u7c7b\u578b\u5b89\u5168\uff1a\u57fa\u4e8e Pydantic \u7684\u914d\u7f6e\u9a8c\u8bc1</li> </ul>"},{"location":"training-framework/modules/optimizer/README_zh/#_7","title":"\u4f7f\u7528\u793a\u4f8b","text":"<pre><code>from src._optimizer import UnionOptimizerParams, AdamParams\n\n# \u521b\u5efa Adam \u4f18\u5316\u5668\u53c2\u6570\nadam_params = AdamParams(\n    lr=1e-3,\n    weight_decay=1e-4,\n    betas=(0.9, 0.999)\n)\n\n# \u5728\u914d\u7f6e\u4e2d\u4f7f\u7528\nconfig = SomeConfig(\n    optimizer=adam_params\n)\n</code></pre>"},{"location":"training-framework/modules/project/","title":"Project Module","text":"<p>English | \u4e2d\u6587</p> <p>The project module focuses on the organization and execution of the entire training project, unifying management of all training components.</p> <p>Note: This module is a tool class (prefixed with <code>_</code>), following the tool class definitions in the project specifications, commonly used but not frequently modified. For more information, please refer to the Project Architecture Specification.</p>"},{"location":"training-framework/modules/project/#directory-structure","title":"Directory Structure","text":"<pre><code>_project/\n\u251c\u2500\u2500 base/              # Base project management abstract classes\n\u2502   \u251c\u2500\u2500 project.py     # ProjectManager core class\n\u2502   \u2514\u2500\u2500 config.py      # ProjectConfig configuration class\n\u2514\u2500\u2500 __init__.py        # Module initialization\n</code></pre>"},{"location":"training-framework/modules/project/#core-components","title":"Core Components","text":""},{"location":"training-framework/modules/project/#projectmanager","title":"ProjectManager","text":"<p>Project manager - the core class that integrates all training components:</p> <pre><code>class ProjectManager:\n    \"\"\"\n    Project manager - the core class that integrates all components\n\n    Design philosophy:\n    - Serves as the unified entry point for all training components\n    - Directly uses native PyTorch Lightning Trainer\n    - Manages all parameters through configuration without additional packaging\n    - Supports complete training lifecycle management\n    \"\"\"\n\n    def __init__(self, config: ProjectConfig):\n        self.config = config\n        # Core components\n        self.model: Optional[LightningModule] = None\n        self.datamodule: Optional[LightningDataModule] = None\n        self.trainer: Optional[Trainer] = None\n</code></pre>"},{"location":"training-framework/modules/project/#projectconfig","title":"ProjectConfig","text":"<p>Project-level configuration class - unifies management of the entire training project's configuration:</p> <pre><code>@dataclass\nclass ProjectConfig:\n    \"\"\"Project-level configuration class - unifies management of the entire training project's configuration\"\"\"\n\n    # Project metadata\n    name: str = \"training_project\"\n    description: str = \"\"\n    version: str = \"1.0.0\"\n\n    # Output settings\n    output_dir: str = \"./outputs\"\n    experiment_name: Optional[str] = None\n\n    # Core component configurations\n    model: UnionModelConfig\n    datamodule: Optional[UnionDataModuleConfig] = None\n    trainer: Optional[UnionTrainerConfig] = None\n</code></pre>"},{"location":"training-framework/modules/project/#main-features","title":"Main Features","text":""},{"location":"training-framework/modules/project/#unified-component-management","title":"Unified Component Management","text":"<ul> <li>Component coordination: Coordinates model, datamodule, trainer, callbacks, loggers, etc.</li> <li>Lifecycle management: Complete training, validation, testing processes</li> <li>Configuration-driven: Manages all parameters through configuration</li> <li>Modular design: Supports flexible component combinations</li> </ul>"},{"location":"training-framework/modules/project/#one-stop-training-interface","title":"One-Stop Training Interface","text":"<ul> <li>Simplified process: Unified training entry point</li> <li>Automatic configuration: Automatically handles dependencies between components</li> <li>State management: Maintains state information during training</li> <li>Error handling: Unified exception handling mechanism</li> </ul>"},{"location":"training-framework/modules/project/#experiment-management","title":"Experiment Management","text":"<ul> <li>Experiment tracking: Records experiment configurations and results</li> <li>Version control: Supports experiment version management and reproduction</li> <li>Result management: Automatically saves and organizes training results</li> <li>Comparative analysis: Supports multi-experiment comparison and analysis</li> </ul>"},{"location":"training-framework/modules/project/#usage-example","title":"Usage Example","text":"<pre><code>from src._project.base.project import ProjectManager\nfrom src._project.base.config import ProjectConfig\n\n# Create project configuration\nconfig = ProjectConfig(\n    name=\"my_experiment\",\n    model=model_config,\n    datamodule=datamodule_config,\n    trainer=trainer_config\n)\n\n# Create project manager\nproject = ProjectManager(config)\n\n# Execute training\nproject.fit()\n</code></pre>"},{"location":"training-framework/modules/project/#extension-guidelines","title":"Extension Guidelines","text":"<p>To extend project management functionality:</p> <ol> <li>Add new management methods in <code>ProjectManager</code></li> <li>Extend <code>ProjectConfig</code> to support new configuration options</li> <li>Add new lifecycle management hooks</li> <li>Update component integration logic</li> </ol>"},{"location":"training-framework/modules/project/README_zh/","title":"Project Module","text":"<p>English | \u4e2d\u6587</p> <p>\u9879\u76ee\u6a21\u5757\u4e13\u6ce8\u4e8e\u6574\u4e2a\u8bad\u7ec3\u9879\u76ee\u7684\u7ec4\u7ec7\u548c\u6267\u884c\uff0c\u7edf\u4e00\u7ba1\u7406\u6240\u6709\u8bad\u7ec3\u7ec4\u4ef6\u3002</p> <p>\u6ce8\u610f: \u6b64\u6a21\u5757\u4e3a\u5de5\u5177\u7c7b\uff08\u4ee5 <code>_</code> \u5f00\u5934\uff09\uff0c\u9075\u5faa\u9879\u76ee\u89c4\u8303\u4e2d\u5de5\u5177\u7c7b\u7684\u5b9a\u4e49\uff0c\u5e38\u7528\u4f46\u4e0d\u5e38\u4fee\u6539\u3002\u5982\u9700\u4e86\u89e3\u66f4\u591a\uff0c\u8bf7\u53c2\u8003 \u9879\u76ee\u67b6\u6784\u89c4\u8303\u3002</p>"},{"location":"training-framework/modules/project/README_zh/#_1","title":"\u76ee\u5f55\u7ed3\u6784","text":"<pre><code>_project/\n\u251c\u2500\u2500 base/              # \u57fa\u7840\u9879\u76ee\u7ba1\u7406\u62bd\u8c61\u7c7b\n\u2502   \u251c\u2500\u2500 project.py     # ProjectManager \u6838\u5fc3\u7c7b\n\u2502   \u2514\u2500\u2500 config.py      # ProjectConfig \u914d\u7f6e\u7c7b\n\u2514\u2500\u2500 __init__.py        # \u6a21\u5757\u521d\u59cb\u5316\n</code></pre>"},{"location":"training-framework/modules/project/README_zh/#_2","title":"\u6838\u5fc3\u7ec4\u4ef6","text":""},{"location":"training-framework/modules/project/README_zh/#projectmanager","title":"ProjectManager","text":"<p>\u9879\u76ee\u7ba1\u7406\u5668 - \u7edf\u6574\u6240\u6709\u8bad\u7ec3\u7ec4\u4ef6\u7684\u6838\u5fc3\u7c7b\uff1a</p> <pre><code>class ProjectManager:\n    \"\"\"\n    \u9879\u76ee\u7ba1\u7406\u5668 - \u7edf\u6574\u6240\u6709\u7ec4\u4ef6\u7684\u6838\u5fc3\u7c7b\n\n    \u8bbe\u8ba1\u7406\u5ff5\uff1a\n    - \u4f5c\u4e3a\u6240\u6709\u8bad\u7ec3\u7ec4\u4ef6\u7684\u7edf\u4e00\u5165\u53e3\n    - \u76f4\u63a5\u4f7f\u7528 PyTorch Lightning \u539f\u751f Trainer\n    - \u901a\u8fc7\u914d\u7f6e\u7ba1\u7406\u6240\u6709\u53c2\u6570\uff0c\u65e0\u9700\u989d\u5916\u5305\u88c5\n    - \u652f\u6301\u5b8c\u6574\u7684\u8bad\u7ec3\u751f\u547d\u5468\u671f\u7ba1\u7406\n    \"\"\"\n\n    def __init__(self, config: ProjectConfig):\n        self.config = config\n        # \u6838\u5fc3\u7ec4\u4ef6\n        self.model: Optional[LightningModule] = None\n        self.datamodule: Optional[LightningDataModule] = None\n        self.trainer: Optional[Trainer] = None\n</code></pre>"},{"location":"training-framework/modules/project/README_zh/#projectconfig","title":"ProjectConfig","text":"<p>\u9879\u76ee\u7ea7\u914d\u7f6e\u7c7b - \u7edf\u4e00\u7ba1\u7406\u6574\u4e2a\u8bad\u7ec3\u9879\u76ee\u7684\u914d\u7f6e\uff1a</p> <pre><code>@dataclass\nclass ProjectConfig:\n    \"\"\"\u9879\u76ee\u7ea7\u914d\u7f6e\u7c7b - \u7edf\u4e00\u7ba1\u7406\u6574\u4e2a\u8bad\u7ec3\u9879\u76ee\u7684\u914d\u7f6e\"\"\"\n\n    # \u9879\u76ee\u5143\u4fe1\u606f\n    name: str = \"training_project\"\n    description: str = \"\"\n    version: str = \"1.0.0\"\n\n    # \u8f93\u51fa\u8bbe\u7f6e\n    output_dir: str = \"./outputs\"\n    experiment_name: Optional[str] = None\n\n    # \u6838\u5fc3\u7ec4\u4ef6\u914d\u7f6e\n    model: UnionModelConfig\n    datamodule: Optional[UnionDataModuleConfig] = None\n    trainer: Optional[UnionTrainerConfig] = None\n</code></pre>"},{"location":"training-framework/modules/project/README_zh/#_3","title":"\u4e3b\u8981\u529f\u80fd","text":""},{"location":"training-framework/modules/project/README_zh/#_4","title":"\u7edf\u4e00\u7ec4\u4ef6\u7ba1\u7406","text":"<ul> <li>\u7ec4\u4ef6\u534f\u8c03\uff1a\u534f\u8c03 model\u3001datamodule\u3001trainer\u3001callbacks\u3001loggers \u7b49</li> <li>\u751f\u547d\u5468\u671f\u7ba1\u7406\uff1a\u5b8c\u6574\u7684\u8bad\u7ec3\u3001\u9a8c\u8bc1\u3001\u6d4b\u8bd5\u6d41\u7a0b</li> <li>\u914d\u7f6e\u9a71\u52a8\uff1a\u901a\u8fc7\u914d\u7f6e\u7ba1\u7406\u6240\u6709\u53c2\u6570</li> <li>\u6a21\u5757\u5316\u8bbe\u8ba1\uff1a\u652f\u6301\u7075\u6d3b\u7684\u7ec4\u4ef6\u7ec4\u5408</li> </ul>"},{"location":"training-framework/modules/project/README_zh/#_5","title":"\u4e00\u7ad9\u5f0f\u8bad\u7ec3\u63a5\u53e3","text":"<ul> <li>\u7b80\u5316\u6d41\u7a0b\uff1a\u7edf\u4e00\u7684\u8bad\u7ec3\u5165\u53e3</li> <li>\u81ea\u52a8\u914d\u7f6e\uff1a\u81ea\u52a8\u5904\u7406\u7ec4\u4ef6\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb</li> <li>\u72b6\u6001\u7ba1\u7406\uff1a\u7ef4\u62a4\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u72b6\u6001\u4fe1\u606f</li> <li>\u9519\u8bef\u5904\u7406\uff1a\u7edf\u4e00\u7684\u5f02\u5e38\u5904\u7406\u673a\u5236</li> </ul>"},{"location":"training-framework/modules/project/README_zh/#_6","title":"\u5b9e\u9a8c\u7ba1\u7406","text":"<ul> <li>\u5b9e\u9a8c\u8ddf\u8e2a\uff1a\u8bb0\u5f55\u5b9e\u9a8c\u914d\u7f6e\u548c\u7ed3\u679c</li> <li>\u7248\u672c\u63a7\u5236\uff1a\u652f\u6301\u5b9e\u9a8c\u7248\u672c\u7ba1\u7406\u548c\u590d\u73b0</li> <li>\u7ed3\u679c\u7ba1\u7406\uff1a\u81ea\u52a8\u4fdd\u5b58\u548c\u7ec4\u7ec7\u8bad\u7ec3\u7ed3\u679c</li> <li>\u5bf9\u6bd4\u5206\u6790\uff1a\u652f\u6301\u591a\u5b9e\u9a8c\u5bf9\u6bd4\u5206\u6790</li> </ul>"},{"location":"training-framework/modules/project/README_zh/#_7","title":"\u4f7f\u7528\u793a\u4f8b","text":"<pre><code>from src._project.base.project import ProjectManager\nfrom src._project.base.config import ProjectConfig\n\n# \u521b\u5efa\u9879\u76ee\u914d\u7f6e\nconfig = ProjectConfig(\n    name=\"my_experiment\",\n    model=model_config,\n    datamodule=datamodule_config,\n    trainer=trainer_config\n)\n\n# \u521b\u5efa\u9879\u76ee\u7ba1\u7406\u5668\nproject = ProjectManager(config)\n\n# \u6267\u884c\u8bad\u7ec3\nproject.fit()\n</code></pre>"},{"location":"training-framework/modules/project/README_zh/#_8","title":"\u6269\u5c55\u6307\u5357","text":"<p>\u8981\u6269\u5c55\u9879\u76ee\u7ba1\u7406\u529f\u80fd\uff1a</p> <ol> <li>\u5728 <code>ProjectManager</code> \u4e2d\u6dfb\u52a0\u65b0\u7684\u7ba1\u7406\u65b9\u6cd5</li> <li>\u6269\u5c55 <code>ProjectConfig</code> \u4ee5\u652f\u6301\u65b0\u7684\u914d\u7f6e\u9009\u9879</li> <li>\u6dfb\u52a0\u65b0\u7684\u751f\u547d\u5468\u671f\u7ba1\u7406\u94a9\u5b50</li> <li>\u66f4\u65b0\u7ec4\u4ef6\u96c6\u6210\u903b\u8f91</li> </ol>"},{"location":"training-framework/modules/trainer/","title":"Trainer Module","text":"<p>English | \u4e2d\u6587</p> <p>The trainer module focuses on PyTorch Lightning Trainer configuration and management, unifying management of all training process parameters.</p> <p>Note: This module is a tool class (prefixed with <code>_</code>), following the tool class definitions in the project specifications, commonly used but not frequently modified. For more information, please refer to the Project Architecture Specification.</p>"},{"location":"training-framework/modules/trainer/#directory-structure","title":"Directory Structure","text":"<pre><code>_trainer/\n\u251c\u2500\u2500 base/              # Base trainer configuration abstract classes\n\u2502   \u251c\u2500\u2500 __init__.py    # Submodule initialization\n\u2502   \u2514\u2500\u2500 config.py      # BaseTrainerConfig configuration class\n\u2514\u2500\u2500 __init__.py        # Module initialization and type definitions\n</code></pre>"},{"location":"training-framework/modules/trainer/#core-components","title":"Core Components","text":""},{"location":"training-framework/modules/trainer/#basetrainerconfig","title":"BaseTrainerConfig","text":"<p>Trainer configuration base class - encapsulates all configuration parameters of PyTorch Lightning Trainer:</p> <pre><code>@dataclass(config=ConfigDict(extra=\"allow\"))\nclass BaseTrainerConfig:\n    \"\"\"Trainer configuration base class - encapsulates all configuration parameters of PyTorch Lightning Trainer\"\"\"\n\n    # Hardware and accelerator configuration\n    accelerator: Union[str, Any] = Field(\n        default=\"auto\",\n        description=\"Accelerator type ('cpu', 'gpu', 'tpu', 'hpu', 'mps', 'auto')\",\n    )\n    strategy: Union[str, Any] = Field(default=\"auto\", description=\"Training strategy\")\n    devices: Union[List[int], str, int] = Field(\n        default=\"auto\", description=\"Devices to use\"\n    )\n    num_nodes: int = Field(default=1, description=\"Number of GPU nodes for distributed training\")\n\n    # Precision configuration\n    precision: Union[...] = Field(default=\"32-true\", description=\"Training precision\")\n\n    # Logging and recording\n    logger: Union[Any, List[Any], bool, None] = Field(\n        default=True, description=\"Logger\"\n    )\n\n    # Training control\n    max_epochs: Optional[int] = Field(default=None, description=\"Maximum number of training epochs\")\n    max_steps: int = Field(default=-1, description=\"Maximum number of training steps\")\n    min_steps: Optional[int] = Field(default=None, description=\"Minimum number of training steps\")\n\n    # Validation control\n    val_check_interval: Union[int, float, None] = Field(\n        default=1.0, description=\"Validation check interval\"\n    )\n    check_val_every_n_epoch: Optional[int] = Field(\n        default=1, description=\"Perform validation every N epochs\"\n    )\n\n    # Gradient control\n    accumulate_grad_batches: int = Field(default=1, description=\"Number of gradient accumulation batches\")\n    gradient_clip_val: Union[int, float, None] = Field(\n        default=None, description=\"Gradient clipping value\"\n    )\n</code></pre>"},{"location":"training-framework/modules/trainer/#uniontrainerconfig","title":"UnionTrainerConfig","text":"<p>Unified trainer configuration type:</p> <pre><code>UnionTrainerConfig = Union[BaseTrainerConfig, dict]\n</code></pre>"},{"location":"training-framework/modules/trainer/#main-features","title":"Main Features","text":""},{"location":"training-framework/modules/trainer/#hardware-configuration","title":"Hardware Configuration","text":"<ul> <li>Multi-accelerator support: Supports CPU, GPU, TPU, HPU, MPS</li> <li>Distributed training: Supports multiple distributed strategies and multi-node training</li> <li>Auto-detection: Automatically detects and configures available hardware</li> <li>Mixed precision: Supports multiple precision training modes</li> </ul>"},{"location":"training-framework/modules/trainer/#training-control","title":"Training Control","text":"<ul> <li>Flexible epochs: Configurable maximum/minimum training epochs and steps</li> <li>Validation scheduling: Flexible validation frequency and batch limits</li> <li>Gradient optimization: Gradient accumulation and clipping control</li> <li>Performance tuning: Deterministic mode and benchmarking</li> </ul>"},{"location":"training-framework/modules/trainer/#logging-and-monitoring","title":"Logging and Monitoring","text":"<ul> <li>Multi-logger integration: Supports multiple logger types</li> <li>Progress monitoring: Training progress and performance metric monitoring</li> <li>Debugging support: Quick development runs and overfitting testing</li> <li>Exception detection: Automatic exception detection and handling</li> </ul>"},{"location":"training-framework/modules/trainer/#usage-example","title":"Usage Example","text":"<pre><code>from src._trainer import UnionTrainerConfig, BaseTrainerConfig\n\n# Create trainer configuration\ntrainer_config = BaseTrainerConfig(\n    accelerator=\"gpu\",\n    devices=1,\n    max_epochs=100,\n    precision=\"16-mixed\"\n)\n\n# Use in configuration\nconfig = SomeConfig(\n    trainer=trainer_config\n)\n</code></pre>"},{"location":"training-framework/modules/trainer/README_zh/","title":"Trainer Module","text":"<p>English | \u4e2d\u6587</p> <p>\u8bad\u7ec3\u5668\u6a21\u5757\u4e13\u6ce8\u4e8e PyTorch Lightning Trainer \u7684\u914d\u7f6e\u548c\u7ba1\u7406\uff0c\u7edf\u4e00\u7ba1\u7406\u8bad\u7ec3\u8fc7\u7a0b\u7684\u6240\u6709\u53c2\u6570\u3002</p> <p>\u6ce8\u610f: \u6b64\u6a21\u5757\u4e3a\u5de5\u5177\u7c7b\uff08\u4ee5 <code>_</code> \u5f00\u5934\uff09\uff0c\u9075\u5faa\u9879\u76ee\u89c4\u8303\u4e2d\u5de5\u5177\u7c7b\u7684\u5b9a\u4e49\uff0c\u5e38\u7528\u4f46\u4e0d\u5e38\u4fee\u6539\u3002\u5982\u9700\u4e86\u89e3\u66f4\u591a\uff0c\u8bf7\u53c2\u8003 \u9879\u76ee\u67b6\u6784\u89c4\u8303\u3002</p>"},{"location":"training-framework/modules/trainer/README_zh/#_1","title":"\u76ee\u5f55\u7ed3\u6784","text":"<pre><code>_trainer/\n\u251c\u2500\u2500 base/              # \u57fa\u7840\u8bad\u7ec3\u5668\u914d\u7f6e\u62bd\u8c61\u7c7b\n\u2502   \u251c\u2500\u2500 __init__.py    # \u6a21\u5757\u521d\u59cb\u5316\n\u2502   \u2514\u2500\u2500 config.py      # BaseTrainerConfig \u914d\u7f6e\u7c7b\n\u2514\u2500\u2500 __init__.py        # \u6a21\u5757\u521d\u59cb\u5316\u548c\u7c7b\u578b\u5b9a\u4e49\n</code></pre>"},{"location":"training-framework/modules/trainer/README_zh/#_2","title":"\u6838\u5fc3\u7ec4\u4ef6","text":""},{"location":"training-framework/modules/trainer/README_zh/#basetrainerconfig","title":"BaseTrainerConfig","text":"<p>\u8bad\u7ec3\u5668\u914d\u7f6e\u57fa\u7c7b - \u5c01\u88c5 PyTorch Lightning Trainer \u7684\u6240\u6709\u914d\u7f6e\u53c2\u6570\uff1a</p> <pre><code>@dataclass(config=ConfigDict(extra=\"allow\"))\nclass BaseTrainerConfig:\n    \"\"\"\u8bad\u7ec3\u5668\u914d\u7f6e\u57fa\u7c7b - \u5c01\u88c5 PyTorch Lightning Trainer \u7684\u6240\u6709\u914d\u7f6e\u53c2\u6570\"\"\"\n\n    # \u786c\u4ef6\u548c\u52a0\u901f\u5668\u914d\u7f6e\n    accelerator: Union[str, Any] = Field(\n        default=\"auto\",\n        description=\"\u52a0\u901f\u5668\u7c7b\u578b ('cpu', 'gpu', 'tpu', 'hpu', 'mps', 'auto')\",\n    )\n    strategy: Union[str, Any] = Field(default=\"auto\", description=\"\u8bad\u7ec3\u7b56\u7565\")\n    devices: Union[List[int], str, int] = Field(\n        default=\"auto\", description=\"\u4f7f\u7528\u7684\u8bbe\u5907\"\n    )\n    num_nodes: int = Field(default=1, description=\"\u5206\u5e03\u5f0f\u8bad\u7ec3\u7684GPU\u8282\u70b9\u6570\u91cf\")\n\n    # \u7cbe\u5ea6\u914d\u7f6e\n    precision: Union[...] = Field(default=\"32-true\", description=\"\u8bad\u7ec3\u7cbe\u5ea6\")\n\n    # \u65e5\u5fd7\u548c\u8bb0\u5f55\u5668\n    logger: Union[Any, List[Any], bool, None] = Field(\n        default=True, description=\"\u65e5\u5fd7\u8bb0\u5f55\u5668\"\n    )\n\n    # \u8bad\u7ec3\u63a7\u5236\n    max_epochs: Optional[int] = Field(default=None, description=\"\u6700\u5927\u8bad\u7ec3\u8f6e\u6570\")\n    max_steps: int = Field(default=-1, description=\"\u6700\u5927\u8bad\u7ec3\u6b65\u6570\")\n    min_steps: Optional[int] = Field(default=None, description=\"\u6700\u5c0f\u8bad\u7ec3\u6b65\u6570\")\n\n    # \u9a8c\u8bc1\u63a7\u5236\n    val_check_interval: Union[int, float, None] = Field(\n        default=1.0, description=\"\u9a8c\u8bc1\u68c0\u67e5\u95f4\u9694\"\n    )\n    check_val_every_n_epoch: Optional[int] = Field(\n        default=1, description=\"\u6bcfN\u4e2aepoch\u8fdb\u884c\u4e00\u6b21\u9a8c\u8bc1\"\n    )\n\n    # \u68af\u5ea6\u63a7\u5236\n    accumulate_grad_batches: int = Field(default=1, description=\"\u68af\u5ea6\u7d2f\u79ef\u6279\u6b21\u6570\")\n    gradient_clip_val: Union[int, float, None] = Field(\n        default=None, description=\"\u68af\u5ea6\u88c1\u526a\u503c\"\n    )\n</code></pre>"},{"location":"training-framework/modules/trainer/README_zh/#uniontrainerconfig","title":"UnionTrainerConfig","text":"<p>\u7edf\u4e00\u7684\u8bad\u7ec3\u5668\u914d\u7f6e\u7c7b\u578b\uff1a</p> <pre><code>UnionTrainerConfig = Union[BaseTrainerConfig, dict]\n</code></pre>"},{"location":"training-framework/modules/trainer/README_zh/#_3","title":"\u4e3b\u8981\u529f\u80fd","text":""},{"location":"training-framework/modules/trainer/README_zh/#_4","title":"\u786c\u4ef6\u914d\u7f6e","text":"<ul> <li>\u591a\u52a0\u901f\u5668\u652f\u6301\uff1a\u652f\u6301 CPU\u3001GPU\u3001TPU\u3001HPU\u3001MPS</li> <li>\u5206\u5e03\u5f0f\u8bad\u7ec3\uff1a\u652f\u6301\u591a\u79cd\u5206\u5e03\u5f0f\u7b56\u7565\u548c\u591a\u8282\u70b9\u8bad\u7ec3</li> <li>\u81ea\u52a8\u68c0\u6d4b\uff1a\u81ea\u52a8\u68c0\u6d4b\u548c\u914d\u7f6e\u53ef\u7528\u786c\u4ef6</li> <li>\u6df7\u5408\u7cbe\u5ea6\uff1a\u652f\u6301\u591a\u79cd\u7cbe\u5ea6\u8bad\u7ec3\u6a21\u5f0f</li> </ul>"},{"location":"training-framework/modules/trainer/README_zh/#_5","title":"\u8bad\u7ec3\u63a7\u5236","text":"<ul> <li>\u7075\u6d3b\u8f6e\u6b21\uff1a\u53ef\u914d\u7f6e\u7684\u6700\u5927/\u6700\u5c0f\u8bad\u7ec3\u8f6e\u6b21\u548c\u6b65\u6570</li> <li>\u9a8c\u8bc1\u8c03\u5ea6\uff1a\u7075\u6d3b\u7684\u9a8c\u8bc1\u9891\u7387\u548c\u6279\u6b21\u9650\u5236</li> <li>\u68af\u5ea6\u4f18\u5316\uff1a\u68af\u5ea6\u7d2f\u79ef\u548c\u88c1\u526a\u63a7\u5236</li> <li>\u6027\u80fd\u8c03\u4f18\uff1a\u786e\u5b9a\u6027\u6a21\u5f0f\u548c\u57fa\u51c6\u6d4b\u8bd5</li> </ul>"},{"location":"training-framework/modules/trainer/README_zh/#_6","title":"\u65e5\u5fd7\u548c\u76d1\u63a7","text":"<ul> <li>\u591a\u65e5\u5fd7\u5668\u96c6\u6210\uff1a\u652f\u6301\u591a\u79cd\u65e5\u5fd7\u8bb0\u5f55\u5668</li> <li>\u8fdb\u5ea6\u76d1\u63a7\uff1a\u8bad\u7ec3\u8fdb\u5ea6\u548c\u6027\u80fd\u6307\u6807\u76d1\u63a7</li> <li>\u8c03\u8bd5\u652f\u6301\uff1a\u5feb\u901f\u5f00\u53d1\u8fd0\u884c\u548c\u8fc7\u62df\u5408\u6d4b\u8bd5</li> <li>\u5f02\u5e38\u68c0\u6d4b\uff1a\u81ea\u52a8\u5f02\u5e38\u68c0\u6d4b\u548c\u5904\u7406</li> </ul>"},{"location":"training-framework/modules/trainer/README_zh/#_7","title":"\u4f7f\u7528\u793a\u4f8b","text":"<pre><code>from src._trainer import UnionTrainerConfig, BaseTrainerConfig\n\n# \u521b\u5efa\u8bad\u7ec3\u5668\u914d\u7f6e\ntrainer_config = BaseTrainerConfig(\n    accelerator=\"gpu\",\n    devices=1,\n    max_epochs=100,\n    precision=\"16-mixed\"\n)\n\n# \u5728\u914d\u7f6e\u4e2d\u4f7f\u7528\nconfig = SomeConfig(\n    trainer=trainer_config\n)\n</code></pre>"},{"location":"training-framework/modules/utils/","title":"Utils Module","text":"<p>English | \u4e2d\u6587</p> <p>The utils module focuses on providing general configuration base classes and utility functions that support multiple configuration types with dictionary access functionality.</p> <p>Note: This module is a tool class (prefixed with <code>_</code>), following the tool class definitions in the project specifications, commonly used but not frequently modified. For more information, please refer to the Project Architecture Specification.</p>"},{"location":"training-framework/modules/utils/#directory-structure","title":"Directory Structure","text":"<pre><code>_utils/\n\u251c\u2500\u2500 config_base.py      # Configuration base classes and dictionary access mixin classes\n\u2514\u2500\u2500 __init__.py         # Module initialization\n</code></pre>"},{"location":"training-framework/modules/utils/#core-components","title":"Core Components","text":""},{"location":"training-framework/modules/utils/#dictaccessmixin","title":"DictAccessMixin","text":"<p>Dictionary access mixin class - provides dictionary-style access interfaces for configuration classes:</p> <pre><code>class DictAccessMixin:\n    \"\"\"Mixin class that provides dictionary access functionality for configuration classes\"\"\"\n\n    def __getitem__(self, key: str) -&gt; Any:\n        \"\"\"Support config['key'] access\"\"\"\n        if hasattr(self, key):\n            return getattr(self, key)\n        raise KeyError(f\"'{key}' not found in {self.__class__.__name__}\")\n\n    def __setitem__(self, key: str, value: Any) -&gt; None:\n        \"\"\"Support config['key'] = value assignment\"\"\"\n        if self._has_field(key):\n            setattr(self, key, value)\n        else:\n            raise KeyError(f\"'{key}' not found in {self.__class__.__name__}\")\n\n    def __contains__(self, key: str) -&gt; bool:\n        \"\"\"Support 'key' in config check\"\"\"\n        return self._has_field(key)\n\n    def get(self, key: str, default: Any = None) -&gt; Any:\n        \"\"\"Support config.get('key', default) access\"\"\"\n        return getattr(self, key, default)\n\n    def keys(self) -&gt; Iterator[str]:\n        \"\"\"Return all field names\"\"\"\n        return iter(self._get_field_names())\n\n    def values(self) -&gt; Iterator[Any]:\n        \"\"\"Return all field values\"\"\"\n        return (getattr(self, key) for key in self.keys())\n\n    def items(self) -&gt; Iterator[tuple[str, Any]]:\n        \"\"\"Return all (key, value) pairs of fields\"\"\"\n        return ((key, getattr(self, key)) for key in self.keys())\n\n    def to_dict(self) -&gt; Dict[str, Any]:\n        \"\"\"Convert to standard dictionary\"\"\"\n        return dict(self.items())\n\n    def update(self, other: Dict[str, Any]) -&gt; None:\n        \"\"\"Batch update field values\"\"\"\n        for key, value in other.items():\n            self[key] = value\n</code></pre>"},{"location":"training-framework/modules/utils/#typeddictaccessmixin","title":"TypedDictAccessMixin","text":"<p>Enhanced dictionary access mixin class - supports TypedDict type safety:</p> <pre><code>class TypedDictAccessMixin(DictAccessMixin):\n    \"\"\"Enhanced mixin class that supports TypedDict type safety\"\"\"\n\n    def to_typed_dict(self) -&gt; Dict[str, Any]:\n        \"\"\"Convert to TypedDict compatible dictionary\"\"\"\n        return self.to_dict()\n\n    def update_from_typed_dict(self, typed_dict: Dict[str, Any]) -&gt; None:\n        \"\"\"Update from TypedDict compatible dictionary\"\"\"\n        self.update(typed_dict)\n</code></pre>"},{"location":"training-framework/modules/utils/#configbase","title":"ConfigBase","text":"<p>Configuration base class based on Pydantic BaseModel:</p> <pre><code>class ConfigBase(BaseModel, DictAccessMixin):\n    \"\"\"Configuration base class based on Pydantic BaseModel\"\"\"\n\n    class Config:\n        arbitrary_types_allowed = True\n        validate_assignment = True\n</code></pre>"},{"location":"training-framework/modules/utils/#dataclassconfigbase","title":"DataclassConfigBase","text":"<p>Configuration base class based on dataclasses:</p> <pre><code>@dataclass\nclass DataclassConfigBase(DictAccessMixin):\n    \"\"\"Configuration base class based on dataclasses\"\"\"\n    pass\n</code></pre>"},{"location":"training-framework/modules/utils/#main-features","title":"Main Features","text":""},{"location":"training-framework/modules/utils/#dictionary-access-interface","title":"Dictionary Access Interface","text":"<ul> <li>Compatibility: Supports both object attribute and dictionary access simultaneously</li> <li>Flexibility: Supports dynamic field access and modification</li> <li>Security: Field existence checks and type validation</li> <li>Convenience: Provides commonly used dictionary operation methods</li> </ul>"},{"location":"training-framework/modules/utils/#configuration-management","title":"Configuration Management","text":"<ul> <li>Type safety: Type validation and checking using Pydantic</li> <li>Data conversion: Automatic handling of data type conversion</li> <li>Configuration inheritance: Supports inheritance and extension of configuration classes</li> <li>Serialization: Supports serialization and deserialization of configurations</li> </ul>"},{"location":"training-framework/modules/utils/#utility-functions","title":"Utility Functions","text":"<ul> <li>Field operations: Batch field updates and queries</li> <li>Data conversion: Mutual conversion between configuration objects and dictionaries</li> <li>Validation mechanisms: Automatic validation of configuration parameters</li> <li>Error handling: Friendly error prompts and exception handling</li> </ul>"},{"location":"training-framework/modules/utils/#usage-example","title":"Usage Example","text":"<pre><code>from src._utils import DictAccessMixin, ConfigBase\n\n# Use dictionary access mixin class\n@dataclass\nclass MyConfig(DictAccessMixin):\n    learning_rate: float = 0.01\n    batch_size: int = 32\n\nconfig = MyConfig()\nconfig['learning_rate'] = 0.001  # Dictionary-style access\nlr = config.get('learning_rate', 0.01)  # Get value\n\n# Use configuration base class\nclass ModelConfig(ConfigBase):\n    lr: float = 0.01\n    name: str = \"model\"\n\nmodel_config = ModelConfig(lr=0.001, name=\"my_model\")\n</code></pre>"},{"location":"training-framework/modules/utils/README_zh/","title":"Utils Module","text":"<p>English | \u4e2d\u6587</p> <p>\u5de5\u5177\u6a21\u5757\u4e13\u6ce8\u4e8e\u63d0\u4f9b\u901a\u7528\u7684\u914d\u7f6e\u57fa\u7840\u7c7b\u548c\u5de5\u5177\u51fd\u6570\uff0c\u652f\u6301\u591a\u79cd\u914d\u7f6e\u7c7b\u578b\u7684\u5b57\u5178\u8bbf\u95ee\u529f\u80fd\u3002</p> <p>\u6ce8\u610f: \u6b64\u6a21\u5757\u4e3a\u5de5\u5177\u7c7b\uff08\u4ee5 <code>_</code> \u5f00\u5934\uff09\uff0c\u9075\u5faa\u9879\u76ee\u89c4\u8303\u4e2d\u5de5\u5177\u7c7b\u7684\u5b9a\u4e49\uff0c\u5e38\u7528\u4f46\u4e0d\u5e38\u4fee\u6539\u3002\u5982\u9700\u4e86\u89e3\u66f4\u591a\uff0c\u8bf7\u53c2\u8003 \u9879\u76ee\u67b6\u6784\u89c4\u8303\u3002</p>"},{"location":"training-framework/modules/utils/README_zh/#_1","title":"\u76ee\u5f55\u7ed3\u6784","text":"<pre><code>_utils/\n\u251c\u2500\u2500 config_base.py      # \u914d\u7f6e\u57fa\u7840\u7c7b\u548c\u5b57\u5178\u8bbf\u95ee\u6df7\u5165\u7c7b\n\u2514\u2500\u2500 __init__.py         # \u6a21\u5757\u521d\u59cb\u5316\n</code></pre>"},{"location":"training-framework/modules/utils/README_zh/#_2","title":"\u6838\u5fc3\u7ec4\u4ef6","text":""},{"location":"training-framework/modules/utils/README_zh/#dictaccessmixin","title":"DictAccessMixin","text":"<p>\u5b57\u5178\u8bbf\u95ee\u6df7\u5165\u7c7b - \u4e3a\u914d\u7f6e\u7c7b\u63d0\u4f9b\u5b57\u5178\u98ce\u683c\u7684\u8bbf\u95ee\u63a5\u53e3\uff1a</p> <pre><code>class DictAccessMixin:\n    \"\"\"\u4e3a\u914d\u7f6e\u7c7b\u63d0\u4f9b\u5b57\u5178\u8bbf\u95ee\u529f\u80fd\u7684\u6df7\u5165\u7c7b\"\"\"\n\n    def __getitem__(self, key: str) -&gt; Any:\n        \"\"\"\u652f\u6301 config['key'] \u8bbf\u95ee\"\"\"\n        if hasattr(self, key):\n            return getattr(self, key)\n        raise KeyError(f\"'{key}' not found in {self.__class__.__name__}\")\n\n    def __setitem__(self, key: str, value: Any) -&gt; None:\n        \"\"\"\u652f\u6301 config['key'] = value \u8d4b\u503c\"\"\"\n        if self._has_field(key):\n            setattr(self, key, value)\n        else:\n            raise KeyError(f\"'{key}' not found in {self.__class__.__name__}\")\n\n    def __contains__(self, key: str) -&gt; bool:\n        \"\"\"\u652f\u6301 'key' in config \u68c0\u67e5\"\"\"\n        return self._has_field(key)\n\n    def get(self, key: str, default: Any = None) -&gt; Any:\n        \"\"\"\u652f\u6301 config.get('key', default) \u8bbf\u95ee\"\"\"\n        return getattr(self, key, default)\n\n    def keys(self) -&gt; Iterator[str]:\n        \"\"\"\u8fd4\u56de\u6240\u6709\u5b57\u6bb5\u540d\"\"\"\n        return iter(self._get_field_names())\n\n    def values(self) -&gt; Iterator[Any]:\n        \"\"\"\u8fd4\u56de\u6240\u6709\u5b57\u6bb5\u503c\"\"\"\n        return (getattr(self, key) for key in self.keys())\n\n    def items(self) -&gt; Iterator[tuple[str, Any]]:\n        \"\"\"\u8fd4\u56de\u6240\u6709\u5b57\u6bb5 (key, value) \u5bf9\"\"\"\n        return ((key, getattr(self, key)) for key in self.keys())\n\n    def to_dict(self) -&gt; Dict[str, Any]:\n        \"\"\"\u8f6c\u6362\u4e3a\u6807\u51c6\u5b57\u5178\"\"\"\n        return dict(self.items())\n\n    def update(self, other: Dict[str, Any]) -&gt; None:\n        \"\"\"\u6279\u91cf\u66f4\u65b0\u5b57\u6bb5\u503c\"\"\"\n        for key, value in other.items():\n            self[key] = value\n</code></pre>"},{"location":"training-framework/modules/utils/README_zh/#typeddictaccessmixin","title":"TypedDictAccessMixin","text":"<p>\u589e\u5f3a\u7684\u5b57\u5178\u8bbf\u95ee\u6df7\u5165\u7c7b - \u652f\u6301 TypedDict \u7c7b\u578b\u5b89\u5168\uff1a</p> <pre><code>class TypedDictAccessMixin(DictAccessMixin):\n    \"\"\"\u589e\u5f3a\u7684\u6df7\u5165\u7c7b\uff0c\u652f\u6301 TypedDict \u7c7b\u578b\u5b89\u5168\"\"\"\n\n    def to_typed_dict(self) -&gt; Dict[str, Any]:\n        \"\"\"\u8f6c\u6362\u4e3a TypedDict \u517c\u5bb9\u7684\u5b57\u5178\"\"\"\n        return self.to_dict()\n\n    def update_from_typed_dict(self, typed_dict: Dict[str, Any]) -&gt; None:\n        \"\"\"\u4ece TypedDict \u517c\u5bb9\u7684\u5b57\u5178\u66f4\u65b0\"\"\"\n        self.update(typed_dict)\n</code></pre>"},{"location":"training-framework/modules/utils/README_zh/#configbase","title":"ConfigBase","text":"<p>\u57fa\u4e8e Pydantic BaseModel \u7684\u914d\u7f6e\u57fa\u7c7b\uff1a</p> <pre><code>class ConfigBase(BaseModel, DictAccessMixin):\n    \"\"\"\u57fa\u4e8e Pydantic BaseModel \u7684\u914d\u7f6e\u57fa\u7c7b\"\"\"\n\n    class Config:\n        arbitrary_types_allowed = True\n        validate_assignment = True\n</code></pre>"},{"location":"training-framework/modules/utils/README_zh/#dataclassconfigbase","title":"DataclassConfigBase","text":"<p>\u57fa\u4e8e\u6570\u636e\u7c7b\u7684\u914d\u7f6e\u57fa\u7c7b\uff1a</p> <pre><code>@dataclass\nclass DataclassConfigBase(DictAccessMixin):\n    \"\"\"\u57fa\u4e8e\u6570\u636e\u7c7b\u7684\u914d\u7f6e\u57fa\u7c7b\"\"\"\n    pass\n</code></pre>"},{"location":"training-framework/modules/utils/README_zh/#_3","title":"\u4e3b\u8981\u529f\u80fd","text":""},{"location":"training-framework/modules/utils/README_zh/#_4","title":"\u5b57\u5178\u8bbf\u95ee\u63a5\u53e3","text":"<ul> <li>\u517c\u5bb9\u6027\uff1a\u540c\u65f6\u652f\u6301\u5bf9\u8c61\u5c5e\u6027\u548c\u5b57\u5178\u8bbf\u95ee</li> <li>\u7075\u6d3b\u6027\uff1a\u652f\u6301\u52a8\u6001\u5b57\u6bb5\u8bbf\u95ee\u548c\u4fee\u6539</li> <li>\u5b89\u5168\u6027\uff1a\u5b57\u6bb5\u5b58\u5728\u6027\u68c0\u67e5\u548c\u7c7b\u578b\u9a8c\u8bc1</li> <li>\u4fbf\u5229\u6027\uff1a\u63d0\u4f9b\u5e38\u7528\u7684\u5b57\u5178\u64cd\u4f5c\u65b9\u6cd5</li> </ul>"},{"location":"training-framework/modules/utils/README_zh/#_5","title":"\u914d\u7f6e\u7ba1\u7406","text":"<ul> <li>\u7c7b\u578b\u5b89\u5168\uff1a\u57fa\u4e8e Pydantic \u7684\u7c7b\u578b\u9a8c\u8bc1</li> <li>\u6570\u636e\u8f6c\u6362\uff1a\u81ea\u52a8\u5904\u7406\u6570\u636e\u7c7b\u578b\u8f6c\u6362</li> <li>\u914d\u7f6e\u7ee7\u627f\uff1a\u652f\u6301\u914d\u7f6e\u7c7b\u7684\u7ee7\u627f\u548c\u6269\u5c55</li> <li>\u5e8f\u5217\u5316\uff1a\u652f\u6301\u914d\u7f6e\u7684\u5e8f\u5217\u5316\u548c\u53cd\u5e8f\u5217\u5316</li> </ul>"},{"location":"training-framework/modules/utils/README_zh/#_6","title":"\u5de5\u5177\u51fd\u6570","text":"<ul> <li>\u5b57\u6bb5\u64cd\u4f5c\uff1a\u6279\u91cf\u5b57\u6bb5\u66f4\u65b0\u548c\u67e5\u8be2</li> <li>\u6570\u636e\u8f6c\u6362\uff1a\u914d\u7f6e\u5bf9\u8c61\u4e0e\u5b57\u5178\u7684\u76f8\u4e92\u8f6c\u6362</li> <li>\u9a8c\u8bc1\u673a\u5236\uff1a\u914d\u7f6e\u53c2\u6570\u7684\u81ea\u52a8\u9a8c\u8bc1</li> <li>\u9519\u8bef\u5904\u7406\uff1a\u53cb\u597d\u7684\u9519\u8bef\u63d0\u793a\u548c\u5f02\u5e38\u5904\u7406</li> </ul>"},{"location":"training-framework/modules/utils/README_zh/#_7","title":"\u4f7f\u7528\u793a\u4f8b","text":"<pre><code>from src._utils import DictAccessMixin, ConfigBase\n\n# \u4f7f\u7528\u5b57\u5178\u8bbf\u95ee\u6df7\u5165\u7c7b\n@dataclass\nclass MyConfig(DictAccessMixin):\n    learning_rate: float = 0.01\n    batch_size: int = 32\n\nconfig = MyConfig()\nconfig['learning_rate'] = 0.001  # \u5b57\u5178\u98ce\u683c\u8bbf\u95ee\nlr = config.get('learning_rate', 0.01)  # \u83b7\u53d6\u503c\n\n# \u4f7f\u7528\u914d\u7f6e\u57fa\u7c7b\nclass ModelConfig(ConfigBase):\n    lr: float = 0.01\n    name: str = \"model\"\n\nmodel_config = ModelConfig(lr=0.001, name=\"my_model\")\n</code></pre>"}]}